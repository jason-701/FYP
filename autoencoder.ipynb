{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Input, LeakyReLU, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history',\n",
      "       'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  hypertension  heart_disease    bmi  HbA1c_level  blood_glucose_level  \\\n",
      "0  80.0             0              1  25.19          6.6                  140   \n",
      "1  54.0             0              0  27.32          6.6                   80   \n",
      "2  28.0             0              0  27.32          5.7                  158   \n",
      "3  36.0             0              0  23.45          5.0                  155   \n",
      "4  76.0             1              1  20.14          4.8                  155   \n",
      "\n",
      "   diabetes  gender_Male  gender_Other  smoking_history_current  \\\n",
      "0         0        False         False                    False   \n",
      "1         0        False         False                    False   \n",
      "2         0         True         False                    False   \n",
      "3         0        False         False                     True   \n",
      "4         0         True         False                     True   \n",
      "\n",
      "   smoking_history_ever  smoking_history_former  smoking_history_never  \\\n",
      "0                 False                   False                   True   \n",
      "1                 False                   False                  False   \n",
      "2                 False                   False                   True   \n",
      "3                 False                   False                  False   \n",
      "4                 False                   False                  False   \n",
      "\n",
      "   smoking_history_not current  \n",
      "0                        False  \n",
      "1                        False  \n",
      "2                        False  \n",
      "3                        False  \n",
      "4                        False  \n"
     ]
    }
   ],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['gender', 'smoking_history'], drop_first=True)\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender_Male', 'gender_Other', 'smoking_history_current',\n",
      "       'smoking_history_ever', 'smoking_history_former',\n",
      "       'smoking_history_never', 'smoking_history_not current'],\n",
      "      dtype='object')\n",
      "Index(['age', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level',\n",
      "       'blood_glucose_level', 'diabetes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "boolean_columns = df_encoded.select_dtypes(include=bool).columns\n",
    "numerical_columns = df_encoded.select_dtypes(include=np.number).columns\n",
    "print(boolean_columns)\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = numerical_columns.drop(['diabetes', 'age'])\n",
    "boolean_columns = boolean_columns.insert(0, 'diabetes')\n",
    "boolean_columns = boolean_columns.insert(0, 'age')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_numerical_scaled = pd.DataFrame(scaler.fit_transform(df[numerical_columns]), columns=numerical_columns)\n",
    "df_scaled = pd.concat([df_numerical_scaled, df_encoded[boolean_columns]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Other</th>\n",
       "      <th>smoking_history_current</th>\n",
       "      <th>smoking_history_ever</th>\n",
       "      <th>smoking_history_former</th>\n",
       "      <th>smoking_history_never</th>\n",
       "      <th>smoking_history_not current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.284439</td>\n",
       "      <td>4.936379</td>\n",
       "      <td>-0.321056</td>\n",
       "      <td>1.001706</td>\n",
       "      <td>0.047704</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.284439</td>\n",
       "      <td>-0.202578</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>1.001706</td>\n",
       "      <td>-1.426210</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.284439</td>\n",
       "      <td>-0.202578</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.161108</td>\n",
       "      <td>0.489878</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.284439</td>\n",
       "      <td>-0.202578</td>\n",
       "      <td>-0.583232</td>\n",
       "      <td>-0.492690</td>\n",
       "      <td>0.416183</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.515687</td>\n",
       "      <td>4.936379</td>\n",
       "      <td>-1.081970</td>\n",
       "      <td>-0.679490</td>\n",
       "      <td>0.416183</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hypertension  heart_disease       bmi  HbA1c_level  blood_glucose_level  \\\n",
       "0     -0.284439       4.936379 -0.321056     1.001706             0.047704   \n",
       "1     -0.284439      -0.202578 -0.000116     1.001706            -1.426210   \n",
       "2     -0.284439      -0.202578 -0.000116     0.161108             0.489878   \n",
       "3     -0.284439      -0.202578 -0.583232    -0.492690             0.416183   \n",
       "4      3.515687       4.936379 -1.081970    -0.679490             0.416183   \n",
       "\n",
       "    age  diabetes  gender_Male  gender_Other  smoking_history_current  \\\n",
       "0  80.0         0        False         False                    False   \n",
       "1  54.0         0        False         False                    False   \n",
       "2  28.0         0         True         False                    False   \n",
       "3  36.0         0        False         False                     True   \n",
       "4  76.0         0         True         False                     True   \n",
       "\n",
       "   smoking_history_ever  smoking_history_former  smoking_history_never  \\\n",
       "0                 False                   False                   True   \n",
       "1                 False                   False                  False   \n",
       "2                 False                   False                   True   \n",
       "3                 False                   False                  False   \n",
       "4                 False                   False                  False   \n",
       "\n",
       "   smoking_history_not current  \n",
       "0                        False  \n",
       "1                        False  \n",
       "2                        False  \n",
       "3                        False  \n",
       "4                        False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "80.00    5621\n",
      "51.00    1619\n",
      "47.00    1574\n",
      "48.00    1568\n",
      "53.00    1542\n",
      "         ... \n",
      "0.48       83\n",
      "1.00       83\n",
      "0.40       66\n",
      "0.16       59\n",
      "0.08       36\n",
      "Name: count, Length: 102, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "age_distribution = df_scaled['age'].value_counts()\n",
    "print(age_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age group 0-29: 32435 records\n",
      "Age group 30-59: 42510 records\n",
      "Age group 60-89: 25055 records\n"
     ]
    }
   ],
   "source": [
    "# age_groups = [(0, 9), (10, 19), (20, 29), (30, 39), (40, 49), (50, 59), (60, 69), (70, 79), (80, 89)]\n",
    "\n",
    "# datasets = {}\n",
    "# for start, end in age_groups:\n",
    "#     group_name = f\"{start}-{end}\"\n",
    "#     datasets[group_name] = df_scaled[(df_scaled['age'] >= start) & (df_scaled['age'] <= end)]\n",
    "\n",
    "# # Display the number of records in each dataset\n",
    "# for group_name, dataset in datasets.items():\n",
    "#     print(f\"Age group {group_name}: {len(dataset)} records\")\n",
    "\n",
    "\n",
    "age_groups = [(0, 29), (30, 59), (60, 89)]\n",
    "\n",
    "datasets = {}\n",
    "for start, end in age_groups:\n",
    "    group_name = f\"{start}-{end}\"\n",
    "    datasets[group_name] = df_scaled[(df_scaled['age'] >= start) & (df_scaled['age'] <= end)]\n",
    "\n",
    "# Display the number of records in each dataset\n",
    "for group_name, dataset in datasets.items():\n",
    "    print(f\"Age group {group_name}: {len(dataset)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = datasets['30-59']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = testDF.drop(['diabetes', 'age'], axis=1)\n",
    "y = testDF['diabetes']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file does not exist. Training a new model...\n",
      "Epoch 1/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.2839 - val_loss: 0.0373\n",
      "Epoch 2/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0810 - val_loss: 0.0198\n",
      "Epoch 3/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0610 - val_loss: 0.0133\n",
      "Epoch 4/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0521 - val_loss: 0.0092\n",
      "Epoch 5/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0474 - val_loss: 0.0084\n",
      "Epoch 6/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0434 - val_loss: 0.0071\n",
      "Epoch 7/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0415 - val_loss: 0.0061\n",
      "Epoch 8/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0389 - val_loss: 0.0057\n",
      "Epoch 9/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0366 - val_loss: 0.0056\n",
      "Epoch 10/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0360 - val_loss: 0.0049\n",
      "Epoch 11/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0344 - val_loss: 0.0046\n",
      "Epoch 12/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0339 - val_loss: 0.0044\n",
      "Epoch 13/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0320 - val_loss: 0.0042\n",
      "Epoch 14/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0319 - val_loss: 0.0042\n",
      "Epoch 15/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0312 - val_loss: 0.0040\n",
      "Epoch 16/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0305 - val_loss: 0.0041\n",
      "Epoch 17/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0298 - val_loss: 0.0037\n",
      "Epoch 18/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0300 - val_loss: 0.0036\n",
      "Epoch 19/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0297 - val_loss: 0.0036\n",
      "Epoch 20/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0298 - val_loss: 0.0035\n",
      "Epoch 21/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0290 - val_loss: 0.0033\n",
      "Epoch 22/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0281 - val_loss: 0.0033\n",
      "Epoch 23/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0283 - val_loss: 0.0035\n",
      "Epoch 24/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0285 - val_loss: 0.0031\n",
      "Epoch 25/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0281 - val_loss: 0.0032\n",
      "Epoch 26/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0279 - val_loss: 0.0031\n",
      "Epoch 27/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0276 - val_loss: 0.0029\n",
      "Epoch 28/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0275 - val_loss: 0.0030\n",
      "Epoch 29/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0273 - val_loss: 0.0031\n",
      "Epoch 30/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0270 - val_loss: 0.0029\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.4681 - val_loss: 0.2722\n",
      "Epoch 2/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2565 - val_loss: 0.2339\n",
      "Epoch 3/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2307 - val_loss: 0.2221\n",
      "Epoch 4/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2189 - val_loss: 0.2153\n",
      "Epoch 5/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2136 - val_loss: 0.2135\n",
      "Epoch 6/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2155 - val_loss: 0.2128\n",
      "Epoch 7/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2113 - val_loss: 0.2125\n",
      "Epoch 8/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2139 - val_loss: 0.2124\n",
      "Epoch 9/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2145 - val_loss: 0.2123\n",
      "Epoch 10/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2131 - val_loss: 0.2122\n",
      "Epoch 11/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2051 - val_loss: 0.2122\n",
      "Epoch 12/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2151 - val_loss: 0.2121\n",
      "Epoch 13/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2107 - val_loss: 0.2121\n",
      "Epoch 14/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2095 - val_loss: 0.2121\n",
      "Epoch 15/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2129 - val_loss: 0.2121\n",
      "Epoch 16/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2102 - val_loss: 0.2121\n",
      "Epoch 17/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2128 - val_loss: 0.2121\n",
      "Epoch 18/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2101 - val_loss: 0.2121\n",
      "Epoch 19/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2128 - val_loss: 0.2121\n",
      "Epoch 20/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2127 - val_loss: 0.2120\n",
      "Epoch 21/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2101 - val_loss: 0.2120\n",
      "Epoch 22/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2103 - val_loss: 0.2120\n",
      "Epoch 23/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2134 - val_loss: 0.2120\n",
      "Epoch 24/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2109 - val_loss: 0.2120\n",
      "Epoch 25/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2124 - val_loss: 0.2120\n",
      "Epoch 26/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2126 - val_loss: 0.2120\n",
      "Epoch 27/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2100 - val_loss: 0.2120\n",
      "Epoch 28/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2091 - val_loss: 0.2120\n",
      "Epoch 29/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2119 - val_loss: 0.2120\n",
      "Epoch 30/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2114 - val_loss: 0.2120\n",
      "Epoch 31/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2121 - val_loss: 0.2120\n",
      "Epoch 32/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2127 - val_loss: 0.2120\n",
      "Epoch 33/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2161 - val_loss: 0.2120\n",
      "Epoch 34/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2113 - val_loss: 0.2120\n",
      "Epoch 35/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2145 - val_loss: 0.2120\n",
      "Epoch 36/200\n",
      "\u001b[1m851/851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2112 - val_loss: 0.2120\n",
      "Model trained and saved.\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Reconstruction Error Percentage: 21.351815006784875\n"
     ]
    }
   ],
   "source": [
    "# Filename for the autoencoder model\n",
    "model_file = 'autoencoder.keras'\n",
    "\n",
    "# Check if the model file exists, load it if available, otherwise train a new model\n",
    "if os.path.exists(model_file):\n",
    "    print(\"Model file exists. Loading the model...\")\n",
    "    autoencoder = load_model(model_file)\n",
    "else:\n",
    "    print(\"Model file does not exist. Training a new model...\")\n",
    "\n",
    "    # Define input dimensions and encoding dimensions\n",
    "    input_dim = x_train.shape[1]  # Assuming 12 features\n",
    "    encoding_dim = 12  # Bottleneck layer dimension\n",
    "\n",
    "    # Define the Encoder\n",
    "    # input_layer = Input(shape=(input_dim,))\n",
    "    # encoded = Dense(128, activation='sigmoid')(input_layer)\n",
    "    # encoded = Dense(64, activation='sigmoid')(encoded)\n",
    "    # encoded = Dense(32, activation='sigmoid')(encoded)\n",
    "    # encoded = Dense(encoding_dim, activation='sigmoid')(encoded)  # Bottleneck layer\n",
    "    \n",
    "    #################################\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(256)(input_layer)\n",
    "    encoded = LeakyReLU()(encoded)\n",
    "    encoded = Dropout(0.2)(encoded)\n",
    "    encoded = Dense(128)(encoded)\n",
    "    encoded = LeakyReLU()(encoded)\n",
    "    encoded = Dropout(0.2)(encoded)\n",
    "    encoded = Dense(64)(encoded)\n",
    "    encoded = LeakyReLU()(encoded)\n",
    "    encoded = Dropout(0.2)(encoded)\n",
    "    encoded = Dense(encoding_dim, activation='linear')(encoded)  # Bottleneck layer\n",
    "    #################################\n",
    "    \n",
    "\n",
    "    # Create the Encoder model\n",
    "    encoder = Model(input_layer, encoded)\n",
    "    encoder.compile(optimizer=Adam(learning_rate=0.00005), loss='mse')\n",
    "\n",
    "    # Train the Encoder\n",
    "    encoder.fit(x_train, x_train, epochs=200, validation_split=0.2, verbose=1,\n",
    "                callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)])\n",
    "\n",
    "    # Define the Decoder\n",
    "    # encoded_input = Input(shape=(encoding_dim,))\n",
    "    # decoded = Dense(32, activation='sigmoid')(encoded_input)\n",
    "    # decoded = Dense(64, activation='sigmoid')(decoded)\n",
    "    # decoded = Dense(128, activation='sigmoid')(decoded)\n",
    "    # decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "    \n",
    "    \n",
    "    #################################\n",
    "    encoded_input = Input(shape=(encoding_dim,))\n",
    "    decoded = Dense(64)(encoded_input)\n",
    "    decoded = LeakyReLU()(decoded)\n",
    "    decoded = Dense(128)(decoded)\n",
    "    decoded = LeakyReLU()(decoded)\n",
    "    decoded = Dense(256)(decoded)\n",
    "    decoded = LeakyReLU()(decoded)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "    #################################\n",
    "    \n",
    "    # Create the Decoder model\n",
    "    decoder = Model(encoded_input, decoded)\n",
    "    decoder.compile(optimizer=Adam(learning_rate=0.00005), loss='mse')\n",
    "\n",
    "    # Train the Decoder\n",
    "    encoded_train = encoder.predict(x_train)\n",
    "    decoder.fit(encoded_train, x_train, epochs=200, validation_split=0.2, verbose=1,\n",
    "                callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)])\n",
    "\n",
    "    # Combine Encoder and Decoder to form the Autoencoder\n",
    "    autoencoder_input = Input(shape=(input_dim,))\n",
    "    encoded_repr = encoder(autoencoder_input)\n",
    "    reconstructed = decoder(encoded_repr)\n",
    "    autoencoder = Model(autoencoder_input, reconstructed)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.00005), loss='mse')\n",
    "\n",
    "    # Save the model as autoencoder.keras\n",
    "    autoencoder.save(model_file)\n",
    "    print(\"Model trained and saved.\")\n",
    "\n",
    "# Calculate reconstruction error on the test set\n",
    "reconstructed_test = autoencoder.predict(x_test)\n",
    "reconstruction_error = np.mean(np.square(x_test - reconstructed_test), axis=1)\n",
    "\n",
    "# Convert reconstruction error to percentage\n",
    "reconstruction_error_percentage = np.mean(reconstruction_error) * 100\n",
    "\n",
    "# Print reconstruction error percentage\n",
    "print(f'Reconstruction Error Percentage: {reconstruction_error_percentage}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Test data for age range 0-29 and 60-89 created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ROG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 34 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Load the autoencoder model\n",
    "model_file = 'autoencoder.keras'\n",
    "autoencoder = load_model(model_file)\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "\n",
    "# Create test data for other age ranges\n",
    "testDF_0_29 = datasets['0-29']\n",
    "testDF_60_89 = datasets['60-89']\n",
    "\n",
    "# Prepare the test data\n",
    "x_test_0_29 = testDF_0_29.drop(['diabetes', 'age'], axis=1)\n",
    "y_test_0_29 = testDF_0_29['diabetes']\n",
    "\n",
    "x_test_60_89 = testDF_60_89.drop(['diabetes', 'age'], axis=1)\n",
    "y_test_60_89 = testDF_60_89['diabetes']\n",
    "\n",
    "print(\"Test data for age range 0-29 and 60-89 created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Reconstruction Error Percentage for 0-29 age group: 19.063993235762034\n"
     ]
    }
   ],
   "source": [
    "# Predict the reconstruction error for the 0-29 age group\n",
    "reconstructed_test_0_29 = autoencoder.predict(x_test_0_29)\n",
    "reconstruction_error_0_29 = np.mean(np.square(x_test_0_29 - reconstructed_test_0_29), axis=1)\n",
    "\n",
    "# Convert reconstruction error to percentage\n",
    "reconstruction_error_percentage_0_29 = np.mean(reconstruction_error_0_29) * 100\n",
    "\n",
    "# Print reconstruction error percentage for 0-29 age group\n",
    "print(f'Reconstruction Error Percentage for 0-29 age group: {reconstruction_error_percentage_0_29}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Reconstruction Error Percentage for 60-89 age group: 40.03314425327109\n"
     ]
    }
   ],
   "source": [
    "# Predict the reconstruction error for the 60-89 age group\n",
    "reconstructed_test_60_89 = autoencoder.predict(x_test_60_89)\n",
    "reconstruction_error_60_89 = np.mean(np.square(x_test_60_89 - reconstructed_test_60_89), axis=1)\n",
    "\n",
    "# Convert reconstruction error to percentage\n",
    "reconstruction_error_percentage_60_89 = np.mean(reconstruction_error_60_89) * 100\n",
    "\n",
    "# Print reconstruction error percentage for 60-89 age group\n",
    "print(f'Reconstruction Error Percentage for 60-89 age group: {reconstruction_error_percentage_60_89}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

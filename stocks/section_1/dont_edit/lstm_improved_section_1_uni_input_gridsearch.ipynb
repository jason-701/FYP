{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 411,
      "metadata": {
        "id": "M_JutKiKPbgK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from numpy.linalg import norm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 412,
      "metadata": {
        "id": "gsObt5CZPbgM"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 413,
      "metadata": {
        "id": "Em0mlPWnPbgM"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "file_path = \"SPY_section_1.csv\"\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 414,
      "metadata": {
        "id": "kxFYjyboPbgN"
      },
      "outputs": [],
      "source": [
        "# Define Autoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoding_dim, dropout_rate):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(64, encoding_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoding_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 415,
      "metadata": {
        "id": "8PoaIEg9PbgO"
      },
      "outputs": [],
      "source": [
        "# Define LSTM model\n",
        "class ComplexLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate):\n",
        "        super(ComplexLSTMModel, self).__init__()\n",
        "        # Unidirectional LSTM for sequential stock price prediction\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
        "                            batch_first=True, dropout=dropout_rate)  # Removed bidirectional=True\n",
        "\n",
        "        # Fully connected layers for added complexity\n",
        "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(hidden_size // 2, hidden_size // 4)\n",
        "        self.dropout2 = nn.Dropout(dropout_rate)\n",
        "        self.fc3 = nn.Linear(hidden_size // 4, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTM expects input of shape (batch_size, sequence_length, input_size)\n",
        "        out, _ = self.lstm(x)\n",
        "        # Use the output of the last time step\n",
        "        out = out[:, -1, :]  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "        out = torch.relu(self.fc1(out))  # First fully connected layer\n",
        "        out = self.dropout1(out)\n",
        "        out = torch.relu(self.fc2(out))  # Second fully connected layer\n",
        "        out = self.dropout2(out)\n",
        "        out = self.fc3(out)  # Output layer (no activation for regression)\n",
        "        return out\n",
        "\n",
        "\n",
        "sequence_length = 10\n",
        "\n",
        "# Reshape data into sequences\n",
        "def create_sequences(data, target, seq_length):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X_seq.append(data[i:i + seq_length])\n",
        "        y_seq.append(target[i + seq_length])\n",
        "    return np.array(X_seq), np.array(y_seq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 416,
      "metadata": {
        "id": "YCcAOTVZPbgP"
      },
      "outputs": [],
      "source": [
        "# Define the target variable\n",
        "if \"Target\" not in df.columns:\n",
        "    # df[\"Target\"] = (df[\"Close\"].shift(-1) > df[\"Close\"]).astype(int)\n",
        "    df[\"Target\"] = df[\"Close\"].shift(-1)\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 417,
      "metadata": {
        "id": "wLsX8RMiPbgP"
      },
      "outputs": [],
      "source": [
        "# Adding SMA and EMA to the feature\n",
        "short_term_period = 20\n",
        "medium_term_period = 50\n",
        "long_term_period = 200\n",
        "\n",
        "# Compute the SMAs\n",
        "df['SMA_20'] = df['Close'].rolling(window=short_term_period).mean() # Short-term SMA\n",
        "df['SMA_50'] = df['Close'].rolling(window=medium_term_period).mean() # Medium-term SMA\n",
        "df['SMA_200'] = df['Close'].rolling(window=long_term_period).mean() # Long-term SMA\n",
        "\n",
        "df['EMA_10'] = df['Close'].ewm(span=10, adjust=False).mean()  # Short-term EMA\n",
        "df['EMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()  # Medium-term EMA\n",
        "df['EMA_200'] = df['Close'].ewm(span=200, adjust=False).mean()  # Long-term EMA\n",
        "\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 418,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4-4dr_aPbgQ",
        "outputId": "47f7108c-0ec8-43be-bc70-0c1c4404b326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1420, Val: 304, Test: 295\n",
            "(2029, 11)\n"
          ]
        }
      ],
      "source": [
        "X = df.drop(columns=[\"Date\", \"Target\"])\n",
        "y = df[\"Target\"]\n",
        "\n",
        "feature_columns = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"SMA_20\", \"SMA_50\", \"SMA_200\", \"EMA_10\", \"EMA_50\", \"EMA_200\"]\n",
        "\n",
        "train_size = int(X.shape[0] * 0.7)\n",
        "val_size = int(X.shape[0] * 0.15)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Split data into train, validation, and test\n",
        "temp_train = X[:train_size]\n",
        "temp_val = X[train_size:train_size + val_size]\n",
        "temp_test = X[train_size + val_size:]\n",
        "\n",
        "temp_train = temp_train[feature_columns]\n",
        "temp_val = temp_val[feature_columns]\n",
        "temp_test = temp_test[feature_columns]\n",
        "\n",
        "# Fit and transform for train, transform for validation and test\n",
        "temp_train = scaler.fit_transform(temp_train)\n",
        "temp_val = scaler.transform(temp_val)\n",
        "temp_test = scaler.transform(temp_test)\n",
        "\n",
        "# Convert NumPy arrays back to DataFrames\n",
        "temp_train = pd.DataFrame(temp_train, columns=feature_columns)\n",
        "temp_val = pd.DataFrame(temp_val, columns=feature_columns)\n",
        "temp_test = pd.DataFrame(temp_test, columns=feature_columns)\n",
        "\n",
        "# Concatenate the data\n",
        "X_scaled = pd.concat([temp_train, temp_val, temp_test], axis=0)\n",
        "\n",
        "X_seq, y_seq = create_sequences(X_scaled, y.values, sequence_length)\n",
        "\n",
        "# Split sequentially\n",
        "X_train, y_train = X_seq[:train_size], y_seq[:train_size]\n",
        "X_val, y_val = X_seq[train_size:train_size + val_size], y_seq[train_size:train_size + val_size]\n",
        "X_test, y_test = X_seq[train_size + val_size:], y_seq[train_size + val_size:]\n",
        "\n",
        "# Print sizes to confirm\n",
        "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "print(X_scaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 419,
      "metadata": {
        "id": "GBsQfpyQPbgQ"
      },
      "outputs": [],
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWSUtBcjPbgS"
      },
      "source": [
        "<span style=\"color: yellow; font-size: 40px;\">Evaluating original LSTM</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 420,
      "metadata": {
        "id": "sTzSYPwxPbgT"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "input_size = X_train.shape[2]  # Number of features\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "dropout_rate = 0.1\n",
        "learning_rate = 0.0005\n",
        "num_epochs = 500\n",
        "patience = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 421,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "G6-GJJUSPbgU",
        "outputId": "c7732162-1644-473c-d116-2a9b53f28d67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Evaluation Results =====\n",
            "Test Loss: 36.7081\n",
            "Test MAE: 4.6086\n",
            "Average Error Percentage: 4.13%\n",
            "Largest Error Percentage: 13.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-421-e7c8f65edd49>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  LSTM_model.load_state_dict(torch.load(LSTM_model_path, map_location=torch.device('cpu')))\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([39])) that is different to the input size (torch.Size([39, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define paths\n",
        "LSTM_model_path = \"./lstm_codes/lstm_models/lstm_section_1.pth\"  # Change this to your specific model file\n",
        "\n",
        "# Load the trained model\n",
        "LSTM_model = ComplexLSTMModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout_rate=dropout_rate).to(device)\n",
        "LSTM_model.load_state_dict(torch.load(LSTM_model_path, map_location=torch.device('cpu')))\n",
        "LSTM_model.eval()\n",
        "\n",
        "# Define loss function\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss = 0.0\n",
        "test_mae = 0.0\n",
        "all_true = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        outputs = LSTM_model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        mae = torch.mean(torch.abs(outputs - y_batch))\n",
        "\n",
        "        test_loss += loss.item() * X_batch.size(0)\n",
        "        test_mae += mae.item() * X_batch.size(0)\n",
        "\n",
        "        all_true.extend(y_batch.cpu().numpy())\n",
        "        all_preds.extend(outputs.cpu().numpy())\n",
        "\n",
        "# Compute final metrics\n",
        "test_loss /= len(test_loader.dataset)\n",
        "test_mae /= len(test_loader.dataset)\n",
        "\n",
        "# Compute error percentages\n",
        "all_true = np.array(all_true).flatten()\n",
        "all_preds = np.array(all_preds).flatten()\n",
        "error = np.abs(all_true - all_preds) / (np.abs(all_true) + 1e-8)\n",
        "avg_error = np.mean(error) * 100\n",
        "largest_error = np.max(error) * 100\n",
        "\n",
        "# Print results\n",
        "print(\"\\n===== Evaluation Results =====\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test MAE: {test_mae:.4f}\")\n",
        "print(f\"Average Error Percentage: {avg_error:.2f}%\")\n",
        "print(f\"Largest Error Percentage: {largest_error:.2f}%\")\n",
        "\n",
        "# Plot actual vs predicted values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(all_true, label='True Values', color='blue')\n",
        "plt.plot(all_preds, label='Predicted Values', color='red')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Actual vs. Predicted Values')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DysuppZ-PbgU"
      },
      "source": [
        "<span style=\"color: yellow; font-size: 40px;\">Evaluating original autoencoder</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 422,
      "metadata": {
        "id": "Brigs17kPbgV"
      },
      "outputs": [],
      "source": [
        "X_train = X_scaled[:train_size]\n",
        "X_val = X_scaled[train_size:train_size + val_size]\n",
        "X_test = X_scaled[train_size + val_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 423,
      "metadata": {
        "id": "FsfRmB9wPbgV"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.values\n",
        "X_val = X_val.values\n",
        "X_test = X_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 424,
      "metadata": {
        "id": "n68TZ3ptPbgV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, X_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, X_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 425,
      "metadata": {
        "id": "hcUQ1lGxPbgW"
      },
      "outputs": [],
      "source": [
        "input_dim = X_train.shape[1]\n",
        "\n",
        "# Hyperparameters\n",
        "encoding_dim = 5\n",
        "learning_rate = 0.0005\n",
        "dropout_rate = 0.3\n",
        "epochs = 750\n",
        "batch_size = 16\n",
        "patience = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 426,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RSUrM-XPbgW",
        "outputId": "ad552c26-b370-468b-e786-5db214181efb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-426-163b13d6c5bf>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  autoencoder_model.load_state_dict(torch.load(autoencoder_model_path, map_location=torch.device('cpu')))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 426
        }
      ],
      "source": [
        "autoencoder_model_path = \"./autoencoder_codes/autoencoder_models/autoencoder_section_1.pth\"\n",
        "autoencoder_model = Autoencoder(input_dim=input_dim, encoding_dim=encoding_dim, dropout_rate=dropout_rate).to(device)\n",
        "autoencoder_model.load_state_dict(torch.load(autoencoder_model_path, map_location=torch.device('cpu')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 427,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib1Drdq-PbgW",
        "outputId": "60d28a9e-ffec-4a62-8ce1-6ac398ce26dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.0016, MAE: 0.0273, REE: 0.0377, Euclidean Distance: 0.1188, Average Error: 2.8993%\n"
          ]
        }
      ],
      "source": [
        "autoencoder_model.eval()\n",
        "with torch.no_grad():\n",
        "    reconstructed_test = autoencoder_model(torch.tensor(X_test, dtype=torch.float32).to(device)).cpu().numpy()\n",
        "mse = np.mean((X_test - reconstructed_test) ** 2)\n",
        "mae = np.mean(np.abs(X_test - reconstructed_test))\n",
        "ree = np.mean(np.linalg.norm(X_test - reconstructed_test, axis=1) / np.linalg.norm(X_test, axis=1))\n",
        "euclidean_dist = np.mean([norm(X_test[i] - reconstructed_test[i]) for i in range(len(X_test))])\n",
        "reconstruction_error_percentage = (\n",
        "    np.mean(np.abs(X_test - reconstructed_test) / (np.abs(X_test) + 1e-8), axis=1) * 100\n",
        ")\n",
        "average_error = np.mean(reconstruction_error_percentage)\n",
        "print(f'MSE: {mse:.4f}, MAE: {mae:.4f}, REE: {ree:.4f}, Euclidean Distance: {euclidean_dist:.4f}, Average Error: {average_error:.4f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 428,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "qQfQI-4iPbgW",
        "outputId": "2efe7a59-2d12-4bd2-ec21-ee831cae9757"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Scatter plot of reconstruction error percentage\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(range(len(reconstruction_error_percentage)), reconstruction_error_percentage, alpha=0.5)\n",
        "plt.ylim(0, 50)\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Reconstruction Error Percentage')\n",
        "plt.title('Reconstruction Error Percentage')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jJwk1fLPbgY"
      },
      "source": [
        "<span style=\"color: yellow; font-size: 40px;\">Bias correction model - single input</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 429,
      "metadata": {
        "id": "uNOyKDulPbgY"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class BiasPredictor(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size1, dropout_rate):\n",
        "#         super(BiasPredictor, self).__init__()\n",
        "\n",
        "#         hidden_size2 = hidden_size1 // 2\n",
        "#         hidden_size3 = hidden_size2 // 2\n",
        "#         hidden_size4 = hidden_size3 // 2  # New additional layer\n",
        "\n",
        "#         self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "#         self.dropout1 = nn.Dropout(dropout_rate)\n",
        "\n",
        "#         self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "#         self.dropout2 = nn.Dropout(dropout_rate)\n",
        "\n",
        "#         self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
        "#         self.dropout3 = nn.Dropout(dropout_rate)\n",
        "\n",
        "#         self.fc4 = nn.Linear(hidden_size3, hidden_size4)  # New additional layer\n",
        "#         self.dropout4 = nn.Dropout(dropout_rate)\n",
        "\n",
        "#         self.fc5 = nn.Linear(hidden_size4, 1)  # Final output layer\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = self.dropout1(x)\n",
        "\n",
        "#         x = F.relu(self.fc2(x))\n",
        "#         x = self.dropout2(x)\n",
        "\n",
        "#         x = F.relu(self.fc3(x))\n",
        "#         x = self.dropout3(x)\n",
        "\n",
        "#         x = F.relu(self.fc4(x))  # New layer\n",
        "#         x = self.dropout4(x)\n",
        "\n",
        "#         return self.fc5(x)\n",
        "\n",
        "##################################################################\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class BiasPredictor(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size, dropout_rate):\n",
        "#         super(BiasPredictor, self).__init__()\n",
        "\n",
        "#         # Calculate progressively halved hidden sizes\n",
        "#         hidden_size2 = hidden_size // 2\n",
        "#         hidden_size3 = hidden_size2 // 2\n",
        "\n",
        "#         # Define layers\n",
        "#         self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "#         self.dropout1 = nn.Dropout(dropout_rate)\n",
        "\n",
        "#         self.fc2 = nn.Linear(hidden_size, hidden_size2)\n",
        "#         self.dropout2 = nn.Dropout(dropout_rate)\n",
        "\n",
        "#         self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
        "#         self.dropout3 = nn.Dropout(dropout_rate)\n",
        "\n",
        "#         self.fc4 = nn.Linear(hidden_size3, 1)  # Final output layer\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = self.dropout1(x)\n",
        "\n",
        "#         x = F.relu(self.fc2(x))\n",
        "#         x = self.dropout2(x)\n",
        "\n",
        "#         x = F.relu(self.fc3(x))\n",
        "#         x = self.dropout3(x)\n",
        "\n",
        "#         return self.fc4(x)  # Output layer without activation\n",
        "\n",
        "##################################################################\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BiasPredictor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_rate):\n",
        "        super(BiasPredictor, self).__init__()\n",
        "\n",
        "        # Calculate progressively halved hidden sizes\n",
        "        hidden_size2 = hidden_size // 2\n",
        "\n",
        "        # Define layers\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size2)\n",
        "        self.dropout2 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.fc3 = nn.Linear(hidden_size2, 1)  # Final output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        return self.fc3(x)  # Output layer without activation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 430,
      "metadata": {
        "id": "8HSuPOWePbgY"
      },
      "outputs": [],
      "source": [
        "# Get LSTM predictions of entire dataset\n",
        "with torch.no_grad():\n",
        "    X_tensor = torch.tensor(X_seq, dtype=torch.float32).to(device)\n",
        "    LSTM_preds = LSTM_model(X_tensor).cpu().numpy()\n",
        "\n",
        "# Put LSTM predictions into a new DataFrame\n",
        "new_df = pd.DataFrame(LSTM_preds, columns=[\"LSTM_Pred\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 431,
      "metadata": {
        "id": "Uj-dqer8PbgY"
      },
      "outputs": [],
      "source": [
        "# Drop the first sequence_length rows\n",
        "temp_y = y\n",
        "temp_y = temp_y[sequence_length:]\n",
        "\n",
        "# add the target variable to the new DataFrame\n",
        "new_df[\"Target\"] = temp_y.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 432,
      "metadata": {
        "id": "ZoOyqfK_PbgZ"
      },
      "outputs": [],
      "source": [
        "# Get reconstruction error percentage for the entire dataset\n",
        "autoencoder_model.eval()\n",
        "with torch.no_grad():\n",
        "    reconstructed = autoencoder_model(torch.tensor(X_scaled.values, dtype=torch.float32).to(device)).cpu().numpy()\n",
        "\n",
        "# Compute the MAE\n",
        "reconstruction_error = np.mean(np.abs(X_scaled.values - reconstructed), axis=1)\n",
        "\n",
        "# Compute the reconstruction error percentage\n",
        "# reconstruction_error = np.mean(np.abs(X_scaled.values - reconstructed) / (np.abs(X_scaled.values) + 1e-8), axis=1) * 100\n",
        "# reconstruction_error = np.mean((X_scaled.values - reconstructed) / ((X_scaled.values) + 1e-8), axis=1) * 100\n",
        "\n",
        "# Drop the first sequence_length rows\n",
        "reconstruction_error_new = reconstruction_error[sequence_length:]\n",
        "\n",
        "# Add the reconstruction error to the new DataFrame\n",
        "new_df[\"Reconstruction_error_single\"] = reconstruction_error_new\n",
        "\n",
        "# Get reconstruction error arr of past 10 days\n",
        "reconstruction_error_arr = []\n",
        "for i in range(sequence_length, len(reconstruction_error)):\n",
        "    reconstruction_error_arr.append(reconstruction_error[i - sequence_length:i])\n",
        "\n",
        "\n",
        "# Add the reconstruction error array to the new DataFrame\n",
        "new_df[\"Reconstruction_error_arr\"] = reconstruction_error_arr\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "d1h2wYSfPbgZ",
        "outputId": "0ae1b049-762f-4420-aaf5-479461fabf57"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot reconstruction error scatter plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(range(len(reconstruction_error)), reconstruction_error, alpha=0.5)\n",
        "plt.ylim(0, 0.5)\n",
        "plt.xlabel('Sample')\n",
        "# plt.ylabel('Reconstruction Error Percentage')\n",
        "# plt.title('Reconstruction Error Percentage')\n",
        "plt.ylabel('Reconstruction Error MAE')\n",
        "plt.title('Reconstruction Error MAE')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 434,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpaba2jsPbgZ",
        "outputId": "3534455d-1aa7-4d51-fbe5-24d1c20dfaaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00189878, 0.00180704, 0.00187237, 0.00172222, 0.00195921,\n",
              "       0.00198496, 0.00210325, 0.00231761, 0.00201488, 0.00175625])"
            ]
          },
          "metadata": {},
          "execution_count": 434
        }
      ],
      "source": [
        "reconstruction_error_arr[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {
        "id": "cK-bJ5TuPbga"
      },
      "outputs": [],
      "source": [
        "# Calculate the difference between the target and LSTM prediction\n",
        "new_df[\"Bias\"] = new_df[\"Target\"] - new_df[\"LSTM_Pred\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 436,
      "metadata": {
        "id": "ZOk4bQp6Pbga"
      },
      "outputs": [],
      "source": [
        "y = new_df[\"Bias\"]\n",
        "X = new_df[\"Reconstruction_error_single\"]\n",
        "# X = new_df[\"Reconstruction_error_arr\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sckHEj-UPbga",
        "outputId": "818e8258-0dab-403a-bd17-a24819eb4c43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1413, Val: 302, Test: 304\n"
          ]
        }
      ],
      "source": [
        "# Sequential split\n",
        "train_size = int(0.7 * len(X))\n",
        "val_size = int(0.15 * len(X))\n",
        "\n",
        "X_train_raw = X[:train_size]\n",
        "y_train_raw = y[:train_size]\n",
        "X_val_raw = X[train_size:train_size + val_size]\n",
        "y_val_raw = y[train_size:train_size + val_size]\n",
        "X_test_raw = X[train_size + val_size:]\n",
        "y_test_raw = y[train_size + val_size:]\n",
        "\n",
        "# Scale using StandardScaler (fit only on train data)\n",
        "# X_scaler = StandardScaler()\n",
        "X_scaler = RobustScaler()\n",
        "X_train_scaled = X_scaler.fit_transform(X_train_raw.values.reshape(-1, 1))\n",
        "X_val_scaled = X_scaler.transform(X_val_raw.values.reshape(-1, 1))\n",
        "X_test_scaled = X_scaler.transform(X_test_raw.values.reshape(-1, 1))\n",
        "\n",
        "# y_scaler = StandardScaler()\n",
        "y_scaler = RobustScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train_raw.values.reshape(-1, 1))\n",
        "y_val_scaled = y_scaler.transform(y_val_raw.values.reshape(-1, 1))\n",
        "y_test_scaled = y_scaler.transform(y_test_raw.values.reshape(-1, 1))\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train_scaled, dtype=torch.float32).unsqueeze(1)\n",
        "y_train = torch.tensor(y_train_scaled, dtype=torch.float32).unsqueeze(1)\n",
        "X_val = torch.tensor(X_val_scaled, dtype=torch.float32).unsqueeze(1)\n",
        "y_val = torch.tensor(y_val_scaled, dtype=torch.float32).unsqueeze(1)\n",
        "X_test = torch.tensor(X_test_scaled, dtype=torch.float32).unsqueeze(1)\n",
        "y_test = torch.tensor(y_test_scaled, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Print sizes\n",
        "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 438,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KQrET0zPbgb",
        "outputId": "4257c71a-865f-425b-f5e1-ffdbdf56a706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Running 1/81: H=32, D=0.0, LR=0.0001, B=8\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.9474, Val Loss = 6.3899\n",
            "     Epoch 5: Train Loss = 0.7377, Val Loss = 12.7133\n",
            "     Epoch 10: Train Loss = 0.7185, Val Loss = 15.4448\n",
            "     Epoch 15: Train Loss = 0.7170, Val Loss = 15.7660\n",
            "     Epoch 20: Train Loss = 0.7169, Val Loss = 15.6111\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 6.3899\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2606%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7804, Val Loss = 9.7976\n",
            "     Epoch 5: Train Loss = 0.7205, Val Loss = 14.4448\n",
            "     Epoch 10: Train Loss = 0.7173, Val Loss = 15.2802\n",
            "     Epoch 15: Train Loss = 0.7164, Val Loss = 14.9517\n",
            "     Epoch 20: Train Loss = 0.7162, Val Loss = 14.9322\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 9.7976\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0715%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.9082, Val Loss = 6.4048\n",
            "     Epoch 5: Train Loss = 0.7383, Val Loss = 12.7513\n",
            "     Epoch 10: Train Loss = 0.7202, Val Loss = 15.3296\n",
            "     Epoch 15: Train Loss = 0.7177, Val Loss = 15.5505\n",
            "     Epoch 20: Train Loss = 0.7169, Val Loss = 15.5170\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 6.4048\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2126%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8030, Val Loss = 7.0708\n",
            "     Epoch 5: Train Loss = 0.7304, Val Loss = 10.7414\n",
            "     Epoch 10: Train Loss = 0.7189, Val Loss = 11.8887\n",
            "     Epoch 15: Train Loss = 0.7168, Val Loss = 11.7897\n",
            "     Epoch 20: Train Loss = 0.7170, Val Loss = 11.9942\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 7.0708\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.3375%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8042, Val Loss = 5.6105\n",
            "     Epoch 5: Train Loss = 0.7539, Val Loss = 6.5498\n",
            "     Epoch 10: Train Loss = 0.7309, Val Loss = 7.9045\n",
            "     Epoch 15: Train Loss = 0.7207, Val Loss = 9.2558\n",
            "     Epoch 20: Train Loss = 0.7174, Val Loss = 10.2610\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 5.6105\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.1413%\n",
            " Finished configuration H=32, D=0.0, LR=0.0001, B=8 → Avg Val Loss: 7.0547, Avg Accuracy: 3.8047%\n",
            "\n",
            " Running 2/81: H=32, D=0.0, LR=0.0001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8005, Val Loss = 6.5120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7428, Val Loss = 8.9997\n",
            "     Epoch 10: Train Loss = 0.7238, Val Loss = 11.0223\n",
            "     Epoch 15: Train Loss = 0.7193, Val Loss = 12.0748\n",
            "     Epoch 20: Train Loss = 0.7180, Val Loss = 12.3747\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 6.5120\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4109%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8381, Val Loss = 5.6617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7551, Val Loss = 7.3739\n",
            "     Epoch 10: Train Loss = 0.7266, Val Loss = 9.1561\n",
            "     Epoch 15: Train Loss = 0.7189, Val Loss = 10.4486\n",
            "     Epoch 20: Train Loss = 0.7171, Val Loss = 11.2569\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 5.6617\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2253%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.9774, Val Loss = 5.5641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7663, Val Loss = 9.2404\n",
            "     Epoch 10: Train Loss = 0.7279, Val Loss = 12.4941\n",
            "     Epoch 15: Train Loss = 0.7196, Val Loss = 14.2909\n",
            "     Epoch 20: Train Loss = 0.7175, Val Loss = 14.7204\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 5.5641\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0108%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8657, Val Loss = 5.3789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7679, Val Loss = 7.7831\n",
            "     Epoch 10: Train Loss = 0.7290, Val Loss = 10.6485\n",
            "     Epoch 15: Train Loss = 0.7208, Val Loss = 12.1238\n",
            "     Epoch 20: Train Loss = 0.7182, Val Loss = 12.3953\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 5.3789\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4590%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8389, Val Loss = 5.5296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7390, Val Loss = 8.2589\n",
            "     Epoch 10: Train Loss = 0.7199, Val Loss = 10.4628\n",
            "     Epoch 15: Train Loss = 0.7178, Val Loss = 11.3467\n",
            "     Epoch 20: Train Loss = 0.7170, Val Loss = 11.7247\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 5.5296\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2795%\n",
            " Finished configuration H=32, D=0.0, LR=0.0001, B=16 → Avg Val Loss: 5.7293, Avg Accuracy: 3.4771%\n",
            "\n",
            " Running 3/81: H=32, D=0.0, LR=0.0001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 1.0618, Val Loss = 5.3140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.8354, Val Loss = 6.6167\n",
            "     Epoch 10: Train Loss = 0.7429, Val Loss = 9.9279\n",
            "     Epoch 15: Train Loss = 0.7218, Val Loss = 12.7270\n",
            "     Epoch 20: Train Loss = 0.7180, Val Loss = 13.6445\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 5.3140\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7132%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8465, Val Loss = 6.2366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7583, Val Loss = 8.7520\n",
            "     Epoch 10: Train Loss = 0.7291, Val Loss = 10.9253\n",
            "     Epoch 15: Train Loss = 0.7203, Val Loss = 12.3344\n",
            "     Epoch 20: Train Loss = 0.7174, Val Loss = 12.9105\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 6.2366\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5546%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8306, Val Loss = 6.1167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7514, Val Loss = 7.3425\n",
            "     Epoch 10: Train Loss = 0.7273, Val Loss = 8.7878\n",
            "     Epoch 15: Train Loss = 0.7191, Val Loss = 10.0652\n",
            "     Epoch 20: Train Loss = 0.7169, Val Loss = 10.8027\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 6.1167\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2067%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8183, Val Loss = 7.0959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7625, Val Loss = 8.1282\n",
            "     Epoch 10: Train Loss = 0.7364, Val Loss = 9.4098\n",
            "     Epoch 15: Train Loss = 0.7241, Val Loss = 10.4207\n",
            "     Epoch 20: Train Loss = 0.7192, Val Loss = 11.2166\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 7.0959\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2274%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7668, Val Loss = 9.3242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7365, Val Loss = 11.0874\n",
            "     Epoch 10: Train Loss = 0.7245, Val Loss = 12.3476\n",
            "     Epoch 15: Train Loss = 0.7204, Val Loss = 12.9284\n",
            "     Epoch 20: Train Loss = 0.7187, Val Loss = 13.5314\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 9.3242\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6936%\n",
            " Finished configuration H=32, D=0.0, LR=0.0001, B=32 → Avg Val Loss: 6.8175, Avg Accuracy: 3.4791%\n",
            "\n",
            " Running 4/81: H=32, D=0.0, LR=0.0005, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7593, Val Loss = 13.3517\n",
            "     Epoch 5: Train Loss = 0.7183, Val Loss = 14.5851\n",
            "     Epoch 10: Train Loss = 0.7179, Val Loss = 14.6066\n",
            "     Epoch 15: Train Loss = 0.7165, Val Loss = 14.5224\n",
            "     Epoch 20: Train Loss = 0.7163, Val Loss = 14.9695\n",
            "     Epoch 25: Train Loss = 0.7149, Val Loss = 15.0105\n",
            "     Epoch 30: Train Loss = 0.7147, Val Loss = 16.3942\n",
            "     Epoch 35: Train Loss = 0.7140, Val Loss = 16.5540\n",
            "    ⏹️ Early stopping at epoch 36\n",
            " Run 1 finished with best val loss: 13.2856\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.7371%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7618, Val Loss = 11.6834\n",
            "     Epoch 5: Train Loss = 0.7176, Val Loss = 12.1871\n",
            "     Epoch 10: Train Loss = 0.7177, Val Loss = 13.1407\n",
            "     Epoch 15: Train Loss = 0.7163, Val Loss = 12.3580\n",
            "     Epoch 20: Train Loss = 0.7150, Val Loss = 13.8810\n",
            "     Epoch 25: Train Loss = 0.7151, Val Loss = 12.5183\n",
            "     Epoch 30: Train Loss = 0.7160, Val Loss = 14.0119\n",
            "    ⏹️ Early stopping at epoch 34\n",
            " Run 2 finished with best val loss: 10.7198\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9285%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7564, Val Loss = 11.2682\n",
            "     Epoch 5: Train Loss = 0.7192, Val Loss = 12.8728\n",
            "     Epoch 10: Train Loss = 0.7164, Val Loss = 13.5911\n",
            "     Epoch 15: Train Loss = 0.7181, Val Loss = 13.4701\n",
            "     Epoch 20: Train Loss = 0.7168, Val Loss = 12.9640\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 11.2682\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5970%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7834, Val Loss = 9.1369\n",
            "     Epoch 5: Train Loss = 0.7165, Val Loss = 12.7853\n",
            "     Epoch 10: Train Loss = 0.7169, Val Loss = 12.4249\n",
            "     Epoch 15: Train Loss = 0.7164, Val Loss = 12.4733\n",
            "     Epoch 20: Train Loss = 0.7157, Val Loss = 13.6435\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 9.1369\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7038%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7850, Val Loss = 14.5522\n",
            "     Epoch 5: Train Loss = 0.7187, Val Loss = 16.2558\n",
            "     Epoch 10: Train Loss = 0.7186, Val Loss = 15.4888\n",
            "     Epoch 15: Train Loss = 0.7191, Val Loss = 15.0570\n",
            "     Epoch 20: Train Loss = 0.7177, Val Loss = 15.2024\n",
            "     Epoch 25: Train Loss = 0.7175, Val Loss = 16.2069\n",
            "    ⏹️ Early stopping at epoch 28\n",
            " Run 5 finished with best val loss: 13.9994\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2936%\n",
            " Finished configuration H=32, D=0.0, LR=0.0005, B=8 → Avg Val Loss: 11.6820, Avg Accuracy: 4.0520%\n",
            "\n",
            " Running 5/81: H=32, D=0.0, LR=0.0005, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8671, Val Loss = 7.7386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7178, Val Loss = 14.3465\n",
            "     Epoch 10: Train Loss = 0.7163, Val Loss = 14.2364\n",
            "     Epoch 15: Train Loss = 0.7164, Val Loss = 14.9041\n",
            "     Epoch 20: Train Loss = 0.7156, Val Loss = 15.2020\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 7.7386\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1153%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8056, Val Loss = 9.5514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7180, Val Loss = 12.4497\n",
            "     Epoch 10: Train Loss = 0.7185, Val Loss = 11.9807\n",
            "     Epoch 15: Train Loss = 0.7163, Val Loss = 11.9049\n",
            "     Epoch 20: Train Loss = 0.7163, Val Loss = 12.0967\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 9.5514\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.3650%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8364, Val Loss = 9.9516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7180, Val Loss = 14.4065\n",
            "     Epoch 10: Train Loss = 0.7177, Val Loss = 14.7940\n",
            "     Epoch 15: Train Loss = 0.7166, Val Loss = 14.9255\n",
            "     Epoch 20: Train Loss = 0.7152, Val Loss = 15.0953\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 9.9516\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1511%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7572, Val Loss = 7.8684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7171, Val Loss = 11.2302\n",
            "     Epoch 10: Train Loss = 0.7157, Val Loss = 12.2947\n",
            "     Epoch 15: Train Loss = 0.7147, Val Loss = 13.7716\n",
            "     Epoch 20: Train Loss = 0.7143, Val Loss = 13.8239\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 7.8684\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7913%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7806, Val Loss = 10.5192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7185, Val Loss = 14.8638\n",
            "     Epoch 10: Train Loss = 0.7181, Val Loss = 14.9916\n",
            "     Epoch 15: Train Loss = 0.7153, Val Loss = 14.0614\n",
            "     Epoch 20: Train Loss = 0.7152, Val Loss = 14.2883\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 10.5192\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9844%\n",
            " Finished configuration H=32, D=0.0, LR=0.0005, B=16 → Avg Val Loss: 9.1258, Avg Accuracy: 3.8814%\n",
            "\n",
            " Running 6/81: H=32, D=0.0, LR=0.0005, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7670, Val Loss = 12.7496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7265, Val Loss = 15.6306\n",
            "     Epoch 10: Train Loss = 0.7203, Val Loss = 13.1219\n",
            "     Epoch 15: Train Loss = 0.7176, Val Loss = 13.1674\n",
            "     Epoch 20: Train Loss = 0.7158, Val Loss = 12.9990\n",
            "     Epoch 25: Train Loss = 0.7162, Val Loss = 11.5006\n",
            "     Epoch 30: Train Loss = 0.7178, Val Loss = 12.1232\n",
            "     Epoch 35: Train Loss = 0.7160, Val Loss = 12.6858\n",
            "     Epoch 40: Train Loss = 0.7153, Val Loss = 12.7196\n",
            "     Epoch 45: Train Loss = 0.7155, Val Loss = 12.6558\n",
            "    ⏹️ Early stopping at epoch 45\n",
            " Run 1 finished with best val loss: 11.5006\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5068%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8574, Val Loss = 7.8487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7174, Val Loss = 14.7526\n",
            "     Epoch 10: Train Loss = 0.7171, Val Loss = 13.7661\n",
            "     Epoch 15: Train Loss = 0.7158, Val Loss = 13.8581\n",
            "     Epoch 20: Train Loss = 0.7157, Val Loss = 13.5000\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 7.8487\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6953%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8074, Val Loss = 6.7174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7171, Val Loss = 10.5906\n",
            "     Epoch 10: Train Loss = 0.7166, Val Loss = 11.1098\n",
            "     Epoch 15: Train Loss = 0.7168, Val Loss = 11.0258\n",
            "     Epoch 20: Train Loss = 0.7185, Val Loss = 11.3787\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 6.7174\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2582%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7917, Val Loss = 12.8384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7214, Val Loss = 16.9469\n",
            "     Epoch 10: Train Loss = 0.7182, Val Loss = 15.3259\n",
            "     Epoch 15: Train Loss = 0.7167, Val Loss = 14.3790\n",
            "     Epoch 20: Train Loss = 0.7155, Val Loss = 14.0549\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 12.8384\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8685%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.9397, Val Loss = 6.3268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7188, Val Loss = 15.2163\n",
            "     Epoch 10: Train Loss = 0.7175, Val Loss = 14.0673\n",
            "     Epoch 15: Train Loss = 0.7164, Val Loss = 13.9504\n",
            "     Epoch 20: Train Loss = 0.7158, Val Loss = 14.2136\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 6.3268\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8553%\n",
            " Finished configuration H=32, D=0.0, LR=0.0005, B=32 → Avg Val Loss: 9.0464, Avg Accuracy: 3.6368%\n",
            "\n",
            " Running 7/81: H=32, D=0.0, LR=0.001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7793, Val Loss = 11.5457\n",
            "     Epoch 5: Train Loss = 0.7207, Val Loss = 13.8252\n",
            "     Epoch 10: Train Loss = 0.7183, Val Loss = 14.4024\n",
            "     Epoch 15: Train Loss = 0.7179, Val Loss = 16.1656\n",
            "     Epoch 20: Train Loss = 0.7190, Val Loss = 19.5474\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 11.5457\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.3045%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7438, Val Loss = 15.8077\n",
            "     Epoch 5: Train Loss = 0.7222, Val Loss = 14.3236\n",
            "     Epoch 10: Train Loss = 0.7184, Val Loss = 14.0929\n",
            "     Epoch 15: Train Loss = 0.7202, Val Loss = 13.8376\n",
            "     Epoch 20: Train Loss = 0.7209, Val Loss = 12.8978\n",
            "     Epoch 25: Train Loss = 0.7177, Val Loss = 12.6696\n",
            "     Epoch 30: Train Loss = 0.7168, Val Loss = 14.5876\n",
            "    ⏹️ Early stopping at epoch 31\n",
            " Run 2 finished with best val loss: 11.7796\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7060%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7406, Val Loss = 12.4310\n",
            "     Epoch 5: Train Loss = 0.7198, Val Loss = 11.8016\n",
            "     Epoch 10: Train Loss = 0.7177, Val Loss = 13.8736\n",
            "     Epoch 15: Train Loss = 0.7172, Val Loss = 12.7548\n",
            "     Epoch 20: Train Loss = 0.7164, Val Loss = 12.9645\n",
            "    ⏹️ Early stopping at epoch 24\n",
            " Run 3 finished with best val loss: 11.5533\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7770%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7592, Val Loss = 9.1733\n",
            "     Epoch 5: Train Loss = 0.7184, Val Loss = 11.3267\n",
            "     Epoch 10: Train Loss = 0.7176, Val Loss = 10.9120\n",
            "     Epoch 15: Train Loss = 0.7168, Val Loss = 13.2880\n",
            "     Epoch 20: Train Loss = 0.7168, Val Loss = 12.8066\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 9.1733\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4687%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7797, Val Loss = 14.1746\n",
            "     Epoch 5: Train Loss = 0.7195, Val Loss = 11.9285\n",
            "     Epoch 10: Train Loss = 0.7186, Val Loss = 12.9627\n",
            "     Epoch 15: Train Loss = 0.7188, Val Loss = 13.4817\n",
            "     Epoch 20: Train Loss = 0.7172, Val Loss = 13.4717\n",
            "     Epoch 25: Train Loss = 0.7182, Val Loss = 13.3974\n",
            "    ⏹️ Early stopping at epoch 29\n",
            " Run 5 finished with best val loss: 11.5892\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8611%\n",
            " Finished configuration H=32, D=0.0, LR=0.001, B=8 → Avg Val Loss: 11.1282, Avg Accuracy: 4.0235%\n",
            "\n",
            " Running 8/81: H=32, D=0.0, LR=0.001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7653, Val Loss = 15.3241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7181, Val Loss = 12.8819\n",
            "     Epoch 10: Train Loss = 0.7191, Val Loss = 13.1812\n",
            "     Epoch 15: Train Loss = 0.7164, Val Loss = 14.0044\n",
            "     Epoch 20: Train Loss = 0.7161, Val Loss = 14.4578\n",
            "     Epoch 25: Train Loss = 0.7145, Val Loss = 15.1570\n",
            "    ⏹️ Early stopping at epoch 25\n",
            " Run 1 finished with best val loss: 12.8819\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1893%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7613, Val Loss = 11.6134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7188, Val Loss = 12.5067\n",
            "     Epoch 10: Train Loss = 0.7165, Val Loss = 12.5303\n",
            "     Epoch 15: Train Loss = 0.7158, Val Loss = 13.3130\n",
            "     Epoch 20: Train Loss = 0.7157, Val Loss = 13.3108\n",
            "     Epoch 25: Train Loss = 0.7166, Val Loss = 13.6139\n",
            "    ⏹️ Early stopping at epoch 27\n",
            " Run 2 finished with best val loss: 11.0633\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7530%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7926, Val Loss = 14.0304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7162, Val Loss = 16.1830\n",
            "     Epoch 10: Train Loss = 0.7175, Val Loss = 15.3988\n",
            "     Epoch 15: Train Loss = 0.7171, Val Loss = 14.9452\n",
            "     Epoch 20: Train Loss = 0.7158, Val Loss = 15.9906\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 3 finished with best val loss: 13.7516\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.0182%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7397, Val Loss = 12.2913\n",
            "     Epoch 5: Train Loss = 0.7206, Val Loss = 12.9005\n",
            "     Epoch 10: Train Loss = 0.7169, Val Loss = 14.9312\n",
            "     Epoch 15: Train Loss = 0.7170, Val Loss = 14.5825\n",
            "     Epoch 20: Train Loss = 0.7188, Val Loss = 15.1343\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 4 finished with best val loss: 11.3989\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.5537%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8027, Val Loss = 11.8752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7189, Val Loss = 12.9412\n",
            "     Epoch 10: Train Loss = 0.7180, Val Loss = 13.8938\n",
            "     Epoch 15: Train Loss = 0.7164, Val Loss = 13.7617\n",
            "     Epoch 20: Train Loss = 0.7168, Val Loss = 14.5117\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 11.8752\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0455%\n",
            " Finished configuration H=32, D=0.0, LR=0.001, B=16 → Avg Val Loss: 12.1942, Avg Accuracy: 4.3119%\n",
            "\n",
            " Running 9/81: H=32, D=0.0, LR=0.001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8118, Val Loss = 11.2976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7186, Val Loss = 11.7064\n",
            "     Epoch 10: Train Loss = 0.7178, Val Loss = 14.8614\n",
            "     Epoch 15: Train Loss = 0.7154, Val Loss = 13.6302\n",
            "     Epoch 20: Train Loss = 0.7201, Val Loss = 13.5603\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 11.2976\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7115%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7722, Val Loss = 11.9077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7183, Val Loss = 12.3079\n",
            "     Epoch 10: Train Loss = 0.7169, Val Loss = 12.4859\n",
            "     Epoch 15: Train Loss = 0.7163, Val Loss = 13.0199\n",
            "     Epoch 20: Train Loss = 0.7165, Val Loss = 13.3139\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 11.9077\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6155%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7827, Val Loss = 13.2240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7198, Val Loss = 12.9727\n",
            "     Epoch 10: Train Loss = 0.7151, Val Loss = 13.7815\n",
            "     Epoch 15: Train Loss = 0.7177, Val Loss = 14.2799\n",
            "     Epoch 20: Train Loss = 0.7155, Val Loss = 14.7365\n",
            "     Epoch 25: Train Loss = 0.7153, Val Loss = 15.6315\n",
            "    ⏹️ Early stopping at epoch 25\n",
            " Run 3 finished with best val loss: 12.9727\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2990%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7504, Val Loss = 10.5354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7175, Val Loss = 12.0501\n",
            "     Epoch 10: Train Loss = 0.7162, Val Loss = 12.6697\n",
            "     Epoch 15: Train Loss = 0.7163, Val Loss = 13.3017\n",
            "     Epoch 20: Train Loss = 0.7149, Val Loss = 13.7769\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 10.5354\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8115%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7781, Val Loss = 8.5091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7191, Val Loss = 11.6867\n",
            "     Epoch 10: Train Loss = 0.7173, Val Loss = 12.1891\n",
            "     Epoch 15: Train Loss = 0.7183, Val Loss = 11.5464\n",
            "     Epoch 20: Train Loss = 0.7167, Val Loss = 12.8777\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 8.5091\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5280%\n",
            " Finished configuration H=32, D=0.0, LR=0.001, B=32 → Avg Val Loss: 11.0445, Avg Accuracy: 3.7931%\n",
            "\n",
            " Running 10/81: H=32, D=0.1, LR=0.0001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8126, Val Loss = 6.9067\n",
            "     Epoch 5: Train Loss = 0.7370, Val Loss = 12.3965\n",
            "     Epoch 10: Train Loss = 0.7317, Val Loss = 13.9616\n",
            "     Epoch 15: Train Loss = 0.7207, Val Loss = 13.7656\n",
            "     Epoch 20: Train Loss = 0.7145, Val Loss = 14.0158\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 6.9067\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8713%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.9434, Val Loss = 6.7166\n",
            "     Epoch 5: Train Loss = 0.7323, Val Loss = 12.9642\n",
            "     Epoch 10: Train Loss = 0.7458, Val Loss = 14.4247\n",
            "     Epoch 15: Train Loss = 0.7268, Val Loss = 14.6741\n",
            "     Epoch 20: Train Loss = 0.7255, Val Loss = 14.5357\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 6.7166\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9485%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8709, Val Loss = 7.5498\n",
            "     Epoch 5: Train Loss = 0.7313, Val Loss = 13.6732\n",
            "     Epoch 10: Train Loss = 0.7255, Val Loss = 14.5334\n",
            "     Epoch 15: Train Loss = 0.7430, Val Loss = 14.1389\n",
            "     Epoch 20: Train Loss = 0.7322, Val Loss = 14.5069\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 7.5498\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0029%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7958, Val Loss = 8.1169\n",
            "     Epoch 5: Train Loss = 0.7401, Val Loss = 12.9852\n",
            "     Epoch 10: Train Loss = 0.7301, Val Loss = 14.1290\n",
            "     Epoch 15: Train Loss = 0.7379, Val Loss = 14.0462\n",
            "     Epoch 20: Train Loss = 0.7281, Val Loss = 14.1499\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 8.1169\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8998%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8345, Val Loss = 6.0148\n",
            "     Epoch 5: Train Loss = 0.7476, Val Loss = 10.5174\n",
            "     Epoch 10: Train Loss = 0.7319, Val Loss = 13.4749\n",
            "     Epoch 15: Train Loss = 0.7210, Val Loss = 13.9753\n",
            "     Epoch 20: Train Loss = 0.7263, Val Loss = 14.0623\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 6.0148\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8335%\n",
            " Finished configuration H=32, D=0.1, LR=0.0001, B=8 → Avg Val Loss: 7.0610, Avg Accuracy: 3.9112%\n",
            "\n",
            " Running 11/81: H=32, D=0.1, LR=0.0001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 1.0033, Val Loss = 5.5025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7584, Val Loss = 12.4275\n",
            "     Epoch 10: Train Loss = 0.7347, Val Loss = 15.4575\n",
            "     Epoch 15: Train Loss = 0.7314, Val Loss = 15.9898\n",
            "     Epoch 20: Train Loss = 0.7363, Val Loss = 15.7298\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 5.5025\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2372%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8125, Val Loss = 6.0619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7544, Val Loss = 7.6940\n",
            "     Epoch 10: Train Loss = 0.7352, Val Loss = 9.2253\n",
            "     Epoch 15: Train Loss = 0.7237, Val Loss = 10.0205\n",
            "     Epoch 20: Train Loss = 0.7188, Val Loss = 10.4746\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 6.0619\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.1483%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8023, Val Loss = 6.6597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7295, Val Loss = 8.8083\n",
            "     Epoch 10: Train Loss = 0.7314, Val Loss = 10.3418\n",
            "     Epoch 15: Train Loss = 0.7231, Val Loss = 11.0581\n",
            "     Epoch 20: Train Loss = 0.7270, Val Loss = 11.3823\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 6.6597\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2766%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8312, Val Loss = 7.1743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7517, Val Loss = 10.7970\n",
            "     Epoch 10: Train Loss = 0.7350, Val Loss = 12.8247\n",
            "     Epoch 15: Train Loss = 0.7406, Val Loss = 13.2652\n",
            "     Epoch 20: Train Loss = 0.7324, Val Loss = 13.2451\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 7.1743\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5762%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7885, Val Loss = 8.2978\n",
            "     Epoch 5: Train Loss = 0.7376, Val Loss = 9.6235\n",
            "     Epoch 10: Train Loss = 0.7194, Val Loss = 10.6070\n",
            "     Epoch 15: Train Loss = 0.7253, Val Loss = 10.8296\n",
            "     Epoch 20: Train Loss = 0.7227, Val Loss = 10.9028\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 8.2978\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.1881%\n",
            " Finished configuration H=32, D=0.1, LR=0.0001, B=16 → Avg Val Loss: 6.7392, Avg Accuracy: 3.4853%\n",
            "\n",
            " Running 12/81: H=32, D=0.1, LR=0.0001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8198, Val Loss = 8.3499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7708, Val Loss = 11.7487\n",
            "     Epoch 10: Train Loss = 0.7486, Val Loss = 14.7042\n",
            "     Epoch 15: Train Loss = 0.7387, Val Loss = 15.8597\n",
            "     Epoch 20: Train Loss = 0.7463, Val Loss = 16.8596\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 8.3499\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.6836%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8451, Val Loss = 6.2953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7827, Val Loss = 8.2281\n",
            "     Epoch 10: Train Loss = 0.7481, Val Loss = 10.4840\n",
            "     Epoch 15: Train Loss = 0.7323, Val Loss = 11.7483\n",
            "     Epoch 20: Train Loss = 0.7257, Val Loss = 12.4382\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 6.2953\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4572%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 1.0578, Val Loss = 5.7216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.8394, Val Loss = 8.2246\n",
            "     Epoch 10: Train Loss = 0.7648, Val Loss = 11.3266\n",
            "     Epoch 15: Train Loss = 0.7384, Val Loss = 13.9480\n",
            "     Epoch 20: Train Loss = 0.7184, Val Loss = 15.8777\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 5.7216\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3300%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7822, Val Loss = 7.8250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7516, Val Loss = 9.1452\n",
            "     Epoch 10: Train Loss = 0.7382, Val Loss = 10.2572\n",
            "     Epoch 15: Train Loss = 0.7266, Val Loss = 11.0287\n",
            "     Epoch 20: Train Loss = 0.7312, Val Loss = 11.3529\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 7.8250\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2628%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8188, Val Loss = 7.3182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7633, Val Loss = 8.5738\n",
            "     Epoch 10: Train Loss = 0.7430, Val Loss = 9.6733\n",
            "     Epoch 15: Train Loss = 0.7348, Val Loss = 10.6658\n",
            "     Epoch 20: Train Loss = 0.7233, Val Loss = 11.4127\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 7.3182\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.3318%\n",
            " Finished configuration H=32, D=0.1, LR=0.0001, B=32 → Avg Val Loss: 7.1020, Avg Accuracy: 3.8131%\n",
            "\n",
            " Running 13/81: H=32, D=0.1, LR=0.0005, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8255, Val Loss = 12.4004\n",
            "     Epoch 5: Train Loss = 0.7266, Val Loss = 15.1155\n",
            "     Epoch 10: Train Loss = 0.7309, Val Loss = 14.3307\n",
            "     Epoch 15: Train Loss = 0.7283, Val Loss = 14.4917\n",
            "     Epoch 20: Train Loss = 0.7117, Val Loss = 15.6368\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 12.4004\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2357%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8415, Val Loss = 11.9798\n",
            "     Epoch 5: Train Loss = 0.7210, Val Loss = 16.7567\n",
            "     Epoch 10: Train Loss = 0.7213, Val Loss = 14.7747\n",
            "     Epoch 15: Train Loss = 0.7218, Val Loss = 13.8511\n",
            "     Epoch 20: Train Loss = 0.7154, Val Loss = 15.6253\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 11.9798\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3702%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7798, Val Loss = 8.8342\n",
            "     Epoch 5: Train Loss = 0.7352, Val Loss = 10.6231\n",
            "     Epoch 10: Train Loss = 0.7333, Val Loss = 10.7736\n",
            "     Epoch 15: Train Loss = 0.7227, Val Loss = 11.3840\n",
            "     Epoch 20: Train Loss = 0.7178, Val Loss = 12.3221\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 8.8342\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4308%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7753, Val Loss = 10.8440\n",
            "     Epoch 5: Train Loss = 0.7236, Val Loss = 13.5513\n",
            "     Epoch 10: Train Loss = 0.7286, Val Loss = 13.9616\n",
            "     Epoch 15: Train Loss = 0.7201, Val Loss = 13.8420\n",
            "     Epoch 20: Train Loss = 0.7250, Val Loss = 14.3510\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 10.8440\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9364%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8206, Val Loss = 11.7874\n",
            "     Epoch 5: Train Loss = 0.7191, Val Loss = 13.3541\n",
            "     Epoch 10: Train Loss = 0.7259, Val Loss = 12.7392\n",
            "     Epoch 15: Train Loss = 0.7231, Val Loss = 12.3287\n",
            "     Epoch 20: Train Loss = 0.7338, Val Loss = 11.6647\n",
            "     Epoch 25: Train Loss = 0.7208, Val Loss = 13.2656\n",
            "     Epoch 30: Train Loss = 0.7201, Val Loss = 12.4928\n",
            "     Epoch 35: Train Loss = 0.7235, Val Loss = 12.1210\n",
            "     Epoch 40: Train Loss = 0.7256, Val Loss = 12.1163\n",
            "    ⏹️ Early stopping at epoch 40\n",
            " Run 5 finished with best val loss: 11.6647\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4227%\n",
            " Finished configuration H=32, D=0.1, LR=0.0005, B=8 → Avg Val Loss: 11.1446, Avg Accuracy: 3.8792%\n",
            "\n",
            " Running 14/81: H=32, D=0.1, LR=0.0005, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8231, Val Loss = 7.4199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7268, Val Loss = 12.7975\n",
            "     Epoch 10: Train Loss = 0.7214, Val Loss = 13.1665\n",
            "     Epoch 15: Train Loss = 0.7212, Val Loss = 13.0594\n",
            "     Epoch 20: Train Loss = 0.7172, Val Loss = 13.6307\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 7.4199\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7504%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7799, Val Loss = 13.0535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7437, Val Loss = 13.6653\n",
            "     Epoch 10: Train Loss = 0.7306, Val Loss = 13.2869\n",
            "     Epoch 15: Train Loss = 0.7284, Val Loss = 14.6365\n",
            "     Epoch 20: Train Loss = 0.7266, Val Loss = 13.3079\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 13.0535\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7624%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 1.0176, Val Loss = 7.9939\n",
            "     Epoch 5: Train Loss = 0.7352, Val Loss = 14.1996\n",
            "     Epoch 10: Train Loss = 0.7275, Val Loss = 13.4898\n",
            "     Epoch 15: Train Loss = 0.7158, Val Loss = 13.4696\n",
            "     Epoch 20: Train Loss = 0.7164, Val Loss = 14.7600\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 7.9939\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0554%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8214, Val Loss = 5.8187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7355, Val Loss = 10.4940\n",
            "     Epoch 10: Train Loss = 0.7213, Val Loss = 11.7240\n",
            "     Epoch 15: Train Loss = 0.7218, Val Loss = 12.6590\n",
            "     Epoch 20: Train Loss = 0.7275, Val Loss = 12.4632\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 5.8187\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4913%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7697, Val Loss = 9.9379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7228, Val Loss = 12.6616\n",
            "     Epoch 10: Train Loss = 0.7262, Val Loss = 12.1623\n",
            "     Epoch 15: Train Loss = 0.7187, Val Loss = 12.5149\n",
            "     Epoch 20: Train Loss = 0.7283, Val Loss = 12.2570\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 9.9379\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4763%\n",
            " Finished configuration H=32, D=0.1, LR=0.0005, B=16 → Avg Val Loss: 8.8448, Avg Accuracy: 3.7071%\n",
            "\n",
            " Running 15/81: H=32, D=0.1, LR=0.0005, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8201, Val Loss = 7.3539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7273, Val Loss = 13.3755\n",
            "     Epoch 10: Train Loss = 0.7222, Val Loss = 13.6835\n",
            "     Epoch 15: Train Loss = 0.7253, Val Loss = 14.4041\n",
            "     Epoch 20: Train Loss = 0.7181, Val Loss = 13.8752\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 7.3539\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8860%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8540, Val Loss = 5.6690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7257, Val Loss = 10.2776\n",
            "     Epoch 10: Train Loss = 0.7216, Val Loss = 11.5375\n",
            "     Epoch 15: Train Loss = 0.7212, Val Loss = 11.4535\n",
            "     Epoch 20: Train Loss = 0.7165, Val Loss = 11.9624\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 5.6690\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.3570%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8005, Val Loss = 10.1541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7286, Val Loss = 14.4437\n",
            "     Epoch 10: Train Loss = 0.7194, Val Loss = 13.8256\n",
            "     Epoch 15: Train Loss = 0.7235, Val Loss = 14.4169\n",
            "     Epoch 20: Train Loss = 0.7257, Val Loss = 14.0684\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 10.1541\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9266%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8455, Val Loss = 7.1760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7417, Val Loss = 13.3739\n",
            "     Epoch 10: Train Loss = 0.7286, Val Loss = 12.7931\n",
            "     Epoch 15: Train Loss = 0.7281, Val Loss = 12.4447\n",
            "     Epoch 20: Train Loss = 0.7269, Val Loss = 12.7826\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 7.1760\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4776%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8562, Val Loss = 6.7031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7320, Val Loss = 12.2417\n",
            "     Epoch 10: Train Loss = 0.7123, Val Loss = 12.1550\n",
            "     Epoch 15: Train Loss = 0.7245, Val Loss = 12.2886\n",
            "     Epoch 20: Train Loss = 0.7238, Val Loss = 12.6504\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 6.7031\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4882%\n",
            " Finished configuration H=32, D=0.1, LR=0.0005, B=32 → Avg Val Loss: 7.4112, Avg Accuracy: 3.6271%\n",
            "\n",
            " Running 16/81: H=32, D=0.1, LR=0.001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7765, Val Loss = 11.0177\n",
            "     Epoch 5: Train Loss = 0.7277, Val Loss = 12.8203\n",
            "     Epoch 10: Train Loss = 0.7184, Val Loss = 12.8304\n",
            "     Epoch 15: Train Loss = 0.7243, Val Loss = 11.6919\n",
            "     Epoch 20: Train Loss = 0.7236, Val Loss = 14.5243\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 11.0177\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9408%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7442, Val Loss = 12.3183\n",
            "     Epoch 5: Train Loss = 0.7263, Val Loss = 12.8773\n",
            "     Epoch 10: Train Loss = 0.7262, Val Loss = 14.5104\n",
            "     Epoch 15: Train Loss = 0.7249, Val Loss = 13.8108\n",
            "     Epoch 20: Train Loss = 0.7145, Val Loss = 14.0056\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 2 finished with best val loss: 11.9425\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3319%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8238, Val Loss = 15.0023\n",
            "     Epoch 5: Train Loss = 0.7309, Val Loss = 13.2546\n",
            "     Epoch 10: Train Loss = 0.7129, Val Loss = 13.2308\n",
            "     Epoch 15: Train Loss = 0.7237, Val Loss = 14.0731\n",
            "     Epoch 20: Train Loss = 0.7223, Val Loss = 14.5424\n",
            "     Epoch 25: Train Loss = 0.7254, Val Loss = 12.6321\n",
            "    ⏹️ Early stopping at epoch 27\n",
            " Run 3 finished with best val loss: 11.9854\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8455%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7540, Val Loss = 10.7073\n",
            "     Epoch 5: Train Loss = 0.7255, Val Loss = 12.3931\n",
            "     Epoch 10: Train Loss = 0.7316, Val Loss = 10.6062\n",
            "     Epoch 15: Train Loss = 0.7130, Val Loss = 12.4337\n",
            "     Epoch 20: Train Loss = 0.7268, Val Loss = 10.9782\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 4 finished with best val loss: 9.8543\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2842%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7708, Val Loss = 15.3395\n",
            "     Epoch 5: Train Loss = 0.7415, Val Loss = 13.3743\n",
            "     Epoch 10: Train Loss = 0.7237, Val Loss = 14.2607\n",
            "     Epoch 15: Train Loss = 0.7259, Val Loss = 16.1920\n",
            "     Epoch 20: Train Loss = 0.7265, Val Loss = 13.4739\n",
            "    ⏹️ Early stopping at epoch 24\n",
            " Run 5 finished with best val loss: 12.1277\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3559%\n",
            " Finished configuration H=32, D=0.1, LR=0.001, B=8 → Avg Val Loss: 11.3855, Avg Accuracy: 3.9517%\n",
            "\n",
            " Running 17/81: H=32, D=0.1, LR=0.001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7571, Val Loss = 12.3737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7213, Val Loss = 12.0622\n",
            "     Epoch 10: Train Loss = 0.7293, Val Loss = 12.3427\n",
            "     Epoch 15: Train Loss = 0.7165, Val Loss = 13.6264\n",
            "     Epoch 20: Train Loss = 0.7214, Val Loss = 14.2490\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 1 finished with best val loss: 11.5490\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6848%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7822, Val Loss = 17.6858\n",
            "     Epoch 5: Train Loss = 0.7291, Val Loss = 14.9116\n",
            "     Epoch 10: Train Loss = 0.7270, Val Loss = 14.7368\n",
            "     Epoch 15: Train Loss = 0.7216, Val Loss = 17.4424\n",
            "     Epoch 20: Train Loss = 0.7256, Val Loss = 17.5642\n",
            "     Epoch 25: Train Loss = 0.7169, Val Loss = 16.0041\n",
            "     Epoch 30: Train Loss = 0.7284, Val Loss = 16.2393\n",
            "    ⏹️ Early stopping at epoch 33\n",
            " Run 2 finished with best val loss: 14.4298\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.0370%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7672, Val Loss = 9.7778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7185, Val Loss = 12.1043\n",
            "     Epoch 10: Train Loss = 0.7187, Val Loss = 12.9563\n",
            "     Epoch 15: Train Loss = 0.7286, Val Loss = 13.9111\n",
            "     Epoch 20: Train Loss = 0.7175, Val Loss = 13.2979\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 9.7778\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7187%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7466, Val Loss = 11.5898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7281, Val Loss = 12.1556\n",
            "     Epoch 10: Train Loss = 0.7187, Val Loss = 12.8199\n",
            "     Epoch 15: Train Loss = 0.7206, Val Loss = 12.3095\n",
            "     Epoch 20: Train Loss = 0.7184, Val Loss = 11.9911\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 4 finished with best val loss: 11.2037\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6793%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7830, Val Loss = 17.4477\n",
            "     Epoch 5: Train Loss = 0.7230, Val Loss = 15.3287\n",
            "     Epoch 10: Train Loss = 0.7334, Val Loss = 13.5988\n",
            "     Epoch 15: Train Loss = 0.7360, Val Loss = 14.2437\n",
            "     Epoch 20: Train Loss = 0.7249, Val Loss = 15.6709\n",
            "     Epoch 25: Train Loss = 0.7227, Val Loss = 16.1815\n",
            "     Epoch 30: Train Loss = 0.7277, Val Loss = 14.7464\n",
            "    ⏹️ Early stopping at epoch 30\n",
            " Run 5 finished with best val loss: 13.5988\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1167%\n",
            " Finished configuration H=32, D=0.1, LR=0.001, B=16 → Avg Val Loss: 12.1118, Avg Accuracy: 4.0473%\n",
            "\n",
            " Running 18/81: H=32, D=0.1, LR=0.001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8019, Val Loss = 8.8999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7258, Val Loss = 12.9160\n",
            "     Epoch 10: Train Loss = 0.7168, Val Loss = 13.7229\n",
            "     Epoch 15: Train Loss = 0.7173, Val Loss = 14.4555\n",
            "     Epoch 20: Train Loss = 0.7196, Val Loss = 14.9051\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 8.8999\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1159%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7815, Val Loss = 7.8047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7174, Val Loss = 10.8032\n",
            "     Epoch 10: Train Loss = 0.7223, Val Loss = 11.3122\n",
            "     Epoch 15: Train Loss = 0.7244, Val Loss = 11.3766\n",
            "     Epoch 20: Train Loss = 0.7251, Val Loss = 11.4065\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 7.8047\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2762%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7842, Val Loss = 8.5946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7331, Val Loss = 13.0924\n",
            "     Epoch 10: Train Loss = 0.7263, Val Loss = 13.6852\n",
            "     Epoch 15: Train Loss = 0.7176, Val Loss = 15.1706\n",
            "     Epoch 20: Train Loss = 0.7266, Val Loss = 14.7388\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 8.5946\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1681%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8013, Val Loss = 10.6891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7223, Val Loss = 15.2979\n",
            "     Epoch 10: Train Loss = 0.7258, Val Loss = 14.6752\n",
            "     Epoch 15: Train Loss = 0.7281, Val Loss = 13.8859\n",
            "     Epoch 20: Train Loss = 0.7203, Val Loss = 15.2988\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 10.6891\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2395%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8547, Val Loss = 13.3121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7319, Val Loss = 15.4311\n",
            "     Epoch 10: Train Loss = 0.7215, Val Loss = 13.6280\n",
            "     Epoch 15: Train Loss = 0.7223, Val Loss = 13.9023\n",
            "     Epoch 20: Train Loss = 0.7303, Val Loss = 13.7571\n",
            "     Epoch 25: Train Loss = 0.7241, Val Loss = 14.6000\n",
            "     Epoch 30: Train Loss = 0.7201, Val Loss = 14.9298\n",
            "     Epoch 35: Train Loss = 0.7219, Val Loss = 15.1086\n",
            "    ⏹️ Early stopping at epoch 39\n",
            " Run 5 finished with best val loss: 13.3045\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2449%\n",
            " Finished configuration H=32, D=0.1, LR=0.001, B=32 → Avg Val Loss: 9.8585, Avg Accuracy: 4.0089%\n",
            "\n",
            " Running 19/81: H=32, D=0.2, LR=0.0001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 1.1041, Val Loss = 5.3912\n",
            "     Epoch 5: Train Loss = 0.7834, Val Loss = 9.1959\n",
            "     Epoch 10: Train Loss = 0.7428, Val Loss = 12.2653\n",
            "     Epoch 15: Train Loss = 0.7504, Val Loss = 13.0934\n",
            "     Epoch 20: Train Loss = 0.7356, Val Loss = 13.4651\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 5.3912\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7633%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 1.0859, Val Loss = 5.8535\n",
            "     Epoch 5: Train Loss = 0.7608, Val Loss = 10.0961\n",
            "     Epoch 10: Train Loss = 0.7410, Val Loss = 11.8203\n",
            "     Epoch 15: Train Loss = 0.7267, Val Loss = 12.7489\n",
            "     Epoch 20: Train Loss = 0.7312, Val Loss = 13.1570\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 5.8535\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6001%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8695, Val Loss = 9.8324\n",
            "     Epoch 5: Train Loss = 0.7607, Val Loss = 17.1381\n",
            "     Epoch 10: Train Loss = 0.7535, Val Loss = 18.2200\n",
            "     Epoch 15: Train Loss = 0.7351, Val Loss = 17.4478\n",
            "     Epoch 20: Train Loss = 0.7441, Val Loss = 16.0320\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 9.8324\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3201%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8300, Val Loss = 8.0555\n",
            "     Epoch 5: Train Loss = 0.7562, Val Loss = 12.8153\n",
            "     Epoch 10: Train Loss = 0.7325, Val Loss = 15.4514\n",
            "     Epoch 15: Train Loss = 0.7348, Val Loss = 15.7476\n",
            "     Epoch 20: Train Loss = 0.7272, Val Loss = 15.4817\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 8.0555\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2132%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8677, Val Loss = 6.3110\n",
            "     Epoch 5: Train Loss = 0.7504, Val Loss = 10.4579\n",
            "     Epoch 10: Train Loss = 0.7523, Val Loss = 11.9761\n",
            "     Epoch 15: Train Loss = 0.7445, Val Loss = 12.3736\n",
            "     Epoch 20: Train Loss = 0.7295, Val Loss = 12.6143\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 6.3110\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5033%\n",
            " Finished configuration H=32, D=0.2, LR=0.0001, B=8 → Avg Val Loss: 7.0887, Avg Accuracy: 3.8800%\n",
            "\n",
            " Running 20/81: H=32, D=0.2, LR=0.0001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.9094, Val Loss = 5.4279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7763, Val Loss = 7.1923\n",
            "     Epoch 10: Train Loss = 0.7457, Val Loss = 8.9271\n",
            "     Epoch 15: Train Loss = 0.7353, Val Loss = 10.3347\n",
            "     Epoch 20: Train Loss = 0.7259, Val Loss = 11.3391\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 5.4279\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2701%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8628, Val Loss = 6.6788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7852, Val Loss = 9.0995\n",
            "     Epoch 10: Train Loss = 0.7428, Val Loss = 11.6869\n",
            "     Epoch 15: Train Loss = 0.7458, Val Loss = 12.8575\n",
            "     Epoch 20: Train Loss = 0.7295, Val Loss = 13.4116\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 6.6788\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7014%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8149, Val Loss = 5.9042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7691, Val Loss = 7.6256\n",
            "     Epoch 10: Train Loss = 0.7434, Val Loss = 9.0018\n",
            "     Epoch 15: Train Loss = 0.7409, Val Loss = 9.9419\n",
            "     Epoch 20: Train Loss = 0.7192, Val Loss = 10.4965\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 5.9042\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.1648%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.9328, Val Loss = 6.0073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.8109, Val Loss = 7.1134\n",
            "     Epoch 10: Train Loss = 0.7438, Val Loss = 8.9390\n",
            "     Epoch 15: Train Loss = 0.7565, Val Loss = 10.4597\n",
            "     Epoch 20: Train Loss = 0.7443, Val Loss = 11.1965\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 6.0073\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2691%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7700, Val Loss = 12.1777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7357, Val Loss = 14.5896\n",
            "     Epoch 10: Train Loss = 0.7369, Val Loss = 15.4861\n",
            "     Epoch 15: Train Loss = 0.7483, Val Loss = 15.7595\n",
            "     Epoch 20: Train Loss = 0.7354, Val Loss = 15.8870\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 12.1777\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3422%\n",
            " Finished configuration H=32, D=0.2, LR=0.0001, B=16 → Avg Val Loss: 7.2392, Avg Accuracy: 3.5495%\n",
            "\n",
            " Running 21/81: H=32, D=0.2, LR=0.0001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.9651, Val Loss = 6.3511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.8116, Val Loss = 8.4890\n",
            "     Epoch 10: Train Loss = 0.7619, Val Loss = 10.4702\n",
            "     Epoch 15: Train Loss = 0.7445, Val Loss = 11.7664\n",
            "     Epoch 20: Train Loss = 0.7584, Val Loss = 12.4496\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 6.3511\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5064%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8678, Val Loss = 6.6494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7735, Val Loss = 9.1391\n",
            "     Epoch 10: Train Loss = 0.7472, Val Loss = 11.4899\n",
            "     Epoch 15: Train Loss = 0.7296, Val Loss = 13.0513\n",
            "     Epoch 20: Train Loss = 0.7369, Val Loss = 13.5296\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 6.6494\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7056%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8143, Val Loss = 6.3260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7728, Val Loss = 7.6510\n",
            "     Epoch 10: Train Loss = 0.7475, Val Loss = 9.4456\n",
            "     Epoch 15: Train Loss = 0.7322, Val Loss = 11.0466\n",
            "     Epoch 20: Train Loss = 0.7319, Val Loss = 11.8562\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 6.3260\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.3291%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 1.0386, Val Loss = 5.8480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.8778, Val Loss = 8.0333\n",
            "     Epoch 10: Train Loss = 0.7881, Val Loss = 10.0422\n",
            "     Epoch 15: Train Loss = 0.7552, Val Loss = 11.7740\n",
            "     Epoch 20: Train Loss = 0.7572, Val Loss = 13.0244\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 5.8480\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6365%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8128, Val Loss = 6.8315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7689, Val Loss = 8.1923\n",
            "     Epoch 10: Train Loss = 0.7290, Val Loss = 9.2278\n",
            "     Epoch 15: Train Loss = 0.7363, Val Loss = 10.0676\n",
            "     Epoch 20: Train Loss = 0.7434, Val Loss = 10.1961\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 6.8315\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.1406%\n",
            " Finished configuration H=32, D=0.2, LR=0.0001, B=32 → Avg Val Loss: 6.4012, Avg Accuracy: 3.4636%\n",
            "\n",
            " Running 22/81: H=32, D=0.2, LR=0.0005, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8084, Val Loss = 8.7315\n",
            "     Epoch 5: Train Loss = 0.7340, Val Loss = 12.3970\n",
            "     Epoch 10: Train Loss = 0.7320, Val Loss = 10.8202\n",
            "     Epoch 15: Train Loss = 0.7406, Val Loss = 12.0696\n",
            "     Epoch 20: Train Loss = 0.7370, Val Loss = 12.7298\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 8.7315\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5734%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7716, Val Loss = 14.1303\n",
            "     Epoch 5: Train Loss = 0.7315, Val Loss = 13.2239\n",
            "     Epoch 10: Train Loss = 0.7291, Val Loss = 12.7077\n",
            "     Epoch 15: Train Loss = 0.7295, Val Loss = 11.6071\n",
            "     Epoch 20: Train Loss = 0.7370, Val Loss = 10.9640\n",
            "     Epoch 25: Train Loss = 0.7194, Val Loss = 12.5610\n",
            "     Epoch 30: Train Loss = 0.7247, Val Loss = 13.2943\n",
            "     Epoch 35: Train Loss = 0.7211, Val Loss = 12.2712\n",
            "     Epoch 40: Train Loss = 0.7301, Val Loss = 11.8221\n",
            "    ⏹️ Early stopping at epoch 40\n",
            " Run 2 finished with best val loss: 10.9640\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4050%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7902, Val Loss = 10.7967\n",
            "     Epoch 5: Train Loss = 0.7252, Val Loss = 15.2201\n",
            "     Epoch 10: Train Loss = 0.7257, Val Loss = 16.5669\n",
            "     Epoch 15: Train Loss = 0.7319, Val Loss = 14.6570\n",
            "     Epoch 20: Train Loss = 0.7217, Val Loss = 15.2979\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 10.7967\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3888%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7857, Val Loss = 9.6402\n",
            "     Epoch 5: Train Loss = 0.7437, Val Loss = 10.8089\n",
            "     Epoch 10: Train Loss = 0.7304, Val Loss = 11.8796\n",
            "     Epoch 15: Train Loss = 0.7410, Val Loss = 13.1116\n",
            "     Epoch 20: Train Loss = 0.7342, Val Loss = 13.4113\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 9.6402\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7326%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7535, Val Loss = 11.1454\n",
            "     Epoch 5: Train Loss = 0.7317, Val Loss = 12.7831\n",
            "     Epoch 10: Train Loss = 0.7289, Val Loss = 13.3170\n",
            "     Epoch 15: Train Loss = 0.7179, Val Loss = 12.4341\n",
            "     Epoch 20: Train Loss = 0.7245, Val Loss = 13.2092\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 11.1454\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6687%\n",
            " Finished configuration H=32, D=0.2, LR=0.0005, B=8 → Avg Val Loss: 10.2555, Avg Accuracy: 3.7537%\n",
            "\n",
            " Running 23/81: H=32, D=0.2, LR=0.0005, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8085, Val Loss = 10.6393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7417, Val Loss = 14.2188\n",
            "     Epoch 10: Train Loss = 0.7431, Val Loss = 13.9040\n",
            "     Epoch 15: Train Loss = 0.7315, Val Loss = 13.3401\n",
            "     Epoch 20: Train Loss = 0.7224, Val Loss = 14.7426\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 10.6393\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0144%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8358, Val Loss = 8.9062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7392, Val Loss = 13.3347\n",
            "     Epoch 10: Train Loss = 0.7390, Val Loss = 13.2647\n",
            "     Epoch 15: Train Loss = 0.7340, Val Loss = 13.9919\n",
            "     Epoch 20: Train Loss = 0.7316, Val Loss = 13.3622\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 8.9062\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7329%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7996, Val Loss = 6.7127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7272, Val Loss = 9.7322\n",
            "     Epoch 10: Train Loss = 0.7426, Val Loss = 9.8809\n",
            "     Epoch 15: Train Loss = 0.7277, Val Loss = 10.7804\n",
            "     Epoch 20: Train Loss = 0.7345, Val Loss = 11.2132\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 6.7127\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2441%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8351, Val Loss = 7.7218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7292, Val Loss = 13.9926\n",
            "     Epoch 10: Train Loss = 0.7330, Val Loss = 13.2516\n",
            "     Epoch 15: Train Loss = 0.7240, Val Loss = 14.6152\n",
            "     Epoch 20: Train Loss = 0.7238, Val Loss = 14.1454\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 7.7218\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9063%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8132, Val Loss = 6.8956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7322, Val Loss = 11.6680\n",
            "     Epoch 10: Train Loss = 0.7298, Val Loss = 11.9385\n",
            "     Epoch 15: Train Loss = 0.7246, Val Loss = 12.1198\n",
            "     Epoch 20: Train Loss = 0.7280, Val Loss = 12.0639\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 6.8956\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.3953%\n",
            " Finished configuration H=32, D=0.2, LR=0.0005, B=16 → Avg Val Loss: 8.1751, Avg Accuracy: 3.6586%\n",
            "\n",
            " Running 24/81: H=32, D=0.2, LR=0.0005, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.9174, Val Loss = 6.4720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7509, Val Loss = 14.1855\n",
            "     Epoch 10: Train Loss = 0.7472, Val Loss = 14.4000\n",
            "     Epoch 15: Train Loss = 0.7457, Val Loss = 14.2053\n",
            "     Epoch 20: Train Loss = 0.7345, Val Loss = 12.9590\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 6.4720\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6274%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.9682, Val Loss = 7.2089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7515, Val Loss = 19.0398\n",
            "     Epoch 10: Train Loss = 0.7340, Val Loss = 18.3165\n",
            "     Epoch 15: Train Loss = 0.7322, Val Loss = 17.6719\n",
            "     Epoch 20: Train Loss = 0.7377, Val Loss = 16.2562\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 7.2089\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4644%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8660, Val Loss = 6.2065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7633, Val Loss = 9.5690\n",
            "     Epoch 10: Train Loss = 0.7449, Val Loss = 10.9849\n",
            "     Epoch 15: Train Loss = 0.7286, Val Loss = 11.4065\n",
            "     Epoch 20: Train Loss = 0.7439, Val Loss = 11.6224\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 6.2065\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.3258%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7854, Val Loss = 10.2658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7382, Val Loss = 14.4101\n",
            "     Epoch 10: Train Loss = 0.7407, Val Loss = 13.2446\n",
            "     Epoch 15: Train Loss = 0.7167, Val Loss = 13.1082\n",
            "     Epoch 20: Train Loss = 0.7242, Val Loss = 12.9689\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 10.2658\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5812%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8120, Val Loss = 8.6464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7291, Val Loss = 12.7144\n",
            "     Epoch 10: Train Loss = 0.7385, Val Loss = 11.7457\n",
            "     Epoch 15: Train Loss = 0.7283, Val Loss = 13.1007\n",
            "     Epoch 20: Train Loss = 0.7262, Val Loss = 12.4582\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 8.6464\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4917%\n",
            " Finished configuration H=32, D=0.2, LR=0.0005, B=32 → Avg Val Loss: 7.7599, Avg Accuracy: 3.6981%\n",
            "\n",
            " Running 25/81: H=32, D=0.2, LR=0.001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.9388, Val Loss = 9.0498\n",
            "     Epoch 5: Train Loss = 0.7405, Val Loss = 12.9257\n",
            "     Epoch 10: Train Loss = 0.7419, Val Loss = 11.4155\n",
            "     Epoch 15: Train Loss = 0.7237, Val Loss = 12.5084\n",
            "     Epoch 20: Train Loss = 0.7433, Val Loss = 10.1247\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 9.0498\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.1743%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7651, Val Loss = 10.1315\n",
            "     Epoch 5: Train Loss = 0.7320, Val Loss = 14.4750\n",
            "     Epoch 10: Train Loss = 0.7232, Val Loss = 13.3446\n",
            "     Epoch 15: Train Loss = 0.7310, Val Loss = 13.3183\n",
            "     Epoch 20: Train Loss = 0.7239, Val Loss = 16.0405\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 10.1315\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4397%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7783, Val Loss = 11.5121\n",
            "     Epoch 5: Train Loss = 0.7311, Val Loss = 13.6758\n",
            "     Epoch 10: Train Loss = 0.7222, Val Loss = 12.8256\n",
            "     Epoch 15: Train Loss = 0.7337, Val Loss = 12.1241\n",
            "     Epoch 20: Train Loss = 0.7255, Val Loss = 10.9178\n",
            "     Epoch 25: Train Loss = 0.7191, Val Loss = 14.4625\n",
            "     Epoch 30: Train Loss = 0.7268, Val Loss = 14.0826\n",
            "     Epoch 35: Train Loss = 0.7299, Val Loss = 12.6790\n",
            "     Epoch 40: Train Loss = 0.7306, Val Loss = 13.4522\n",
            "    ⏹️ Early stopping at epoch 40\n",
            " Run 3 finished with best val loss: 10.9178\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8135%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7683, Val Loss = 13.4822\n",
            "     Epoch 5: Train Loss = 0.7218, Val Loss = 12.8095\n",
            "     Epoch 10: Train Loss = 0.7342, Val Loss = 11.7726\n",
            "     Epoch 15: Train Loss = 0.7224, Val Loss = 12.5155\n",
            "     Epoch 20: Train Loss = 0.7308, Val Loss = 13.0783\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 4 finished with best val loss: 11.1284\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9639%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7815, Val Loss = 11.7708\n",
            "     Epoch 5: Train Loss = 0.7369, Val Loss = 11.4475\n",
            "     Epoch 10: Train Loss = 0.7322, Val Loss = 10.8030\n",
            "     Epoch 15: Train Loss = 0.7282, Val Loss = 12.3371\n",
            "     Epoch 20: Train Loss = 0.7156, Val Loss = 12.0618\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 5 finished with best val loss: 8.9943\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6723%\n",
            " Finished configuration H=32, D=0.2, LR=0.001, B=8 → Avg Val Loss: 10.0444, Avg Accuracy: 3.8127%\n",
            "\n",
            " Running 26/81: H=32, D=0.2, LR=0.001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7651, Val Loss = 10.8006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7299, Val Loss = 13.5415\n",
            "     Epoch 10: Train Loss = 0.7273, Val Loss = 13.9827\n",
            "     Epoch 15: Train Loss = 0.7209, Val Loss = 14.0465\n",
            "     Epoch 20: Train Loss = 0.7206, Val Loss = 16.8873\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 10.8006\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.6203%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7845, Val Loss = 10.1276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7283, Val Loss = 13.9634\n",
            "     Epoch 10: Train Loss = 0.7318, Val Loss = 12.7654\n",
            "     Epoch 15: Train Loss = 0.7187, Val Loss = 14.6872\n",
            "     Epoch 20: Train Loss = 0.7272, Val Loss = 14.2228\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 10.1276\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9984%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8418, Val Loss = 6.4529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7445, Val Loss = 10.4409\n",
            "     Epoch 10: Train Loss = 0.7286, Val Loss = 11.3281\n",
            "     Epoch 15: Train Loss = 0.7287, Val Loss = 12.8286\n",
            "     Epoch 20: Train Loss = 0.7236, Val Loss = 12.3219\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 6.4529\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4421%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7634, Val Loss = 13.6183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7161, Val Loss = 13.9422\n",
            "     Epoch 10: Train Loss = 0.7230, Val Loss = 14.0179\n",
            "     Epoch 15: Train Loss = 0.7321, Val Loss = 13.4625\n",
            "     Epoch 20: Train Loss = 0.7357, Val Loss = 13.7815\n",
            "     Epoch 25: Train Loss = 0.7240, Val Loss = 14.6738\n",
            "    ⏹️ Early stopping at epoch 28\n",
            " Run 4 finished with best val loss: 13.1312\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2702%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7870, Val Loss = 10.7966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7307, Val Loss = 13.6329\n",
            "     Epoch 10: Train Loss = 0.7364, Val Loss = 14.6312\n",
            "     Epoch 15: Train Loss = 0.7266, Val Loss = 14.6792\n",
            "     Epoch 20: Train Loss = 0.7220, Val Loss = 14.7309\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 10.7966\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1886%\n",
            " Finished configuration H=32, D=0.2, LR=0.001, B=16 → Avg Val Loss: 10.2618, Avg Accuracy: 4.1039%\n",
            "\n",
            " Running 27/81: H=32, D=0.2, LR=0.001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8192, Val Loss = 12.0861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7401, Val Loss = 12.9857\n",
            "     Epoch 10: Train Loss = 0.7349, Val Loss = 12.3379\n",
            "     Epoch 15: Train Loss = 0.7331, Val Loss = 12.7816\n",
            "     Epoch 20: Train Loss = 0.7219, Val Loss = 12.5681\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 12.0861\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5222%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8233, Val Loss = 9.8725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7538, Val Loss = 12.8984\n",
            "     Epoch 10: Train Loss = 0.7411, Val Loss = 12.3110\n",
            "     Epoch 15: Train Loss = 0.7337, Val Loss = 11.1608\n",
            "     Epoch 20: Train Loss = 0.7404, Val Loss = 11.6844\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 9.8725\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.3659%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8187, Val Loss = 9.4645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7307, Val Loss = 12.6821\n",
            "     Epoch 10: Train Loss = 0.7208, Val Loss = 12.4379\n",
            "     Epoch 15: Train Loss = 0.7249, Val Loss = 12.4108\n",
            "     Epoch 20: Train Loss = 0.7325, Val Loss = 12.1807\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 9.4645\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4381%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8707, Val Loss = 6.8563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7205, Val Loss = 13.5530\n",
            "     Epoch 10: Train Loss = 0.7358, Val Loss = 13.0952\n",
            "     Epoch 15: Train Loss = 0.7268, Val Loss = 13.0528\n",
            "     Epoch 20: Train Loss = 0.7321, Val Loss = 12.0400\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 6.8563\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.3968%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7980, Val Loss = 11.3981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7295, Val Loss = 12.2694\n",
            "     Epoch 10: Train Loss = 0.7183, Val Loss = 11.9823\n",
            "     Epoch 15: Train Loss = 0.7444, Val Loss = 12.4822\n",
            "     Epoch 20: Train Loss = 0.7234, Val Loss = 13.5444\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 11.3981\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7447%\n",
            " Finished configuration H=32, D=0.2, LR=0.001, B=32 → Avg Val Loss: 9.9355, Avg Accuracy: 3.4935%\n",
            "\n",
            " Running 28/81: H=64, D=0.0, LR=0.0001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8021, Val Loss = 7.2610\n",
            "     Epoch 5: Train Loss = 0.7166, Val Loss = 12.3588\n",
            "     Epoch 10: Train Loss = 0.7163, Val Loss = 12.6009\n",
            "     Epoch 15: Train Loss = 0.7160, Val Loss = 12.7092\n",
            "     Epoch 20: Train Loss = 0.7159, Val Loss = 12.6036\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 7.2610\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4879%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7628, Val Loss = 9.9737\n",
            "     Epoch 5: Train Loss = 0.7174, Val Loss = 13.3252\n",
            "     Epoch 10: Train Loss = 0.7162, Val Loss = 13.4756\n",
            "     Epoch 15: Train Loss = 0.7148, Val Loss = 13.6191\n",
            "     Epoch 20: Train Loss = 0.7144, Val Loss = 13.5099\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 9.9737\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7302%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7908, Val Loss = 9.7512\n",
            "     Epoch 5: Train Loss = 0.7192, Val Loss = 14.0451\n",
            "     Epoch 10: Train Loss = 0.7174, Val Loss = 14.3690\n",
            "     Epoch 15: Train Loss = 0.7158, Val Loss = 14.3016\n",
            "     Epoch 20: Train Loss = 0.7155, Val Loss = 14.2932\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 9.7512\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8081%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7920, Val Loss = 9.4777\n",
            "     Epoch 5: Train Loss = 0.7173, Val Loss = 14.2832\n",
            "     Epoch 10: Train Loss = 0.7158, Val Loss = 14.1166\n",
            "     Epoch 15: Train Loss = 0.7154, Val Loss = 13.9231\n",
            "     Epoch 20: Train Loss = 0.7157, Val Loss = 14.2119\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 9.4777\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9412%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7867, Val Loss = 8.6310\n",
            "     Epoch 5: Train Loss = 0.7177, Val Loss = 13.9795\n",
            "     Epoch 10: Train Loss = 0.7164, Val Loss = 13.9021\n",
            "     Epoch 15: Train Loss = 0.7152, Val Loss = 14.0553\n",
            "     Epoch 20: Train Loss = 0.7146, Val Loss = 14.2925\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 8.6310\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9382%\n",
            " Finished configuration H=64, D=0.0, LR=0.0001, B=8 → Avg Val Loss: 9.0189, Avg Accuracy: 3.7811%\n",
            "\n",
            " Running 29/81: H=64, D=0.0, LR=0.0001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8240, Val Loss = 9.9126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7201, Val Loss = 15.8959\n",
            "     Epoch 10: Train Loss = 0.7176, Val Loss = 16.0216\n",
            "     Epoch 15: Train Loss = 0.7161, Val Loss = 15.5290\n",
            "     Epoch 20: Train Loss = 0.7156, Val Loss = 14.8178\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 9.9126\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1060%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7946, Val Loss = 9.9684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7196, Val Loss = 15.2876\n",
            "     Epoch 10: Train Loss = 0.7171, Val Loss = 15.1524\n",
            "     Epoch 15: Train Loss = 0.7165, Val Loss = 14.7825\n",
            "     Epoch 20: Train Loss = 0.7155, Val Loss = 14.5185\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 9.9684\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9506%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8726, Val Loss = 6.1702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7281, Val Loss = 12.4055\n",
            "     Epoch 10: Train Loss = 0.7185, Val Loss = 13.9474\n",
            "     Epoch 15: Train Loss = 0.7165, Val Loss = 14.1286\n",
            "     Epoch 20: Train Loss = 0.7161, Val Loss = 14.0874\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 6.1702\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8164%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7712, Val Loss = 11.6193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7192, Val Loss = 15.3580\n",
            "     Epoch 10: Train Loss = 0.7171, Val Loss = 14.5863\n",
            "     Epoch 15: Train Loss = 0.7157, Val Loss = 14.4180\n",
            "     Epoch 20: Train Loss = 0.7153, Val Loss = 14.2828\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 11.6193\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9405%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8374, Val Loss = 6.2593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7215, Val Loss = 12.4834\n",
            "     Epoch 10: Train Loss = 0.7164, Val Loss = 14.2858\n",
            "     Epoch 15: Train Loss = 0.7164, Val Loss = 13.8837\n",
            "     Epoch 20: Train Loss = 0.7155, Val Loss = 13.7145\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 6.2593\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7496%\n",
            " Finished configuration H=64, D=0.0, LR=0.0001, B=16 → Avg Val Loss: 8.7860, Avg Accuracy: 3.9126%\n",
            "\n",
            " Running 30/81: H=64, D=0.0, LR=0.0001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8163, Val Loss = 8.2894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7293, Val Loss = 12.6721\n",
            "     Epoch 10: Train Loss = 0.7188, Val Loss = 14.2393\n",
            "     Epoch 15: Train Loss = 0.7170, Val Loss = 13.9781\n",
            "     Epoch 20: Train Loss = 0.7165, Val Loss = 13.5934\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 8.2894\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7030%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8764, Val Loss = 7.2662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7322, Val Loss = 13.1221\n",
            "     Epoch 10: Train Loss = 0.7185, Val Loss = 15.1334\n",
            "     Epoch 15: Train Loss = 0.7174, Val Loss = 15.6503\n",
            "     Epoch 20: Train Loss = 0.7157, Val Loss = 14.9252\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 7.2662\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0813%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8009, Val Loss = 7.3959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7226, Val Loss = 11.4097\n",
            "     Epoch 10: Train Loss = 0.7173, Val Loss = 12.3341\n",
            "     Epoch 15: Train Loss = 0.7168, Val Loss = 12.1687\n",
            "     Epoch 20: Train Loss = 0.7166, Val Loss = 12.0602\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 7.3959\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.3580%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8145, Val Loss = 9.1911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7298, Val Loss = 15.2781\n",
            "     Epoch 10: Train Loss = 0.7191, Val Loss = 16.6937\n",
            "     Epoch 15: Train Loss = 0.7164, Val Loss = 16.1404\n",
            "     Epoch 20: Train Loss = 0.7153, Val Loss = 15.3027\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 9.1911\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2416%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7892, Val Loss = 9.5408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7247, Val Loss = 16.0553\n",
            "     Epoch 10: Train Loss = 0.7196, Val Loss = 16.5001\n",
            "     Epoch 15: Train Loss = 0.7179, Val Loss = 16.0488\n",
            "     Epoch 20: Train Loss = 0.7167, Val Loss = 15.3849\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 9.5408\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2153%\n",
            " Finished configuration H=64, D=0.0, LR=0.0001, B=32 → Avg Val Loss: 8.3367, Avg Accuracy: 3.9198%\n",
            "\n",
            " Running 31/81: H=64, D=0.0, LR=0.0005, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7748, Val Loss = 12.3297\n",
            "     Epoch 5: Train Loss = 0.7166, Val Loss = 14.0571\n",
            "     Epoch 10: Train Loss = 0.7178, Val Loss = 14.6014\n",
            "     Epoch 15: Train Loss = 0.7163, Val Loss = 14.2872\n",
            "     Epoch 20: Train Loss = 0.7158, Val Loss = 13.9208\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 12.3297\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8466%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7552, Val Loss = 12.1207\n",
            "     Epoch 5: Train Loss = 0.7150, Val Loss = 14.5138\n",
            "     Epoch 10: Train Loss = 0.7166, Val Loss = 14.4611\n",
            "     Epoch 15: Train Loss = 0.7173, Val Loss = 15.7846\n",
            "     Epoch 20: Train Loss = 0.7163, Val Loss = 14.8632\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 12.1207\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1704%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7510, Val Loss = 14.1967\n",
            "     Epoch 5: Train Loss = 0.7140, Val Loss = 17.8935\n",
            "     Epoch 10: Train Loss = 0.7162, Val Loss = 21.0166\n",
            "     Epoch 15: Train Loss = 0.7157, Val Loss = 17.3012\n",
            "     Epoch 20: Train Loss = 0.7156, Val Loss = 18.6500\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 3 finished with best val loss: 10.6142\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.2858%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7473, Val Loss = 17.0500\n",
            "     Epoch 5: Train Loss = 0.7192, Val Loss = 16.1906\n",
            "     Epoch 10: Train Loss = 0.7200, Val Loss = 13.5014\n",
            "     Epoch 15: Train Loss = 0.7162, Val Loss = 16.6060\n",
            "     Epoch 20: Train Loss = 0.7146, Val Loss = 18.5531\n",
            "     Epoch 25: Train Loss = 0.7169, Val Loss = 16.1568\n",
            "     Epoch 30: Train Loss = 0.7145, Val Loss = 17.6337\n",
            "    ⏹️ Early stopping at epoch 30\n",
            " Run 4 finished with best val loss: 13.5014\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.0178%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7688, Val Loss = 10.1825\n",
            "     Epoch 5: Train Loss = 0.7202, Val Loss = 11.8221\n",
            "     Epoch 10: Train Loss = 0.7187, Val Loss = 13.6150\n",
            "     Epoch 15: Train Loss = 0.7156, Val Loss = 14.9920\n",
            "     Epoch 20: Train Loss = 0.7152, Val Loss = 15.0272\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 10.1825\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0674%\n",
            " Finished configuration H=64, D=0.0, LR=0.0005, B=8 → Avg Val Loss: 11.7497, Avg Accuracy: 4.4776%\n",
            "\n",
            " Running 32/81: H=64, D=0.0, LR=0.0005, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7585, Val Loss = 16.6276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7185, Val Loss = 14.1682\n",
            "     Epoch 10: Train Loss = 0.7154, Val Loss = 13.6932\n",
            "     Epoch 15: Train Loss = 0.7157, Val Loss = 15.3083\n",
            "     Epoch 20: Train Loss = 0.7140, Val Loss = 14.4714\n",
            "     Epoch 25: Train Loss = 0.7146, Val Loss = 16.0109\n",
            "     Epoch 30: Train Loss = 0.7163, Val Loss = 15.3618\n",
            "     Epoch 35: Train Loss = 0.7135, Val Loss = 15.0089\n",
            "     Epoch 40: Train Loss = 0.7134, Val Loss = 16.1025\n",
            "    ⏹️ Early stopping at epoch 44\n",
            " Run 1 finished with best val loss: 13.5957\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1941%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7707, Val Loss = 15.9364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7183, Val Loss = 13.8076\n",
            "     Epoch 10: Train Loss = 0.7180, Val Loss = 13.2635\n",
            "     Epoch 15: Train Loss = 0.7175, Val Loss = 13.4554\n",
            "     Epoch 20: Train Loss = 0.7164, Val Loss = 13.2844\n",
            "     Epoch 25: Train Loss = 0.7161, Val Loss = 13.4623\n",
            "     Epoch 30: Train Loss = 0.7154, Val Loss = 13.6998\n",
            "     Epoch 35: Train Loss = 0.7170, Val Loss = 14.6634\n",
            "    ⏹️ Early stopping at epoch 36\n",
            " Run 2 finished with best val loss: 12.7228\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1718%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7354, Val Loss = 13.3464\n",
            "     Epoch 5: Train Loss = 0.7175, Val Loss = 13.2938\n",
            "     Epoch 10: Train Loss = 0.7162, Val Loss = 14.4612\n",
            "     Epoch 15: Train Loss = 0.7169, Val Loss = 15.6351\n",
            "     Epoch 20: Train Loss = 0.7145, Val Loss = 15.5446\n",
            "     Epoch 25: Train Loss = 0.7137, Val Loss = 15.6261\n",
            "    ⏹️ Early stopping at epoch 25\n",
            " Run 3 finished with best val loss: 13.2938\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3328%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7862, Val Loss = 10.7973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7180, Val Loss = 13.7381\n",
            "     Epoch 10: Train Loss = 0.7176, Val Loss = 14.0170\n",
            "     Epoch 15: Train Loss = 0.7180, Val Loss = 13.9887\n",
            "     Epoch 20: Train Loss = 0.7155, Val Loss = 15.9827\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 10.7973\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3734%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7496, Val Loss = 10.7031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "     Epoch 5: Train Loss = 0.7188, Val Loss = 12.2213\n",
            "     Epoch 10: Train Loss = 0.7171, Val Loss = 13.1329\n",
            "     Epoch 15: Train Loss = 0.7158, Val Loss = 14.2837\n",
            "     Epoch 20: Train Loss = 0.7143, Val Loss = 15.5168\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 10.7031\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3446%\n",
            " Finished configuration H=64, D=0.0, LR=0.0005, B=16 → Avg Val Loss: 12.2225, Avg Accuracy: 4.2833%\n",
            "\n",
            " Running 33/81: H=64, D=0.0, LR=0.0005, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8004, Val Loss = 9.5212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7184, Val Loss = 12.8563\n",
            "     Epoch 10: Train Loss = 0.7158, Val Loss = 13.9646\n",
            "     Epoch 15: Train Loss = 0.7173, Val Loss = 15.0759\n",
            "     Epoch 20: Train Loss = 0.7148, Val Loss = 13.7736\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 9.5212\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8206%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7491, Val Loss = 12.8774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7200, Val Loss = 14.9662\n",
            "     Epoch 10: Train Loss = 0.7157, Val Loss = 13.3622\n",
            "     Epoch 15: Train Loss = 0.7180, Val Loss = 14.5611\n",
            "     Epoch 20: Train Loss = 0.7138, Val Loss = 17.1536\n",
            "    ⏹️ Early stopping at epoch 24\n",
            " Run 2 finished with best val loss: 12.4122\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0524%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8451, Val Loss = 9.2683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7173, Val Loss = 15.0957\n",
            "     Epoch 10: Train Loss = 0.7155, Val Loss = 15.4908\n",
            "     Epoch 15: Train Loss = 0.7148, Val Loss = 16.6812\n",
            "     Epoch 20: Train Loss = 0.7149, Val Loss = 15.7348\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 9.2683\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3465%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8089, Val Loss = 8.7758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7155, Val Loss = 14.2293\n",
            "     Epoch 10: Train Loss = 0.7157, Val Loss = 14.5256\n",
            "     Epoch 15: Train Loss = 0.7152, Val Loss = 14.9782\n",
            "     Epoch 20: Train Loss = 0.7146, Val Loss = 15.9091\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 8.7758\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4161%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7857, Val Loss = 10.3745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7165, Val Loss = 12.4393\n",
            "     Epoch 10: Train Loss = 0.7155, Val Loss = 13.7504\n",
            "     Epoch 15: Train Loss = 0.7157, Val Loss = 14.0935\n",
            "     Epoch 20: Train Loss = 0.7157, Val Loss = 14.8884\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 10.3745\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0535%\n",
            " Finished configuration H=64, D=0.0, LR=0.0005, B=32 → Avg Val Loss: 10.0704, Avg Accuracy: 4.1378%\n",
            "\n",
            " Running 34/81: H=64, D=0.0, LR=0.001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7413, Val Loss = 14.5076\n",
            "     Epoch 5: Train Loss = 0.7203, Val Loss = 15.9117\n",
            "     Epoch 10: Train Loss = 0.7226, Val Loss = 15.2397\n",
            "     Epoch 15: Train Loss = 0.7164, Val Loss = 19.3313\n",
            "     Epoch 20: Train Loss = 0.7148, Val Loss = 22.1048\n",
            "     Epoch 25: Train Loss = 0.7190, Val Loss = 20.7993\n",
            "     Epoch 30: Train Loss = 0.7159, Val Loss = 18.1049\n",
            "     Epoch 35: Train Loss = 0.7174, Val Loss = 20.2931\n",
            "     Epoch 40: Train Loss = 0.7156, Val Loss = 19.4531\n",
            "    ⏹️ Early stopping at epoch 42\n",
            " Run 1 finished with best val loss: 12.5580\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.9335%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7362, Val Loss = 16.0751\n",
            "     Epoch 5: Train Loss = 0.7229, Val Loss = 12.7842\n",
            "     Epoch 10: Train Loss = 0.7192, Val Loss = 17.8535\n",
            "     Epoch 15: Train Loss = 0.7181, Val Loss = 14.5874\n",
            "     Epoch 20: Train Loss = 0.7205, Val Loss = 13.5614\n",
            "     Epoch 25: Train Loss = 0.7158, Val Loss = 10.3656\n",
            "     Epoch 30: Train Loss = 0.7203, Val Loss = 15.4859\n",
            "     Epoch 35: Train Loss = 0.7165, Val Loss = 14.4085\n",
            "     Epoch 40: Train Loss = 0.7158, Val Loss = 15.2308\n",
            "     Epoch 45: Train Loss = 0.7147, Val Loss = 17.1181\n",
            "    ⏹️ Early stopping at epoch 45\n",
            " Run 2 finished with best val loss: 10.3656\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.7218%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7344, Val Loss = 13.8611\n",
            "     Epoch 5: Train Loss = 0.7204, Val Loss = 11.7513\n",
            "     Epoch 10: Train Loss = 0.7202, Val Loss = 15.9696\n",
            "     Epoch 15: Train Loss = 0.7188, Val Loss = 15.9479\n",
            "     Epoch 20: Train Loss = 0.7146, Val Loss = 13.4598\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 3 finished with best val loss: 11.3095\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4276%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7305, Val Loss = 22.7898\n",
            "     Epoch 5: Train Loss = 0.7192, Val Loss = 12.2628\n",
            "     Epoch 10: Train Loss = 0.7195, Val Loss = 12.8036\n",
            "     Epoch 15: Train Loss = 0.7199, Val Loss = 18.2662\n",
            "     Epoch 20: Train Loss = 0.7189, Val Loss = 16.4174\n",
            "     Epoch 25: Train Loss = 0.7171, Val Loss = 17.0925\n",
            "    ⏹️ Early stopping at epoch 27\n",
            " Run 4 finished with best val loss: 10.5806\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.2147%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7275, Val Loss = 13.4907\n",
            "     Epoch 5: Train Loss = 0.7163, Val Loss = 11.4820\n",
            "     Epoch 10: Train Loss = 0.7162, Val Loss = 17.5407\n",
            "     Epoch 15: Train Loss = 0.7153, Val Loss = 16.4120\n",
            "     Epoch 20: Train Loss = 0.7172, Val Loss = 19.3616\n",
            "     Epoch 25: Train Loss = 0.7156, Val Loss = 18.4682\n",
            "    ⏹️ Early stopping at epoch 25\n",
            " Run 5 finished with best val loss: 11.4820\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.3492%\n",
            " Finished configuration H=64, D=0.0, LR=0.001, B=8 → Avg Val Loss: 11.2591, Avg Accuracy: 4.9294%\n",
            "\n",
            " Running 35/81: H=64, D=0.0, LR=0.001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7404, Val Loss = 12.2869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7199, Val Loss = 11.5791\n",
            "     Epoch 10: Train Loss = 0.7188, Val Loss = 14.3574\n",
            "     Epoch 15: Train Loss = 0.7185, Val Loss = 11.0840\n",
            "     Epoch 20: Train Loss = 0.7195, Val Loss = 15.5768\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 1 finished with best val loss: 9.1289\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8514%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7768, Val Loss = 13.4297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7196, Val Loss = 12.1634\n",
            "     Epoch 10: Train Loss = 0.7174, Val Loss = 15.9102\n",
            "     Epoch 15: Train Loss = 0.7148, Val Loss = 15.2944\n",
            "     Epoch 20: Train Loss = 0.7177, Val Loss = 17.8913\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 2 finished with best val loss: 11.7446\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.6027%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7311, Val Loss = 11.9508\n",
            "     Epoch 5: Train Loss = 0.7187, Val Loss = 15.3735\n",
            "     Epoch 10: Train Loss = 0.7182, Val Loss = 12.2488\n",
            "     Epoch 15: Train Loss = 0.7148, Val Loss = 16.9593\n",
            "     Epoch 20: Train Loss = 0.7163, Val Loss = 14.8462\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 3 finished with best val loss: 10.3694\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.6137%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7422, Val Loss = 13.8144\n",
            "     Epoch 5: Train Loss = 0.7206, Val Loss = 16.1418\n",
            "     Epoch 10: Train Loss = 0.7167, Val Loss = 15.6620\n",
            "     Epoch 15: Train Loss = 0.7199, Val Loss = 14.7269\n",
            "     Epoch 20: Train Loss = 0.7152, Val Loss = 14.6292\n",
            "     Epoch 25: Train Loss = 0.7149, Val Loss = 14.3290\n",
            "    ⏹️ Early stopping at epoch 27\n",
            " Run 4 finished with best val loss: 12.6120\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0835%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7484, Val Loss = 11.7695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7185, Val Loss = 14.2474\n",
            "     Epoch 10: Train Loss = 0.7173, Val Loss = 14.1240\n",
            "     Epoch 15: Train Loss = 0.7186, Val Loss = 16.7794\n",
            "     Epoch 20: Train Loss = 0.7159, Val Loss = 15.7318\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 11.7695\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3944%\n",
            " Finished configuration H=64, D=0.0, LR=0.001, B=16 → Avg Val Loss: 11.1249, Avg Accuracy: 4.3091%\n",
            "\n",
            " Running 36/81: H=64, D=0.0, LR=0.001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7444, Val Loss = 15.5253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7175, Val Loss = 14.0356\n",
            "     Epoch 10: Train Loss = 0.7184, Val Loss = 12.5656\n",
            "     Epoch 15: Train Loss = 0.7164, Val Loss = 13.9333\n",
            "     Epoch 20: Train Loss = 0.7200, Val Loss = 12.7429\n",
            "     Epoch 25: Train Loss = 0.7190, Val Loss = 15.6456\n",
            "     Epoch 30: Train Loss = 0.7165, Val Loss = 13.4577\n",
            "    ⏹️ Early stopping at epoch 30\n",
            " Run 1 finished with best val loss: 12.5656\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7983%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7881, Val Loss = 9.6093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7181, Val Loss = 12.8250\n",
            "     Epoch 10: Train Loss = 0.7177, Val Loss = 14.9573\n",
            "     Epoch 15: Train Loss = 0.7160, Val Loss = 13.6763\n",
            "     Epoch 20: Train Loss = 0.7154, Val Loss = 15.2079\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 9.6093\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2207%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7438, Val Loss = 16.5298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7197, Val Loss = 14.6150\n",
            "     Epoch 10: Train Loss = 0.7170, Val Loss = 13.5605\n",
            "     Epoch 15: Train Loss = 0.7188, Val Loss = 11.5163\n",
            "     Epoch 20: Train Loss = 0.7189, Val Loss = 13.6016\n",
            "    ⏹️ Early stopping at epoch 24\n",
            " Run 3 finished with best val loss: 11.4570\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9402%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7484, Val Loss = 19.7611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7186, Val Loss = 15.9963\n",
            "     Epoch 10: Train Loss = 0.7162, Val Loss = 17.7842\n",
            "     Epoch 15: Train Loss = 0.7179, Val Loss = 18.7902\n",
            "     Epoch 20: Train Loss = 0.7168, Val Loss = 17.9479\n",
            "     Epoch 25: Train Loss = 0.7144, Val Loss = 18.4607\n",
            "    ⏹️ Early stopping at epoch 29\n",
            " Run 4 finished with best val loss: 14.0305\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.0964%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7539, Val Loss = 18.4515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7209, Val Loss = 15.2083\n",
            "     Epoch 10: Train Loss = 0.7164, Val Loss = 13.6982\n",
            "     Epoch 15: Train Loss = 0.7145, Val Loss = 14.2202\n",
            "     Epoch 20: Train Loss = 0.7152, Val Loss = 15.7749\n",
            "     Epoch 25: Train Loss = 0.7138, Val Loss = 16.4775\n",
            "     Epoch 30: Train Loss = 0.7128, Val Loss = 15.2149\n",
            "    ⏹️ Early stopping at epoch 31\n",
            " Run 5 finished with best val loss: 12.4080\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8166%\n",
            " Finished configuration H=64, D=0.0, LR=0.001, B=32 → Avg Val Loss: 12.0141, Avg Accuracy: 4.1745%\n",
            "\n",
            " Running 37/81: H=64, D=0.1, LR=0.0001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8227, Val Loss = 8.3739\n",
            "     Epoch 5: Train Loss = 0.7216, Val Loss = 12.4188\n",
            "     Epoch 10: Train Loss = 0.7269, Val Loss = 12.3611\n",
            "     Epoch 15: Train Loss = 0.7230, Val Loss = 12.1298\n",
            "     Epoch 20: Train Loss = 0.7135, Val Loss = 12.5749\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 8.3739\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4898%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7709, Val Loss = 8.9446\n",
            "     Epoch 5: Train Loss = 0.7275, Val Loss = 13.4213\n",
            "     Epoch 10: Train Loss = 0.7233, Val Loss = 13.0415\n",
            "     Epoch 15: Train Loss = 0.7180, Val Loss = 13.5191\n",
            "     Epoch 20: Train Loss = 0.7216, Val Loss = 14.0530\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 8.9446\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8277%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7969, Val Loss = 8.8333\n",
            "     Epoch 5: Train Loss = 0.7193, Val Loss = 13.9943\n",
            "     Epoch 10: Train Loss = 0.7177, Val Loss = 13.7493\n",
            "     Epoch 15: Train Loss = 0.7204, Val Loss = 13.5716\n",
            "     Epoch 20: Train Loss = 0.7215, Val Loss = 12.9340\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 8.8333\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6172%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8592, Val Loss = 7.3727\n",
            "     Epoch 5: Train Loss = 0.7306, Val Loss = 14.6562\n",
            "     Epoch 10: Train Loss = 0.7301, Val Loss = 14.7408\n",
            "     Epoch 15: Train Loss = 0.7259, Val Loss = 14.7065\n",
            "     Epoch 20: Train Loss = 0.7198, Val Loss = 14.6228\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 7.3727\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0405%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8970, Val Loss = 6.4415\n",
            "     Epoch 5: Train Loss = 0.7260, Val Loss = 12.1396\n",
            "     Epoch 10: Train Loss = 0.7131, Val Loss = 12.3285\n",
            "     Epoch 15: Train Loss = 0.7289, Val Loss = 12.5178\n",
            "     Epoch 20: Train Loss = 0.7192, Val Loss = 12.6454\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 6.4415\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5389%\n",
            " Finished configuration H=64, D=0.1, LR=0.0001, B=8 → Avg Val Loss: 7.9932, Avg Accuracy: 3.7028%\n",
            "\n",
            " Running 38/81: H=64, D=0.1, LR=0.0001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7909, Val Loss = 7.4282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7301, Val Loss = 12.0010\n",
            "     Epoch 10: Train Loss = 0.7236, Val Loss = 13.3595\n",
            "     Epoch 15: Train Loss = 0.7177, Val Loss = 13.4971\n",
            "     Epoch 20: Train Loss = 0.7259, Val Loss = 13.3533\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 7.4282\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7249%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8416, Val Loss = 7.2463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7319, Val Loss = 13.4190\n",
            "     Epoch 10: Train Loss = 0.7205, Val Loss = 13.4726\n",
            "     Epoch 15: Train Loss = 0.7203, Val Loss = 13.6762\n",
            "     Epoch 20: Train Loss = 0.7106, Val Loss = 13.5616\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 7.2463\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6975%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8216, Val Loss = 7.6344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7362, Val Loss = 12.6909\n",
            "     Epoch 10: Train Loss = 0.7337, Val Loss = 13.2296\n",
            "     Epoch 15: Train Loss = 0.7230, Val Loss = 13.3312\n",
            "     Epoch 20: Train Loss = 0.7298, Val Loss = 13.2693\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 7.6344\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6950%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8467, Val Loss = 7.2985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7344, Val Loss = 12.7173\n",
            "     Epoch 10: Train Loss = 0.7243, Val Loss = 13.9358\n",
            "     Epoch 15: Train Loss = 0.7234, Val Loss = 13.3856\n",
            "     Epoch 20: Train Loss = 0.7154, Val Loss = 13.5831\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 7.2985\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7657%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.9120, Val Loss = 6.6106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7338, Val Loss = 12.6419\n",
            "     Epoch 10: Train Loss = 0.7360, Val Loss = 14.6659\n",
            "     Epoch 15: Train Loss = 0.7209, Val Loss = 14.9406\n",
            "     Epoch 20: Train Loss = 0.7210, Val Loss = 14.9596\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 6.6106\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1556%\n",
            " Finished configuration H=64, D=0.1, LR=0.0001, B=16 → Avg Val Loss: 7.2436, Avg Accuracy: 3.8077%\n",
            "\n",
            " Running 39/81: H=64, D=0.1, LR=0.0001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8741, Val Loss = 7.3764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7335, Val Loss = 12.6599\n",
            "     Epoch 10: Train Loss = 0.7283, Val Loss = 14.4758\n",
            "     Epoch 15: Train Loss = 0.7188, Val Loss = 14.8172\n",
            "     Epoch 20: Train Loss = 0.7278, Val Loss = 14.3258\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 7.3764\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9273%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8213, Val Loss = 7.1998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7419, Val Loss = 10.4456\n",
            "     Epoch 10: Train Loss = 0.7249, Val Loss = 12.8896\n",
            "     Epoch 15: Train Loss = 0.7172, Val Loss = 13.6035\n",
            "     Epoch 20: Train Loss = 0.7218, Val Loss = 13.4450\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 7.1998\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6956%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8294, Val Loss = 7.8195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7328, Val Loss = 12.9321\n",
            "     Epoch 10: Train Loss = 0.7215, Val Loss = 15.0583\n",
            "     Epoch 15: Train Loss = 0.7306, Val Loss = 14.9521\n",
            "     Epoch 20: Train Loss = 0.7271, Val Loss = 15.1541\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 7.8195\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1789%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8117, Val Loss = 7.0364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7329, Val Loss = 11.2295\n",
            "     Epoch 10: Train Loss = 0.7282, Val Loss = 13.1359\n",
            "     Epoch 15: Train Loss = 0.7231, Val Loss = 13.1135\n",
            "     Epoch 20: Train Loss = 0.7283, Val Loss = 13.4782\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 7.0364\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6732%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7563, Val Loss = 9.1028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7307, Val Loss = 11.6087\n",
            "     Epoch 10: Train Loss = 0.7248, Val Loss = 12.9024\n",
            "     Epoch 15: Train Loss = 0.7176, Val Loss = 13.0236\n",
            "     Epoch 20: Train Loss = 0.7252, Val Loss = 13.1003\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 9.1028\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5930%\n",
            " Finished configuration H=64, D=0.1, LR=0.0001, B=32 → Avg Val Loss: 7.7070, Avg Accuracy: 3.8136%\n",
            "\n",
            " Running 40/81: H=64, D=0.1, LR=0.0005, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7479, Val Loss = 18.5239\n",
            "     Epoch 5: Train Loss = 0.7172, Val Loss = 13.2740\n",
            "     Epoch 10: Train Loss = 0.7249, Val Loss = 12.2924\n",
            "     Epoch 15: Train Loss = 0.7195, Val Loss = 14.8598\n",
            "     Epoch 20: Train Loss = 0.7272, Val Loss = 13.2042\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 1 finished with best val loss: 10.4546\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0315%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7866, Val Loss = 12.2045\n",
            "     Epoch 5: Train Loss = 0.7336, Val Loss = 14.7065\n",
            "     Epoch 10: Train Loss = 0.7244, Val Loss = 13.5411\n",
            "     Epoch 15: Train Loss = 0.7225, Val Loss = 15.4341\n",
            "     Epoch 20: Train Loss = 0.7227, Val Loss = 14.7624\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 12.2045\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1167%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7682, Val Loss = 14.3956\n",
            "     Epoch 5: Train Loss = 0.7192, Val Loss = 13.3635\n",
            "     Epoch 10: Train Loss = 0.7249, Val Loss = 13.6608\n",
            "     Epoch 15: Train Loss = 0.7195, Val Loss = 13.2785\n",
            "     Epoch 20: Train Loss = 0.7235, Val Loss = 11.1466\n",
            "     Epoch 25: Train Loss = 0.7193, Val Loss = 14.7477\n",
            "     Epoch 30: Train Loss = 0.7136, Val Loss = 13.3165\n",
            "     Epoch 35: Train Loss = 0.7211, Val Loss = 16.0519\n",
            "     Epoch 40: Train Loss = 0.7195, Val Loss = 13.4406\n",
            "    ⏹️ Early stopping at epoch 40\n",
            " Run 3 finished with best val loss: 11.1466\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7753%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7612, Val Loss = 12.2235\n",
            "     Epoch 5: Train Loss = 0.7256, Val Loss = 11.2124\n",
            "     Epoch 10: Train Loss = 0.7255, Val Loss = 12.7135\n",
            "     Epoch 15: Train Loss = 0.7217, Val Loss = 14.1311\n",
            "     Epoch 20: Train Loss = 0.7217, Val Loss = 14.1107\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 4 finished with best val loss: 10.7784\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1251%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7530, Val Loss = 15.4305\n",
            "     Epoch 5: Train Loss = 0.7212, Val Loss = 13.7727\n",
            "     Epoch 10: Train Loss = 0.7262, Val Loss = 13.7525\n",
            "     Epoch 15: Train Loss = 0.7109, Val Loss = 16.6186\n",
            "     Epoch 20: Train Loss = 0.7204, Val Loss = 16.7949\n",
            "     Epoch 25: Train Loss = 0.7144, Val Loss = 16.1505\n",
            "    ⏹️ Early stopping at epoch 26\n",
            " Run 5 finished with best val loss: 11.6227\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.3933%\n",
            " Finished configuration H=64, D=0.1, LR=0.0005, B=8 → Avg Val Loss: 11.2414, Avg Accuracy: 4.2884%\n",
            "\n",
            " Running 41/81: H=64, D=0.1, LR=0.0005, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7598, Val Loss = 12.3616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7190, Val Loss = 14.6351\n",
            "     Epoch 10: Train Loss = 0.7222, Val Loss = 15.2152\n",
            "     Epoch 15: Train Loss = 0.7116, Val Loss = 13.8515\n",
            "     Epoch 20: Train Loss = 0.7188, Val Loss = 14.9832\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 12.3616\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1523%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7566, Val Loss = 12.2794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7264, Val Loss = 13.8252\n",
            "     Epoch 10: Train Loss = 0.7217, Val Loss = 15.4277\n",
            "     Epoch 15: Train Loss = 0.7222, Val Loss = 14.7651\n",
            "     Epoch 20: Train Loss = 0.7227, Val Loss = 15.5090\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 2 finished with best val loss: 11.6117\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0450%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7460, Val Loss = 14.4917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7285, Val Loss = 13.9964\n",
            "     Epoch 10: Train Loss = 0.7325, Val Loss = 12.6429\n",
            "     Epoch 15: Train Loss = 0.7205, Val Loss = 13.6213\n",
            "     Epoch 20: Train Loss = 0.7159, Val Loss = 14.7264\n",
            "     Epoch 25: Train Loss = 0.7196, Val Loss = 14.0272\n",
            "     Epoch 30: Train Loss = 0.7234, Val Loss = 14.0736\n",
            "    ⏹️ Early stopping at epoch 31\n",
            " Run 3 finished with best val loss: 12.1557\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7984%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7874, Val Loss = 14.0264\n",
            "     Epoch 5: Train Loss = 0.7298, Val Loss = 14.7968\n",
            "     Epoch 10: Train Loss = 0.7206, Val Loss = 16.0297\n",
            "     Epoch 15: Train Loss = 0.7226, Val Loss = 16.7339\n",
            "     Epoch 20: Train Loss = 0.7169, Val Loss = 18.5477\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 4 finished with best val loss: 12.1789\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.3238%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7647, Val Loss = 12.7638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7252, Val Loss = 12.5074\n",
            "     Epoch 10: Train Loss = 0.7271, Val Loss = 15.1444\n",
            "     Epoch 15: Train Loss = 0.7160, Val Loss = 14.0486\n",
            "     Epoch 20: Train Loss = 0.7243, Val Loss = 13.0101\n",
            "     Epoch 25: Train Loss = 0.7169, Val Loss = 14.1232\n",
            "    ⏹️ Early stopping at epoch 25\n",
            " Run 5 finished with best val loss: 12.5074\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9200%\n",
            " Finished configuration H=64, D=0.1, LR=0.0005, B=16 → Avg Val Loss: 12.1630, Avg Accuracy: 4.2479%\n",
            "\n",
            " Running 42/81: H=64, D=0.1, LR=0.0005, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7672, Val Loss = 12.1526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7253, Val Loss = 12.9801\n",
            "     Epoch 10: Train Loss = 0.7198, Val Loss = 13.6531\n",
            "     Epoch 15: Train Loss = 0.7222, Val Loss = 14.7416\n",
            "     Epoch 20: Train Loss = 0.7146, Val Loss = 15.9800\n",
            "     Epoch 25: Train Loss = 0.7132, Val Loss = 16.1432\n",
            "    ⏹️ Early stopping at epoch 27\n",
            " Run 1 finished with best val loss: 12.0748\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.5290%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8009, Val Loss = 12.3150\n",
            "     Epoch 5: Train Loss = 0.7256, Val Loss = 14.0271\n",
            "     Epoch 10: Train Loss = 0.7197, Val Loss = 14.9746\n",
            "     Epoch 15: Train Loss = 0.7150, Val Loss = 14.1189\n",
            "     Epoch 20: Train Loss = 0.7234, Val Loss = 13.9429\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 12.3150\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8806%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8094, Val Loss = 9.0512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7164, Val Loss = 14.2578\n",
            "     Epoch 10: Train Loss = 0.7187, Val Loss = 15.2757\n",
            "     Epoch 15: Train Loss = 0.7177, Val Loss = 13.6979\n",
            "     Epoch 20: Train Loss = 0.7258, Val Loss = 14.9851\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 9.0512\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1885%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7857, Val Loss = 10.1529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7191, Val Loss = 12.2236\n",
            "     Epoch 10: Train Loss = 0.7262, Val Loss = 11.9169\n",
            "     Epoch 15: Train Loss = 0.7230, Val Loss = 12.4661\n",
            "     Epoch 20: Train Loss = 0.7213, Val Loss = 13.4950\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 10.1529\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7535%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7978, Val Loss = 10.6495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7207, Val Loss = 13.7537\n",
            "     Epoch 10: Train Loss = 0.7248, Val Loss = 15.2501\n",
            "     Epoch 15: Train Loss = 0.7235, Val Loss = 15.9832\n",
            "     Epoch 20: Train Loss = 0.7229, Val Loss = 15.7489\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 10.6495\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4565%\n",
            " Finished configuration H=64, D=0.1, LR=0.0005, B=32 → Avg Val Loss: 10.8487, Avg Accuracy: 4.1616%\n",
            "\n",
            " Running 43/81: H=64, D=0.1, LR=0.001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7423, Val Loss = 11.5686\n",
            "     Epoch 5: Train Loss = 0.7223, Val Loss = 12.9613\n",
            "     Epoch 10: Train Loss = 0.7233, Val Loss = 13.1642\n",
            "     Epoch 15: Train Loss = 0.7181, Val Loss = 14.3099\n",
            "     Epoch 20: Train Loss = 0.7139, Val Loss = 16.2332\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 1 finished with best val loss: 10.4029\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1942%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7572, Val Loss = 17.4456\n",
            "     Epoch 5: Train Loss = 0.7226, Val Loss = 11.6524\n",
            "     Epoch 10: Train Loss = 0.7249, Val Loss = 14.6571\n",
            "     Epoch 15: Train Loss = 0.7209, Val Loss = 14.9067\n",
            "     Epoch 20: Train Loss = 0.7210, Val Loss = 14.3184\n",
            "     Epoch 25: Train Loss = 0.7222, Val Loss = 14.6946\n",
            "    ⏹️ Early stopping at epoch 29\n",
            " Run 2 finished with best val loss: 10.8471\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5030%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7294, Val Loss = 17.4905\n",
            "     Epoch 5: Train Loss = 0.7215, Val Loss = 13.0007\n",
            "     Epoch 10: Train Loss = 0.7284, Val Loss = 12.8596\n",
            "     Epoch 15: Train Loss = 0.7266, Val Loss = 17.7585\n",
            "     Epoch 20: Train Loss = 0.7212, Val Loss = 17.2686\n",
            "     Epoch 25: Train Loss = 0.7223, Val Loss = 14.2493\n",
            "    ⏹️ Early stopping at epoch 27\n",
            " Run 3 finished with best val loss: 11.2139\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1662%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7502, Val Loss = 10.9782\n",
            "     Epoch 5: Train Loss = 0.7269, Val Loss = 13.4857\n",
            "     Epoch 10: Train Loss = 0.7267, Val Loss = 11.8779\n",
            "     Epoch 15: Train Loss = 0.7263, Val Loss = 12.1236\n",
            "     Epoch 20: Train Loss = 0.7213, Val Loss = 16.8831\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 10.9782\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.5801%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7336, Val Loss = 17.5905\n",
            "     Epoch 5: Train Loss = 0.7196, Val Loss = 18.7150\n",
            "     Epoch 10: Train Loss = 0.7211, Val Loss = 17.7853\n",
            "     Epoch 15: Train Loss = 0.7162, Val Loss = 16.1110\n",
            "     Epoch 20: Train Loss = 0.7148, Val Loss = 19.9139\n",
            "     Epoch 25: Train Loss = 0.7144, Val Loss = 20.6160\n",
            "     Epoch 30: Train Loss = 0.7209, Val Loss = 16.9237\n",
            "    ⏹️ Early stopping at epoch 34\n",
            " Run 5 finished with best val loss: 13.0127\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.0348%\n",
            " Finished configuration H=64, D=0.1, LR=0.001, B=8 → Avg Val Loss: 11.2909, Avg Accuracy: 4.2957%\n",
            "\n",
            " Running 44/81: H=64, D=0.1, LR=0.001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7403, Val Loss = 13.6499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7202, Val Loss = 14.6208\n",
            "     Epoch 10: Train Loss = 0.7262, Val Loss = 14.1252\n",
            "     Epoch 15: Train Loss = 0.7306, Val Loss = 16.6163\n",
            "     Epoch 20: Train Loss = 0.7224, Val Loss = 16.8137\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 1 finished with best val loss: 12.9593\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 6.4773%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7447, Val Loss = 11.3865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7266, Val Loss = 12.0454\n",
            "     Epoch 10: Train Loss = 0.7302, Val Loss = 12.2716\n",
            "     Epoch 15: Train Loss = 0.7167, Val Loss = 12.0054\n",
            "     Epoch 20: Train Loss = 0.7167, Val Loss = 16.2047\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 2 finished with best val loss: 9.2590\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9269%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7535, Val Loss = 13.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7295, Val Loss = 18.1931\n",
            "     Epoch 10: Train Loss = 0.7195, Val Loss = 15.7862\n",
            "     Epoch 15: Train Loss = 0.7267, Val Loss = 15.4114\n",
            "     Epoch 20: Train Loss = 0.7204, Val Loss = 14.2314\n",
            "     Epoch 25: Train Loss = 0.7239, Val Loss = 15.8082\n",
            "    ⏹️ Early stopping at epoch 26\n",
            " Run 3 finished with best val loss: 11.3791\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3569%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7426, Val Loss = 13.8911\n",
            "     Epoch 5: Train Loss = 0.7265, Val Loss = 14.0140\n",
            "     Epoch 10: Train Loss = 0.7129, Val Loss = 12.2883\n",
            "     Epoch 15: Train Loss = 0.7254, Val Loss = 14.5504\n",
            "     Epoch 20: Train Loss = 0.7225, Val Loss = 13.3140\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 4 finished with best val loss: 10.8219\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6831%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7444, Val Loss = 11.4261\n",
            "     Epoch 5: Train Loss = 0.7224, Val Loss = 13.8778\n",
            "     Epoch 10: Train Loss = 0.7251, Val Loss = 15.0895\n",
            "     Epoch 15: Train Loss = 0.7224, Val Loss = 12.5316\n",
            "     Epoch 20: Train Loss = 0.7217, Val Loss = 14.7984\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 11.4261\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0725%\n",
            " Finished configuration H=64, D=0.1, LR=0.001, B=16 → Avg Val Loss: 11.1691, Avg Accuracy: 4.5033%\n",
            "\n",
            " Running 45/81: H=64, D=0.1, LR=0.001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7642, Val Loss = 16.1029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7231, Val Loss = 14.2599\n",
            "     Epoch 10: Train Loss = 0.7329, Val Loss = 13.4270\n",
            "     Epoch 15: Train Loss = 0.7102, Val Loss = 15.2449\n",
            "     Epoch 20: Train Loss = 0.7288, Val Loss = 16.9909\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 1 finished with best val loss: 13.2477\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.9228%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7471, Val Loss = 16.7092\n",
            "     Epoch 5: Train Loss = 0.7265, Val Loss = 14.8371\n",
            "     Epoch 10: Train Loss = 0.7166, Val Loss = 16.9489\n",
            "     Epoch 15: Train Loss = 0.7182, Val Loss = 14.6092\n",
            "     Epoch 20: Train Loss = 0.7188, Val Loss = 17.7592\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 2 finished with best val loss: 11.2464\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4952%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7407, Val Loss = 15.2955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7275, Val Loss = 12.3730\n",
            "     Epoch 10: Train Loss = 0.7161, Val Loss = 13.5427\n",
            "     Epoch 15: Train Loss = 0.7255, Val Loss = 14.6915\n",
            "     Epoch 20: Train Loss = 0.7207, Val Loss = 16.9479\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 3 finished with best val loss: 11.7122\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.9746%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7445, Val Loss = 14.4281\n",
            "     Epoch 5: Train Loss = 0.7260, Val Loss = 14.6914\n",
            "     Epoch 10: Train Loss = 0.7314, Val Loss = 13.3594\n",
            "     Epoch 15: Train Loss = 0.7149, Val Loss = 13.4918\n",
            "     Epoch 20: Train Loss = 0.7215, Val Loss = 14.8395\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 4 finished with best val loss: 12.0079\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2622%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7835, Val Loss = 14.7935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7272, Val Loss = 13.5658\n",
            "     Epoch 10: Train Loss = 0.7168, Val Loss = 16.3076\n",
            "     Epoch 15: Train Loss = 0.7219, Val Loss = 15.6115\n",
            "     Epoch 20: Train Loss = 0.7245, Val Loss = 14.4643\n",
            "    ⏹️ Early stopping at epoch 24\n",
            " Run 5 finished with best val loss: 12.0624\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.8986%\n",
            " Finished configuration H=64, D=0.1, LR=0.001, B=32 → Avg Val Loss: 12.0553, Avg Accuracy: 4.7107%\n",
            "\n",
            " Running 46/81: H=64, D=0.2, LR=0.0001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8399, Val Loss = 7.1903\n",
            "     Epoch 5: Train Loss = 0.7144, Val Loss = 13.2737\n",
            "     Epoch 10: Train Loss = 0.7209, Val Loss = 13.9583\n",
            "     Epoch 15: Train Loss = 0.7220, Val Loss = 13.9497\n",
            "     Epoch 20: Train Loss = 0.7248, Val Loss = 14.1642\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 7.1903\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8833%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8024, Val Loss = 10.2881\n",
            "     Epoch 5: Train Loss = 0.7207, Val Loss = 15.7578\n",
            "     Epoch 10: Train Loss = 0.7419, Val Loss = 15.1404\n",
            "     Epoch 15: Train Loss = 0.7268, Val Loss = 14.2290\n",
            "     Epoch 20: Train Loss = 0.7189, Val Loss = 14.7852\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 10.2881\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0274%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7700, Val Loss = 11.3524\n",
            "     Epoch 5: Train Loss = 0.7224, Val Loss = 14.0475\n",
            "     Epoch 10: Train Loss = 0.7431, Val Loss = 13.1501\n",
            "     Epoch 15: Train Loss = 0.7281, Val Loss = 13.8663\n",
            "     Epoch 20: Train Loss = 0.7285, Val Loss = 12.7878\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 11.3524\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5832%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8154, Val Loss = 6.4674\n",
            "     Epoch 5: Train Loss = 0.7370, Val Loss = 10.7101\n",
            "     Epoch 10: Train Loss = 0.7275, Val Loss = 11.1671\n",
            "     Epoch 15: Train Loss = 0.7309, Val Loss = 11.5034\n",
            "     Epoch 20: Train Loss = 0.7279, Val Loss = 11.8905\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 6.4674\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.3475%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8742, Val Loss = 6.5117\n",
            "     Epoch 5: Train Loss = 0.7460, Val Loss = 12.3161\n",
            "     Epoch 10: Train Loss = 0.7240, Val Loss = 12.5614\n",
            "     Epoch 15: Train Loss = 0.7311, Val Loss = 12.5683\n",
            "     Epoch 20: Train Loss = 0.7340, Val Loss = 12.5388\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 6.5117\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.4679%\n",
            " Finished configuration H=64, D=0.2, LR=0.0001, B=8 → Avg Val Loss: 8.3620, Avg Accuracy: 3.6619%\n",
            "\n",
            " Running 47/81: H=64, D=0.2, LR=0.0001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.9360, Val Loss = 6.8520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7429, Val Loss = 15.1622\n",
            "     Epoch 10: Train Loss = 0.7261, Val Loss = 15.1925\n",
            "     Epoch 15: Train Loss = 0.7213, Val Loss = 14.5943\n",
            "     Epoch 20: Train Loss = 0.7255, Val Loss = 14.6786\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 6.8520\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9845%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7908, Val Loss = 7.2693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7389, Val Loss = 9.7515\n",
            "     Epoch 10: Train Loss = 0.7472, Val Loss = 10.6079\n",
            "     Epoch 15: Train Loss = 0.7313, Val Loss = 10.8985\n",
            "     Epoch 20: Train Loss = 0.7390, Val Loss = 11.4233\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 7.2693\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2857%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.9543, Val Loss = 5.8727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7435, Val Loss = 10.7297\n",
            "     Epoch 10: Train Loss = 0.7319, Val Loss = 12.5301\n",
            "     Epoch 15: Train Loss = 0.7291, Val Loss = 12.8698\n",
            "     Epoch 20: Train Loss = 0.7431, Val Loss = 13.0250\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 5.8727\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5971%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8261, Val Loss = 6.5779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7399, Val Loss = 9.4291\n",
            "     Epoch 10: Train Loss = 0.7275, Val Loss = 10.4707\n",
            "     Epoch 15: Train Loss = 0.7252, Val Loss = 10.8766\n",
            "     Epoch 20: Train Loss = 0.7231, Val Loss = 10.9486\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 6.5779\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.2077%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8953, Val Loss = 6.6679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7432, Val Loss = 14.9650\n",
            "     Epoch 10: Train Loss = 0.7212, Val Loss = 16.0783\n",
            "     Epoch 15: Train Loss = 0.7374, Val Loss = 15.4158\n",
            "     Epoch 20: Train Loss = 0.7215, Val Loss = 14.8556\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 6.6679\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0655%\n",
            " Finished configuration H=64, D=0.2, LR=0.0001, B=16 → Avg Val Loss: 6.6480, Avg Accuracy: 3.6281%\n",
            "\n",
            " Running 48/81: H=64, D=0.2, LR=0.0001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8354, Val Loss = 7.6539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7371, Val Loss = 12.7054\n",
            "     Epoch 10: Train Loss = 0.7297, Val Loss = 14.4223\n",
            "     Epoch 15: Train Loss = 0.7257, Val Loss = 14.8003\n",
            "     Epoch 20: Train Loss = 0.7334, Val Loss = 14.9297\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 7.6539\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0575%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.9059, Val Loss = 6.3038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7665, Val Loss = 11.3923\n",
            "     Epoch 10: Train Loss = 0.7439, Val Loss = 14.4500\n",
            "     Epoch 15: Train Loss = 0.7448, Val Loss = 14.9487\n",
            "     Epoch 20: Train Loss = 0.7324, Val Loss = 15.6598\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 6.3038\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1841%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8955, Val Loss = 6.4765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7445, Val Loss = 11.8717\n",
            "     Epoch 10: Train Loss = 0.7382, Val Loss = 12.9702\n",
            "     Epoch 15: Train Loss = 0.7334, Val Loss = 12.5514\n",
            "     Epoch 20: Train Loss = 0.7373, Val Loss = 12.8275\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 6.4765\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5368%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.8207, Val Loss = 8.5288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7575, Val Loss = 13.9846\n",
            "     Epoch 10: Train Loss = 0.7456, Val Loss = 15.1460\n",
            "     Epoch 15: Train Loss = 0.7425, Val Loss = 14.9822\n",
            "     Epoch 20: Train Loss = 0.7235, Val Loss = 14.3652\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 8.5288\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9399%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8178, Val Loss = 6.9867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7525, Val Loss = 9.8333\n",
            "     Epoch 10: Train Loss = 0.7317, Val Loss = 11.8313\n",
            "     Epoch 15: Train Loss = 0.7382, Val Loss = 13.0439\n",
            "     Epoch 20: Train Loss = 0.7302, Val Loss = 13.1108\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 6.9867\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5875%\n",
            " Finished configuration H=64, D=0.2, LR=0.0001, B=32 → Avg Val Loss: 7.1900, Avg Accuracy: 3.8612%\n",
            "\n",
            " Running 49/81: H=64, D=0.2, LR=0.0005, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7528, Val Loss = 13.9045\n",
            "     Epoch 5: Train Loss = 0.7299, Val Loss = 11.4589\n",
            "     Epoch 10: Train Loss = 0.7215, Val Loss = 13.5784\n",
            "     Epoch 15: Train Loss = 0.7300, Val Loss = 12.9335\n",
            "     Epoch 20: Train Loss = 0.7217, Val Loss = 14.8292\n",
            "     Epoch 25: Train Loss = 0.7263, Val Loss = 15.0715\n",
            "    ⏹️ Early stopping at epoch 27\n",
            " Run 1 finished with best val loss: 10.3373\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4518%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7585, Val Loss = 12.8792\n",
            "     Epoch 5: Train Loss = 0.7144, Val Loss = 16.4014\n",
            "     Epoch 10: Train Loss = 0.7300, Val Loss = 14.1700\n",
            "     Epoch 15: Train Loss = 0.7227, Val Loss = 14.0785\n",
            "     Epoch 20: Train Loss = 0.7161, Val Loss = 14.3892\n",
            "     Epoch 25: Train Loss = 0.7258, Val Loss = 13.8417\n",
            "     Epoch 30: Train Loss = 0.7187, Val Loss = 15.2097\n",
            "    ⏹️ Early stopping at epoch 31\n",
            " Run 2 finished with best val loss: 12.1462\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8586%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7645, Val Loss = 16.1723\n",
            "     Epoch 5: Train Loss = 0.7246, Val Loss = 12.1645\n",
            "     Epoch 10: Train Loss = 0.7350, Val Loss = 15.3746\n",
            "     Epoch 15: Train Loss = 0.7224, Val Loss = 14.6749\n",
            "     Epoch 20: Train Loss = 0.7254, Val Loss = 16.2830\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 3 finished with best val loss: 10.9687\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3597%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7678, Val Loss = 16.3929\n",
            "     Epoch 5: Train Loss = 0.7326, Val Loss = 16.2947\n",
            "     Epoch 10: Train Loss = 0.7282, Val Loss = 14.9100\n",
            "     Epoch 15: Train Loss = 0.7311, Val Loss = 14.9783\n",
            "     Epoch 20: Train Loss = 0.7266, Val Loss = 15.0716\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 4 finished with best val loss: 12.9856\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.7059%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7793, Val Loss = 14.0672\n",
            "     Epoch 5: Train Loss = 0.7302, Val Loss = 14.9380\n",
            "     Epoch 10: Train Loss = 0.7321, Val Loss = 16.0278\n",
            "     Epoch 15: Train Loss = 0.7233, Val Loss = 13.6559\n",
            "     Epoch 20: Train Loss = 0.7234, Val Loss = 14.7863\n",
            "     Epoch 25: Train Loss = 0.7197, Val Loss = 16.0213\n",
            "     Epoch 30: Train Loss = 0.7288, Val Loss = 13.7770\n",
            "     Epoch 35: Train Loss = 0.7232, Val Loss = 15.5504\n",
            "     Epoch 40: Train Loss = 0.7228, Val Loss = 15.3376\n",
            "    ⏹️ Early stopping at epoch 44\n",
            " Run 5 finished with best val loss: 12.9388\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0360%\n",
            " Finished configuration H=64, D=0.2, LR=0.0005, B=8 → Avg Val Loss: 11.8753, Avg Accuracy: 4.2824%\n",
            "\n",
            " Running 50/81: H=64, D=0.2, LR=0.0005, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7617, Val Loss = 12.7124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7411, Val Loss = 14.6462\n",
            "     Epoch 10: Train Loss = 0.7352, Val Loss = 13.6210\n",
            "     Epoch 15: Train Loss = 0.7248, Val Loss = 14.7076\n",
            "     Epoch 20: Train Loss = 0.7182, Val Loss = 14.9934\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 1 finished with best val loss: 12.3133\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2794%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7523, Val Loss = 14.0191\n",
            "     Epoch 5: Train Loss = 0.7288, Val Loss = 12.8634\n",
            "     Epoch 10: Train Loss = 0.7273, Val Loss = 13.2943\n",
            "     Epoch 15: Train Loss = 0.7299, Val Loss = 13.7728\n",
            "     Epoch 20: Train Loss = 0.7246, Val Loss = 14.8459\n",
            "     Epoch 25: Train Loss = 0.7255, Val Loss = 15.2946\n",
            "    ⏹️ Early stopping at epoch 26\n",
            " Run 2 finished with best val loss: 12.4627\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3149%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7850, Val Loss = 11.6930\n",
            "     Epoch 5: Train Loss = 0.7202, Val Loss = 14.4371\n",
            "     Epoch 10: Train Loss = 0.7330, Val Loss = 12.6881\n",
            "     Epoch 15: Train Loss = 0.7282, Val Loss = 13.5273\n",
            "     Epoch 20: Train Loss = 0.7205, Val Loss = 14.3613\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 11.6930\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9620%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7575, Val Loss = 13.0119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7197, Val Loss = 12.3957\n",
            "     Epoch 10: Train Loss = 0.7271, Val Loss = 12.3318\n",
            "     Epoch 15: Train Loss = 0.7202, Val Loss = 11.9413\n",
            "     Epoch 20: Train Loss = 0.7183, Val Loss = 12.9690\n",
            "     Epoch 25: Train Loss = 0.7154, Val Loss = 13.9266\n",
            "    ⏹️ Early stopping at epoch 27\n",
            " Run 4 finished with best val loss: 11.2577\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9027%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7976, Val Loss = 13.2062\n",
            "     Epoch 5: Train Loss = 0.7229, Val Loss = 13.7039\n",
            "     Epoch 10: Train Loss = 0.7181, Val Loss = 13.9718\n",
            "     Epoch 15: Train Loss = 0.7191, Val Loss = 12.7289\n",
            "     Epoch 20: Train Loss = 0.7302, Val Loss = 12.6083\n",
            "     Epoch 25: Train Loss = 0.7218, Val Loss = 12.5680\n",
            "     Epoch 30: Train Loss = 0.7277, Val Loss = 13.5713\n",
            "     Epoch 35: Train Loss = 0.7212, Val Loss = 13.6288\n",
            "    ⏹️ Early stopping at epoch 39\n",
            " Run 5 finished with best val loss: 11.9621\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8677%\n",
            " Finished configuration H=64, D=0.2, LR=0.0005, B=16 → Avg Val Loss: 11.9378, Avg Accuracy: 4.0653%\n",
            "\n",
            " Running 51/81: H=64, D=0.2, LR=0.0005, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7679, Val Loss = 11.0739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7267, Val Loss = 14.0445\n",
            "     Epoch 10: Train Loss = 0.7222, Val Loss = 12.8354\n",
            "     Epoch 15: Train Loss = 0.7185, Val Loss = 13.4422\n",
            "     Epoch 20: Train Loss = 0.7178, Val Loss = 13.9837\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 11.0739\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8993%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7664, Val Loss = 14.7376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7263, Val Loss = 13.8617\n",
            "     Epoch 10: Train Loss = 0.7330, Val Loss = 13.3680\n",
            "     Epoch 15: Train Loss = 0.7200, Val Loss = 12.5425\n",
            "     Epoch 20: Train Loss = 0.7271, Val Loss = 14.6655\n",
            "     Epoch 25: Train Loss = 0.7272, Val Loss = 14.0168\n",
            "     Epoch 30: Train Loss = 0.7220, Val Loss = 13.2947\n",
            "     Epoch 35: Train Loss = 0.7220, Val Loss = 14.2484\n",
            "    ⏹️ Early stopping at epoch 35\n",
            " Run 2 finished with best val loss: 12.5425\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0210%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7804, Val Loss = 13.2070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7582, Val Loss = 13.9119\n",
            "     Epoch 10: Train Loss = 0.7300, Val Loss = 12.8942\n",
            "     Epoch 15: Train Loss = 0.7269, Val Loss = 12.9243\n",
            "     Epoch 20: Train Loss = 0.7346, Val Loss = 12.6043\n",
            "     Epoch 25: Train Loss = 0.7216, Val Loss = 14.2736\n",
            "     Epoch 30: Train Loss = 0.7267, Val Loss = 13.4570\n",
            "    ⏹️ Early stopping at epoch 32\n",
            " Run 3 finished with best val loss: 12.2879\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7688%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7515, Val Loss = 13.8889\n",
            "     Epoch 5: Train Loss = 0.7336, Val Loss = 12.4711\n",
            "     Epoch 10: Train Loss = 0.7238, Val Loss = 12.4294\n",
            "     Epoch 15: Train Loss = 0.7222, Val Loss = 13.0466\n",
            "     Epoch 20: Train Loss = 0.7252, Val Loss = 13.4179\n",
            "     Epoch 25: Train Loss = 0.7197, Val Loss = 12.5846\n",
            "     Epoch 30: Train Loss = 0.7250, Val Loss = 13.4030\n",
            "    ⏹️ Early stopping at epoch 30\n",
            " Run 4 finished with best val loss: 12.4294\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7565%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7918, Val Loss = 13.7297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7340, Val Loss = 13.3668\n",
            "     Epoch 10: Train Loss = 0.7227, Val Loss = 15.3947\n",
            "     Epoch 15: Train Loss = 0.7303, Val Loss = 13.6237\n",
            "     Epoch 20: Train Loss = 0.7328, Val Loss = 15.3364\n",
            "     Epoch 25: Train Loss = 0.7201, Val Loss = 16.1411\n",
            "    ⏹️ Early stopping at epoch 25\n",
            " Run 5 finished with best val loss: 13.3668\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4886%\n",
            " Finished configuration H=64, D=0.2, LR=0.0005, B=32 → Avg Val Loss: 12.3401, Avg Accuracy: 3.9868%\n",
            "\n",
            " Running 52/81: H=64, D=0.2, LR=0.001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7532, Val Loss = 14.1413\n",
            "     Epoch 5: Train Loss = 0.7375, Val Loss = 13.4377\n",
            "     Epoch 10: Train Loss = 0.7298, Val Loss = 15.1340\n",
            "     Epoch 15: Train Loss = 0.7369, Val Loss = 13.7740\n",
            "     Epoch 20: Train Loss = 0.7197, Val Loss = 13.5495\n",
            "     Epoch 25: Train Loss = 0.7241, Val Loss = 17.2737\n",
            "     Epoch 30: Train Loss = 0.7195, Val Loss = 17.2864\n",
            "     Epoch 35: Train Loss = 0.7210, Val Loss = 16.5483\n",
            "    ⏹️ Early stopping at epoch 36\n",
            " Run 1 finished with best val loss: 11.3768\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9122%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7471, Val Loss = 21.1535\n",
            "     Epoch 5: Train Loss = 0.7304, Val Loss = 12.5867\n",
            "     Epoch 10: Train Loss = 0.7250, Val Loss = 14.2166\n",
            "     Epoch 15: Train Loss = 0.7287, Val Loss = 12.5001\n",
            "     Epoch 20: Train Loss = 0.7235, Val Loss = 16.4183\n",
            "     Epoch 25: Train Loss = 0.7287, Val Loss = 13.5023\n",
            "    ⏹️ Early stopping at epoch 27\n",
            " Run 2 finished with best val loss: 11.2926\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8079%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7485, Val Loss = 10.7221\n",
            "     Epoch 5: Train Loss = 0.7232, Val Loss = 12.5671\n",
            "     Epoch 10: Train Loss = 0.7354, Val Loss = 13.8007\n",
            "     Epoch 15: Train Loss = 0.7297, Val Loss = 13.0353\n",
            "     Epoch 20: Train Loss = 0.7292, Val Loss = 13.3266\n",
            "     Epoch 25: Train Loss = 0.7232, Val Loss = 11.3237\n",
            "     Epoch 30: Train Loss = 0.7214, Val Loss = 12.2478\n",
            "     Epoch 35: Train Loss = 0.7193, Val Loss = 12.9091\n",
            "     Epoch 40: Train Loss = 0.7295, Val Loss = 14.0803\n",
            "    ⏹️ Early stopping at epoch 44\n",
            " Run 3 finished with best val loss: 10.5075\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6893%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7460, Val Loss = 13.5430\n",
            "     Epoch 5: Train Loss = 0.7387, Val Loss = 12.1785\n",
            "     Epoch 10: Train Loss = 0.7223, Val Loss = 13.2073\n",
            "     Epoch 15: Train Loss = 0.7240, Val Loss = 14.2984\n",
            "     Epoch 20: Train Loss = 0.7191, Val Loss = 17.5203\n",
            "     Epoch 25: Train Loss = 0.7198, Val Loss = 12.5683\n",
            "    ⏹️ Early stopping at epoch 26\n",
            " Run 4 finished with best val loss: 10.2050\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4674%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7520, Val Loss = 14.7409\n",
            "     Epoch 5: Train Loss = 0.7283, Val Loss = 13.8961\n",
            "     Epoch 10: Train Loss = 0.7236, Val Loss = 14.5732\n",
            "     Epoch 15: Train Loss = 0.7222, Val Loss = 13.5102\n",
            "     Epoch 20: Train Loss = 0.7237, Val Loss = 13.4535\n",
            "     Epoch 25: Train Loss = 0.7239, Val Loss = 15.5093\n",
            "    ⏹️ Early stopping at epoch 28\n",
            " Run 5 finished with best val loss: 12.1648\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.5042%\n",
            " Finished configuration H=64, D=0.2, LR=0.001, B=8 → Avg Val Loss: 11.1093, Avg Accuracy: 4.0762%\n",
            "\n",
            " Running 53/81: H=64, D=0.2, LR=0.001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7679, Val Loss = 14.9161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7164, Val Loss = 12.8899\n",
            "     Epoch 10: Train Loss = 0.7266, Val Loss = 15.6550\n",
            "     Epoch 15: Train Loss = 0.7267, Val Loss = 16.1336\n",
            "     Epoch 20: Train Loss = 0.7186, Val Loss = 18.4349\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 1 finished with best val loss: 10.9160\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4392%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7599, Val Loss = 14.3331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7249, Val Loss = 15.0566\n",
            "     Epoch 10: Train Loss = 0.7213, Val Loss = 17.0769\n",
            "     Epoch 15: Train Loss = 0.7265, Val Loss = 16.9375\n",
            "     Epoch 20: Train Loss = 0.7222, Val Loss = 15.8962\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 2 finished with best val loss: 12.7711\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.6008%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7500, Val Loss = 12.3360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7326, Val Loss = 12.2540\n",
            "     Epoch 10: Train Loss = 0.7249, Val Loss = 14.5151\n",
            "     Epoch 15: Train Loss = 0.7235, Val Loss = 15.2609\n",
            "     Epoch 20: Train Loss = 0.7216, Val Loss = 13.9127\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 3 finished with best val loss: 10.9390\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0493%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7534, Val Loss = 13.8138\n",
            "     Epoch 5: Train Loss = 0.7179, Val Loss = 13.2506\n",
            "     Epoch 10: Train Loss = 0.7232, Val Loss = 12.8725\n",
            "     Epoch 15: Train Loss = 0.7185, Val Loss = 13.0187\n",
            "     Epoch 20: Train Loss = 0.7248, Val Loss = 14.1228\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 4 finished with best val loss: 11.1458\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2595%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7408, Val Loss = 11.0291\n",
            "     Epoch 5: Train Loss = 0.7289, Val Loss = 10.8095\n",
            "     Epoch 10: Train Loss = 0.7275, Val Loss = 13.4275\n",
            "     Epoch 15: Train Loss = 0.7260, Val Loss = 11.6317\n",
            "     Epoch 20: Train Loss = 0.7212, Val Loss = 13.3082\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 5 finished with best val loss: 10.3686\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8936%\n",
            " Finished configuration H=64, D=0.2, LR=0.001, B=16 → Avg Val Loss: 11.2281, Avg Accuracy: 4.2485%\n",
            "\n",
            " Running 54/81: H=64, D=0.2, LR=0.001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7763, Val Loss = 16.1055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7289, Val Loss = 11.5882\n",
            "     Epoch 10: Train Loss = 0.7312, Val Loss = 12.9701\n",
            "     Epoch 15: Train Loss = 0.7286, Val Loss = 12.5681\n",
            "     Epoch 20: Train Loss = 0.7197, Val Loss = 13.1833\n",
            "     Epoch 25: Train Loss = 0.7236, Val Loss = 13.2122\n",
            "    ⏹️ Early stopping at epoch 25\n",
            " Run 1 finished with best val loss: 11.5882\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6891%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7777, Val Loss = 15.3160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7289, Val Loss = 14.3708\n",
            "     Epoch 10: Train Loss = 0.7277, Val Loss = 13.1208\n",
            "     Epoch 15: Train Loss = 0.7269, Val Loss = 13.2749\n",
            "     Epoch 20: Train Loss = 0.7091, Val Loss = 15.0416\n",
            "     Epoch 25: Train Loss = 0.7146, Val Loss = 15.2286\n",
            "     Epoch 30: Train Loss = 0.7234, Val Loss = 17.3309\n",
            "    ⏹️ Early stopping at epoch 32\n",
            " Run 2 finished with best val loss: 11.3042\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.5306%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8141, Val Loss = 12.5703\n",
            "     Epoch 5: Train Loss = 0.7318, Val Loss = 12.5972\n",
            "     Epoch 10: Train Loss = 0.7185, Val Loss = 14.2899\n",
            "     Epoch 15: Train Loss = 0.7320, Val Loss = 12.0818\n",
            "     Epoch 20: Train Loss = 0.7249, Val Loss = 15.7051\n",
            "     Epoch 25: Train Loss = 0.7242, Val Loss = 13.2806\n",
            "     Epoch 30: Train Loss = 0.7175, Val Loss = 14.4686\n",
            "     Epoch 35: Train Loss = 0.7250, Val Loss = 15.4332\n",
            "    ⏹️ Early stopping at epoch 38\n",
            " Run 3 finished with best val loss: 10.3423\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2203%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7613, Val Loss = 14.1845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7375, Val Loss = 12.0479\n",
            "     Epoch 10: Train Loss = 0.7227, Val Loss = 14.5935\n",
            "     Epoch 15: Train Loss = 0.7194, Val Loss = 14.2698\n",
            "     Epoch 20: Train Loss = 0.7229, Val Loss = 13.4608\n",
            "     Epoch 25: Train Loss = 0.7329, Val Loss = 14.9815\n",
            "    ⏹️ Early stopping at epoch 25\n",
            " Run 4 finished with best val loss: 12.0479\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1667%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7741, Val Loss = 12.9140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7347, Val Loss = 12.7977\n",
            "     Epoch 10: Train Loss = 0.7305, Val Loss = 13.3927\n",
            "     Epoch 15: Train Loss = 0.7202, Val Loss = 12.8522\n",
            "     Epoch 20: Train Loss = 0.7191, Val Loss = 14.7943\n",
            "    ⏹️ Early stopping at epoch 24\n",
            " Run 5 finished with best val loss: 12.6341\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4345%\n",
            " Finished configuration H=64, D=0.2, LR=0.001, B=32 → Avg Val Loss: 11.5833, Avg Accuracy: 4.2082%\n",
            "\n",
            " Running 55/81: H=128, D=0.0, LR=0.0001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7462, Val Loss = 10.2756\n",
            "     Epoch 5: Train Loss = 0.7177, Val Loss = 12.3540\n",
            "     Epoch 10: Train Loss = 0.7166, Val Loss = 12.6210\n",
            "     Epoch 15: Train Loss = 0.7170, Val Loss = 12.2642\n",
            "     Epoch 20: Train Loss = 0.7158, Val Loss = 11.8913\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 10.2756\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.3596%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7715, Val Loss = 12.0807\n",
            "     Epoch 5: Train Loss = 0.7169, Val Loss = 13.8383\n",
            "     Epoch 10: Train Loss = 0.7160, Val Loss = 15.5230\n",
            "     Epoch 15: Train Loss = 0.7160, Val Loss = 14.7325\n",
            "     Epoch 20: Train Loss = 0.7140, Val Loss = 16.9725\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 12.0807\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.7000%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7555, Val Loss = 13.7877\n",
            "     Epoch 5: Train Loss = 0.7167, Val Loss = 16.3209\n",
            "     Epoch 10: Train Loss = 0.7167, Val Loss = 16.1361\n",
            "     Epoch 15: Train Loss = 0.7174, Val Loss = 15.3583\n",
            "     Epoch 20: Train Loss = 0.7149, Val Loss = 16.0845\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 3 finished with best val loss: 13.7512\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3115%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7611, Val Loss = 17.5398\n",
            "     Epoch 5: Train Loss = 0.7182, Val Loss = 15.8324\n",
            "     Epoch 10: Train Loss = 0.7170, Val Loss = 15.9946\n",
            "     Epoch 15: Train Loss = 0.7164, Val Loss = 15.1989\n",
            "     Epoch 20: Train Loss = 0.7150, Val Loss = 14.7424\n",
            "     Epoch 25: Train Loss = 0.7152, Val Loss = 17.1202\n",
            "     Epoch 30: Train Loss = 0.7148, Val Loss = 16.7268\n",
            "     Epoch 35: Train Loss = 0.7134, Val Loss = 17.5401\n",
            "    ⏹️ Early stopping at epoch 38\n",
            " Run 4 finished with best val loss: 14.1090\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.4643%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7395, Val Loss = 12.5131\n",
            "     Epoch 5: Train Loss = 0.7186, Val Loss = 13.5409\n",
            "     Epoch 10: Train Loss = 0.7154, Val Loss = 17.4490\n",
            "     Epoch 15: Train Loss = 0.7157, Val Loss = 15.9326\n",
            "     Epoch 20: Train Loss = 0.7146, Val Loss = 16.1553\n",
            "     Epoch 25: Train Loss = 0.7154, Val Loss = 18.3681\n",
            "     Epoch 30: Train Loss = 0.7136, Val Loss = 18.5300\n",
            "     Epoch 35: Train Loss = 0.7126, Val Loss = 18.4633\n",
            "    ⏹️ Early stopping at epoch 38\n",
            " Run 5 finished with best val loss: 11.9217\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.7697%\n",
            " Finished configuration H=128, D=0.0, LR=0.0001, B=8 → Avg Val Loss: 12.4277, Avg Accuracy: 4.7210%\n",
            "\n",
            " Running 56/81: H=128, D=0.0, LR=0.0001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8788, Val Loss = 10.5770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7186, Val Loss = 15.2144\n",
            "     Epoch 10: Train Loss = 0.7172, Val Loss = 14.8219\n",
            "     Epoch 15: Train Loss = 0.7182, Val Loss = 13.9944\n",
            "     Epoch 20: Train Loss = 0.7160, Val Loss = 14.8397\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 10.5770\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1065%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7784, Val Loss = 10.4374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7176, Val Loss = 12.1382\n",
            "     Epoch 10: Train Loss = 0.7160, Val Loss = 12.6764\n",
            "     Epoch 15: Train Loss = 0.7176, Val Loss = 12.7603\n",
            "     Epoch 20: Train Loss = 0.7158, Val Loss = 13.1039\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 10.4374\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5920%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7977, Val Loss = 10.7704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7174, Val Loss = 12.6268\n",
            "     Epoch 10: Train Loss = 0.7167, Val Loss = 13.6671\n",
            "     Epoch 15: Train Loss = 0.7162, Val Loss = 13.9742\n",
            "     Epoch 20: Train Loss = 0.7181, Val Loss = 13.3630\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 10.7704\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7236%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7636, Val Loss = 10.3852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7160, Val Loss = 14.2790\n",
            "     Epoch 10: Train Loss = 0.7153, Val Loss = 13.9221\n",
            "     Epoch 15: Train Loss = 0.7150, Val Loss = 13.8295\n",
            "     Epoch 20: Train Loss = 0.7146, Val Loss = 13.6685\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 10.3852\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8028%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8156, Val Loss = 7.9761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7185, Val Loss = 13.8327\n",
            "     Epoch 10: Train Loss = 0.7158, Val Loss = 13.9504\n",
            "     Epoch 15: Train Loss = 0.7161, Val Loss = 13.5732\n",
            "     Epoch 20: Train Loss = 0.7154, Val Loss = 14.3810\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 7.9761\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9540%\n",
            " Finished configuration H=128, D=0.0, LR=0.0001, B=16 → Avg Val Loss: 10.0292, Avg Accuracy: 3.8358%\n",
            "\n",
            " Running 57/81: H=128, D=0.0, LR=0.0001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7414, Val Loss = 13.1126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7173, Val Loss = 15.1021\n",
            "     Epoch 10: Train Loss = 0.7162, Val Loss = 14.7544\n",
            "     Epoch 15: Train Loss = 0.7153, Val Loss = 14.1513\n",
            "     Epoch 20: Train Loss = 0.7149, Val Loss = 14.7078\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 13.1126\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0388%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8597, Val Loss = 6.6193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7171, Val Loss = 11.8808\n",
            "     Epoch 10: Train Loss = 0.7163, Val Loss = 12.4130\n",
            "     Epoch 15: Train Loss = 0.7162, Val Loss = 12.5107\n",
            "     Epoch 20: Train Loss = 0.7150, Val Loss = 13.1575\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 6.6193\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6600%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7644, Val Loss = 10.2757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7154, Val Loss = 13.9079\n",
            "     Epoch 10: Train Loss = 0.7151, Val Loss = 13.3403\n",
            "     Epoch 15: Train Loss = 0.7139, Val Loss = 13.7223\n",
            "     Epoch 20: Train Loss = 0.7137, Val Loss = 13.9818\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 10.2757\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8405%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7696, Val Loss = 10.2497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7170, Val Loss = 14.5489\n",
            "     Epoch 10: Train Loss = 0.7158, Val Loss = 14.0976\n",
            "     Epoch 15: Train Loss = 0.7153, Val Loss = 14.3982\n",
            "     Epoch 20: Train Loss = 0.7147, Val Loss = 14.5300\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 10.2497\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9604%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8147, Val Loss = 7.9407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7162, Val Loss = 14.5959\n",
            "     Epoch 10: Train Loss = 0.7156, Val Loss = 14.9941\n",
            "     Epoch 15: Train Loss = 0.7151, Val Loss = 14.5688\n",
            "     Epoch 20: Train Loss = 0.7152, Val Loss = 14.7985\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 7.9407\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0385%\n",
            " Finished configuration H=128, D=0.0, LR=0.0001, B=32 → Avg Val Loss: 9.6396, Avg Accuracy: 3.9076%\n",
            "\n",
            " Running 58/81: H=128, D=0.0, LR=0.0005, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7276, Val Loss = 18.1408\n",
            "     Epoch 5: Train Loss = 0.7198, Val Loss = 16.6734\n",
            "     Epoch 10: Train Loss = 0.7191, Val Loss = 16.7600\n",
            "     Epoch 15: Train Loss = 0.7184, Val Loss = 14.3853\n",
            "     Epoch 20: Train Loss = 0.7161, Val Loss = 19.4542\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 1 finished with best val loss: 11.2469\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.3686%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7352, Val Loss = 12.4215\n",
            "     Epoch 5: Train Loss = 0.7172, Val Loss = 15.6770\n",
            "     Epoch 10: Train Loss = 0.7196, Val Loss = 17.1377\n",
            "     Epoch 15: Train Loss = 0.7180, Val Loss = 17.4925\n",
            "     Epoch 20: Train Loss = 0.7154, Val Loss = 22.8626\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 12.4215\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 6.3796%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7311, Val Loss = 15.9566\n",
            "     Epoch 5: Train Loss = 0.7206, Val Loss = 12.8754\n",
            "     Epoch 10: Train Loss = 0.7227, Val Loss = 16.6859\n",
            "     Epoch 15: Train Loss = 0.7186, Val Loss = 16.2273\n",
            "     Epoch 20: Train Loss = 0.7157, Val Loss = 22.6427\n",
            "    ⏹️ Early stopping at epoch 24\n",
            " Run 3 finished with best val loss: 11.7536\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 6.0142%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7351, Val Loss = 14.0565\n",
            "     Epoch 5: Train Loss = 0.7274, Val Loss = 14.6841\n",
            "     Epoch 10: Train Loss = 0.7189, Val Loss = 16.7552\n",
            "     Epoch 15: Train Loss = 0.7172, Val Loss = 14.6203\n",
            "     Epoch 20: Train Loss = 0.7202, Val Loss = 15.6317\n",
            "     Epoch 25: Train Loss = 0.7175, Val Loss = 14.5411\n",
            "    ⏹️ Early stopping at epoch 27\n",
            " Run 4 finished with best val loss: 10.7093\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3612%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7359, Val Loss = 14.9860\n",
            "     Epoch 5: Train Loss = 0.7244, Val Loss = 11.4672\n",
            "     Epoch 10: Train Loss = 0.7207, Val Loss = 15.3183\n",
            "     Epoch 15: Train Loss = 0.7152, Val Loss = 18.9140\n",
            "     Epoch 20: Train Loss = 0.7196, Val Loss = 17.8935\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 5 finished with best val loss: 9.1526\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.5085%\n",
            " Finished configuration H=128, D=0.0, LR=0.0005, B=8 → Avg Val Loss: 11.0568, Avg Accuracy: 5.3264%\n",
            "\n",
            " Running 59/81: H=128, D=0.0, LR=0.0005, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7438, Val Loss = 13.3074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7233, Val Loss = 14.4085\n",
            "     Epoch 10: Train Loss = 0.7216, Val Loss = 16.8281\n",
            "     Epoch 15: Train Loss = 0.7159, Val Loss = 16.5988\n",
            "     Epoch 20: Train Loss = 0.7180, Val Loss = 19.3872\n",
            "     Epoch 25: Train Loss = 0.7161, Val Loss = 20.6998\n",
            "    ⏹️ Early stopping at epoch 29\n",
            " Run 1 finished with best val loss: 12.6451\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 6.1725%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7342, Val Loss = 13.0275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7200, Val Loss = 13.2259\n",
            "     Epoch 10: Train Loss = 0.7198, Val Loss = 15.6990\n",
            "     Epoch 15: Train Loss = 0.7209, Val Loss = 21.1451\n",
            "     Epoch 20: Train Loss = 0.7146, Val Loss = 19.2924\n",
            "    ⏹️ Early stopping at epoch 24\n",
            " Run 2 finished with best val loss: 12.1460\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 6.4802%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7278, Val Loss = 15.5144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7215, Val Loss = 16.1801\n",
            "     Epoch 10: Train Loss = 0.7177, Val Loss = 18.1074\n",
            "     Epoch 15: Train Loss = 0.7188, Val Loss = 18.5849\n",
            "     Epoch 20: Train Loss = 0.7191, Val Loss = 15.9832\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 3 finished with best val loss: 9.5817\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.9090%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7360, Val Loss = 11.9567\n",
            "     Epoch 5: Train Loss = 0.7193, Val Loss = 15.1216\n",
            "     Epoch 10: Train Loss = 0.7171, Val Loss = 14.8606\n",
            "     Epoch 15: Train Loss = 0.7158, Val Loss = 18.0201\n",
            "     Epoch 20: Train Loss = 0.7140, Val Loss = 17.5305\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 11.9567\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.0587%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7437, Val Loss = 14.6736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7176, Val Loss = 17.5947\n",
            "     Epoch 10: Train Loss = 0.7185, Val Loss = 16.3740\n",
            "     Epoch 15: Train Loss = 0.7219, Val Loss = 17.7132\n",
            "     Epoch 20: Train Loss = 0.7157, Val Loss = 18.3887\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 5 finished with best val loss: 13.2858\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 6.7787%\n",
            " Finished configuration H=128, D=0.0, LR=0.0005, B=16 → Avg Val Loss: 11.9231, Avg Accuracy: 6.0798%\n",
            "\n",
            " Running 60/81: H=128, D=0.0, LR=0.0005, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7416, Val Loss = 16.8980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7191, Val Loss = 13.4911\n",
            "     Epoch 10: Train Loss = 0.7160, Val Loss = 15.1190\n",
            "     Epoch 15: Train Loss = 0.7165, Val Loss = 13.5996\n",
            "     Epoch 20: Train Loss = 0.7163, Val Loss = 14.8425\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 1 finished with best val loss: 12.3538\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9697%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7639, Val Loss = 15.4261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7175, Val Loss = 12.1189\n",
            "     Epoch 10: Train Loss = 0.7169, Val Loss = 13.1091\n",
            "     Epoch 15: Train Loss = 0.7166, Val Loss = 13.8833\n",
            "     Epoch 20: Train Loss = 0.7173, Val Loss = 15.4840\n",
            "     Epoch 25: Train Loss = 0.7149, Val Loss = 15.5927\n",
            "    ⏹️ Early stopping at epoch 25\n",
            " Run 2 finished with best val loss: 12.1189\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4383%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7756, Val Loss = 14.0890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7194, Val Loss = 12.6699\n",
            "     Epoch 10: Train Loss = 0.7207, Val Loss = 11.8891\n",
            "     Epoch 15: Train Loss = 0.7168, Val Loss = 14.8202\n",
            "     Epoch 20: Train Loss = 0.7156, Val Loss = 16.1404\n",
            "     Epoch 25: Train Loss = 0.7186, Val Loss = 15.1455\n",
            "     Epoch 30: Train Loss = 0.7198, Val Loss = 17.3255\n",
            "    ⏹️ Early stopping at epoch 30\n",
            " Run 3 finished with best val loss: 11.8891\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.8026%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7566, Val Loss = 14.7224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7181, Val Loss = 13.6086\n",
            "     Epoch 10: Train Loss = 0.7168, Val Loss = 14.9245\n",
            "     Epoch 15: Train Loss = 0.7182, Val Loss = 17.3284\n",
            "     Epoch 20: Train Loss = 0.7138, Val Loss = 15.1713\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 4 finished with best val loss: 12.4186\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4478%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7447, Val Loss = 14.1157\n",
            "     Epoch 5: Train Loss = 0.7168, Val Loss = 17.0195\n",
            "     Epoch 10: Train Loss = 0.7231, Val Loss = 18.5650\n",
            "     Epoch 15: Train Loss = 0.7178, Val Loss = 13.7733\n",
            "     Epoch 20: Train Loss = 0.7160, Val Loss = 20.7657\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 5 finished with best val loss: 12.0803\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.8332%\n",
            " Finished configuration H=128, D=0.0, LR=0.0005, B=32 → Avg Val Loss: 12.1721, Avg Accuracy: 4.6984%\n",
            "\n",
            " Running 61/81: H=128, D=0.0, LR=0.001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7434, Val Loss = 15.1104\n",
            "     Epoch 5: Train Loss = 0.7192, Val Loss = 22.1140\n",
            "     Epoch 10: Train Loss = 0.7190, Val Loss = 12.4478\n",
            "     Epoch 15: Train Loss = 0.7213, Val Loss = 16.7795\n",
            "     Epoch 20: Train Loss = 0.7187, Val Loss = 15.6900\n",
            "     Epoch 25: Train Loss = 0.7161, Val Loss = 15.1334\n",
            "     Epoch 30: Train Loss = 0.7162, Val Loss = 21.0308\n",
            "    ⏹️ Early stopping at epoch 30\n",
            " Run 1 finished with best val loss: 12.4478\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 6.0433%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7404, Val Loss = 13.4604\n",
            "     Epoch 5: Train Loss = 0.7249, Val Loss = 11.0850\n",
            "     Epoch 10: Train Loss = 0.7201, Val Loss = 11.2447\n",
            "     Epoch 15: Train Loss = 0.7174, Val Loss = 10.8041\n",
            "     Epoch 20: Train Loss = 0.7176, Val Loss = 14.2304\n",
            "     Epoch 25: Train Loss = 0.7193, Val Loss = 13.0756\n",
            "    ⏹️ Early stopping at epoch 28\n",
            " Run 2 finished with best val loss: 9.7307\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7741%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7423, Val Loss = 14.5314\n",
            "     Epoch 5: Train Loss = 0.7220, Val Loss = 13.7488\n",
            "     Epoch 10: Train Loss = 0.7193, Val Loss = 17.1348\n",
            "     Epoch 15: Train Loss = 0.7164, Val Loss = 17.9639\n",
            "     Epoch 20: Train Loss = 0.7213, Val Loss = 12.5581\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 3 finished with best val loss: 10.8115\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.5721%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7387, Val Loss = 17.5341\n",
            "     Epoch 5: Train Loss = 0.7269, Val Loss = 16.0369\n",
            "     Epoch 10: Train Loss = 0.7214, Val Loss = 13.4762\n",
            "     Epoch 15: Train Loss = 0.7214, Val Loss = 14.0400\n",
            "     Epoch 20: Train Loss = 0.7182, Val Loss = 15.5173\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 4 finished with best val loss: 8.5256\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.8361%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7375, Val Loss = 21.9562\n",
            "     Epoch 5: Train Loss = 0.7249, Val Loss = 18.8556\n",
            "     Epoch 10: Train Loss = 0.7206, Val Loss = 18.5494\n",
            "     Epoch 15: Train Loss = 0.7207, Val Loss = 16.2933\n",
            "     Epoch 20: Train Loss = 0.7174, Val Loss = 19.0868\n",
            "     Epoch 25: Train Loss = 0.7154, Val Loss = 19.5538\n",
            "    ⏹️ Early stopping at epoch 26\n",
            " Run 5 finished with best val loss: 11.9328\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4552%\n",
            " Finished configuration H=128, D=0.0, LR=0.001, B=8 → Avg Val Loss: 10.6897, Avg Accuracy: 4.7361%\n",
            "\n",
            " Running 62/81: H=128, D=0.0, LR=0.001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7367, Val Loss = 10.6612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7219, Val Loss = 13.4955\n",
            "     Epoch 10: Train Loss = 0.7187, Val Loss = 14.0108\n",
            "     Epoch 15: Train Loss = 0.7170, Val Loss = 15.1485\n",
            "     Epoch 20: Train Loss = 0.7167, Val Loss = 14.0849\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 1 finished with best val loss: 10.3849\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4179%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7312, Val Loss = 13.9948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7203, Val Loss = 11.9608\n",
            "     Epoch 10: Train Loss = 0.7200, Val Loss = 14.7468\n",
            "     Epoch 15: Train Loss = 0.7162, Val Loss = 17.2930\n",
            "     Epoch 20: Train Loss = 0.7168, Val Loss = 13.4254\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 2 finished with best val loss: 11.4554\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.7358%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7306, Val Loss = 15.7895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7209, Val Loss = 11.0119\n",
            "     Epoch 10: Train Loss = 0.7170, Val Loss = 16.4525\n",
            "     Epoch 15: Train Loss = 0.7142, Val Loss = 18.3353\n",
            "     Epoch 20: Train Loss = 0.7175, Val Loss = 19.4271\n",
            "     Epoch 25: Train Loss = 0.7158, Val Loss = 16.4497\n",
            "    ⏹️ Early stopping at epoch 25\n",
            " Run 3 finished with best val loss: 11.0119\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.7061%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7309, Val Loss = 22.5161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7192, Val Loss = 15.5280\n",
            "     Epoch 10: Train Loss = 0.7223, Val Loss = 16.2956\n",
            "     Epoch 15: Train Loss = 0.7163, Val Loss = 18.3232\n",
            "     Epoch 20: Train Loss = 0.7345, Val Loss = 17.6377\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 4 finished with best val loss: 10.1879\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3459%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7384, Val Loss = 11.3963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7172, Val Loss = 11.7952\n",
            "     Epoch 10: Train Loss = 0.7209, Val Loss = 14.4362\n",
            "     Epoch 15: Train Loss = 0.7239, Val Loss = 17.4693\n",
            "     Epoch 20: Train Loss = 0.7180, Val Loss = 15.4704\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 11.3963\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3393%\n",
            " Finished configuration H=128, D=0.0, LR=0.001, B=16 → Avg Val Loss: 10.8873, Avg Accuracy: 4.5090%\n",
            "\n",
            " Running 63/81: H=128, D=0.0, LR=0.001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7406, Val Loss = 9.0604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7207, Val Loss = 13.3096\n",
            "     Epoch 10: Train Loss = 0.7176, Val Loss = 13.2043\n",
            "     Epoch 15: Train Loss = 0.7165, Val Loss = 16.4482\n",
            "     Epoch 20: Train Loss = 0.7169, Val Loss = 16.4465\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 9.0604\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4533%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7393, Val Loss = 11.2737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7211, Val Loss = 16.3062\n",
            "     Epoch 10: Train Loss = 0.7179, Val Loss = 15.8637\n",
            "     Epoch 15: Train Loss = 0.7158, Val Loss = 16.2544\n",
            "     Epoch 20: Train Loss = 0.7147, Val Loss = 15.1692\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 11.2737\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3350%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7427, Val Loss = 11.7803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7211, Val Loss = 13.2487\n",
            "     Epoch 10: Train Loss = 0.7171, Val Loss = 17.0666\n",
            "     Epoch 15: Train Loss = 0.7225, Val Loss = 18.1855\n",
            "     Epoch 20: Train Loss = 0.7183, Val Loss = 16.9087\n",
            "     Epoch 25: Train Loss = 0.7178, Val Loss = 18.1118\n",
            "    ⏹️ Early stopping at epoch 28\n",
            " Run 3 finished with best val loss: 11.7451\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.8481%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7295, Val Loss = 12.7560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7172, Val Loss = 16.0204\n",
            "     Epoch 10: Train Loss = 0.7150, Val Loss = 14.2203\n",
            "     Epoch 15: Train Loss = 0.7169, Val Loss = 18.2027\n",
            "     Epoch 20: Train Loss = 0.7156, Val Loss = 18.4009\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 4 finished with best val loss: 10.7373\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.2348%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7470, Val Loss = 12.9668\n",
            "     Epoch 5: Train Loss = 0.7229, Val Loss = 13.4426\n",
            "     Epoch 10: Train Loss = 0.7168, Val Loss = 16.7485\n",
            "     Epoch 15: Train Loss = 0.7200, Val Loss = 13.8681\n",
            "     Epoch 20: Train Loss = 0.7216, Val Loss = 15.9062\n",
            "     Epoch 25: Train Loss = 0.7171, Val Loss = 14.2559\n",
            "    ⏹️ Early stopping at epoch 26\n",
            " Run 5 finished with best val loss: 11.6879\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.8075%\n",
            " Finished configuration H=128, D=0.0, LR=0.001, B=32 → Avg Val Loss: 10.9009, Avg Accuracy: 4.7357%\n",
            "\n",
            " Running 64/81: H=128, D=0.1, LR=0.0001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7941, Val Loss = 11.7697\n",
            "     Epoch 5: Train Loss = 0.7249, Val Loss = 15.5369\n",
            "     Epoch 10: Train Loss = 0.7156, Val Loss = 13.4322\n",
            "     Epoch 15: Train Loss = 0.7165, Val Loss = 15.3872\n",
            "     Epoch 20: Train Loss = 0.7266, Val Loss = 15.2977\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 11.7697\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2541%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7513, Val Loss = 13.8471\n",
            "     Epoch 5: Train Loss = 0.7239, Val Loss = 13.4689\n",
            "     Epoch 10: Train Loss = 0.7243, Val Loss = 13.1835\n",
            "     Epoch 15: Train Loss = 0.7249, Val Loss = 13.7271\n",
            "     Epoch 20: Train Loss = 0.7154, Val Loss = 13.6950\n",
            "     Epoch 25: Train Loss = 0.7262, Val Loss = 14.0619\n",
            "    ⏹️ Early stopping at epoch 28\n",
            " Run 2 finished with best val loss: 12.2618\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9996%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7549, Val Loss = 14.8502\n",
            "     Epoch 5: Train Loss = 0.7219, Val Loss = 15.6050\n",
            "     Epoch 10: Train Loss = 0.7231, Val Loss = 14.3382\n",
            "     Epoch 15: Train Loss = 0.7224, Val Loss = 15.4310\n",
            "     Epoch 20: Train Loss = 0.7200, Val Loss = 16.2252\n",
            "     Epoch 25: Train Loss = 0.7180, Val Loss = 16.5569\n",
            "     Epoch 30: Train Loss = 0.7194, Val Loss = 16.8934\n",
            "    ⏹️ Early stopping at epoch 33\n",
            " Run 3 finished with best val loss: 14.1376\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.2710%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8427, Val Loss = 11.6372\n",
            "     Epoch 5: Train Loss = 0.7280, Val Loss = 14.5549\n",
            "     Epoch 10: Train Loss = 0.7163, Val Loss = 15.0488\n",
            "     Epoch 15: Train Loss = 0.7245, Val Loss = 14.8983\n",
            "     Epoch 20: Train Loss = 0.7207, Val Loss = 14.0725\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 11.6372\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8854%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7892, Val Loss = 9.8361\n",
            "     Epoch 5: Train Loss = 0.7192, Val Loss = 13.7787\n",
            "     Epoch 10: Train Loss = 0.7237, Val Loss = 14.0128\n",
            "     Epoch 15: Train Loss = 0.7185, Val Loss = 13.9243\n",
            "     Epoch 20: Train Loss = 0.7214, Val Loss = 13.7136\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 9.8361\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8459%\n",
            " Finished configuration H=128, D=0.1, LR=0.0001, B=8 → Avg Val Loss: 11.9285, Avg Accuracy: 4.2512%\n",
            "\n",
            " Running 65/81: H=128, D=0.1, LR=0.0001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7686, Val Loss = 9.5726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7160, Val Loss = 12.3382\n",
            "     Epoch 10: Train Loss = 0.7171, Val Loss = 12.8033\n",
            "     Epoch 15: Train Loss = 0.7202, Val Loss = 12.6741\n",
            "     Epoch 20: Train Loss = 0.7189, Val Loss = 13.0017\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 9.5726\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6175%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7990, Val Loss = 10.1127\n",
            "     Epoch 5: Train Loss = 0.7213, Val Loss = 15.8516\n",
            "     Epoch 10: Train Loss = 0.7208, Val Loss = 14.6095\n",
            "     Epoch 15: Train Loss = 0.7191, Val Loss = 15.2398\n",
            "     Epoch 20: Train Loss = 0.7142, Val Loss = 15.8642\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 10.1127\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3900%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7998, Val Loss = 11.5021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7352, Val Loss = 13.6132\n",
            "     Epoch 10: Train Loss = 0.7273, Val Loss = 13.1436\n",
            "     Epoch 15: Train Loss = 0.7306, Val Loss = 14.0716\n",
            "     Epoch 20: Train Loss = 0.7145, Val Loss = 14.5889\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 11.5021\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0230%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7892, Val Loss = 13.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7266, Val Loss = 14.2257\n",
            "     Epoch 10: Train Loss = 0.7203, Val Loss = 14.1048\n",
            "     Epoch 15: Train Loss = 0.7193, Val Loss = 14.7735\n",
            "     Epoch 20: Train Loss = 0.7240, Val Loss = 15.1373\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 13.0009\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2189%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7900, Val Loss = 11.5232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7276, Val Loss = 14.9607\n",
            "     Epoch 10: Train Loss = 0.7229, Val Loss = 13.9987\n",
            "     Epoch 15: Train Loss = 0.7174, Val Loss = 14.4792\n",
            "     Epoch 20: Train Loss = 0.7232, Val Loss = 14.1874\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 11.5232\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9444%\n",
            " Finished configuration H=128, D=0.1, LR=0.0001, B=16 → Avg Val Loss: 11.1423, Avg Accuracy: 4.0388%\n",
            "\n",
            " Running 66/81: H=128, D=0.1, LR=0.0001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.8554, Val Loss = 6.8198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7263, Val Loss = 13.0320\n",
            "     Epoch 10: Train Loss = 0.7205, Val Loss = 12.8673\n",
            "     Epoch 15: Train Loss = 0.7251, Val Loss = 13.2524\n",
            "     Epoch 20: Train Loss = 0.7202, Val Loss = 13.7059\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 6.8198\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7887%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7723, Val Loss = 8.6104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7274, Val Loss = 12.2908\n",
            "     Epoch 10: Train Loss = 0.7133, Val Loss = 12.6054\n",
            "     Epoch 15: Train Loss = 0.7213, Val Loss = 12.6287\n",
            "     Epoch 20: Train Loss = 0.7167, Val Loss = 12.7709\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 8.6104\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5124%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8281, Val Loss = 9.8207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7341, Val Loss = 13.9469\n",
            "     Epoch 10: Train Loss = 0.7144, Val Loss = 13.7478\n",
            "     Epoch 15: Train Loss = 0.7183, Val Loss = 13.0668\n",
            "     Epoch 20: Train Loss = 0.7165, Val Loss = 14.1355\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 9.8207\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9111%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7598, Val Loss = 12.0575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7167, Val Loss = 14.1544\n",
            "     Epoch 10: Train Loss = 0.7272, Val Loss = 13.4894\n",
            "     Epoch 15: Train Loss = 0.7231, Val Loss = 13.6378\n",
            "     Epoch 20: Train Loss = 0.7182, Val Loss = 13.1997\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 12.0575\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7141%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7967, Val Loss = 10.7261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7215, Val Loss = 14.5071\n",
            "     Epoch 10: Train Loss = 0.7184, Val Loss = 15.2504\n",
            "     Epoch 15: Train Loss = 0.7268, Val Loss = 14.6083\n",
            "     Epoch 20: Train Loss = 0.7259, Val Loss = 14.7853\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 10.7261\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1015%\n",
            " Finished configuration H=128, D=0.1, LR=0.0001, B=32 → Avg Val Loss: 9.6069, Avg Accuracy: 3.8056%\n",
            "\n",
            " Running 67/81: H=128, D=0.1, LR=0.0005, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7437, Val Loss = 14.2034\n",
            "     Epoch 5: Train Loss = 0.7208, Val Loss = 14.4899\n",
            "     Epoch 10: Train Loss = 0.7238, Val Loss = 13.0908\n",
            "     Epoch 15: Train Loss = 0.7162, Val Loss = 14.5649\n",
            "     Epoch 20: Train Loss = 0.7204, Val Loss = 19.3823\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 1 finished with best val loss: 8.8340\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3095%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7385, Val Loss = 11.0353\n",
            "     Epoch 5: Train Loss = 0.7255, Val Loss = 11.8968\n",
            "     Epoch 10: Train Loss = 0.7301, Val Loss = 14.0755\n",
            "     Epoch 15: Train Loss = 0.7183, Val Loss = 14.3961\n",
            "     Epoch 20: Train Loss = 0.7169, Val Loss = 12.9021\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 11.0353\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7771%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7436, Val Loss = 22.8277\n",
            "     Epoch 5: Train Loss = 0.7288, Val Loss = 13.7235\n",
            "     Epoch 10: Train Loss = 0.7272, Val Loss = 19.1166\n",
            "     Epoch 15: Train Loss = 0.7280, Val Loss = 14.2916\n",
            "     Epoch 20: Train Loss = 0.7243, Val Loss = 15.3131\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 3 finished with best val loss: 10.3819\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3841%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7487, Val Loss = 10.4554\n",
            "     Epoch 5: Train Loss = 0.7220, Val Loss = 15.2712\n",
            "     Epoch 10: Train Loss = 0.7164, Val Loss = 11.3971\n",
            "     Epoch 15: Train Loss = 0.7232, Val Loss = 14.4130\n",
            "     Epoch 20: Train Loss = 0.7133, Val Loss = 20.9807\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 10.4554\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.9865%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7388, Val Loss = 13.4408\n",
            "     Epoch 5: Train Loss = 0.7325, Val Loss = 16.4348\n",
            "     Epoch 10: Train Loss = 0.7211, Val Loss = 13.9206\n",
            "     Epoch 15: Train Loss = 0.7219, Val Loss = 16.8075\n",
            "     Epoch 20: Train Loss = 0.7226, Val Loss = 15.1762\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 5 finished with best val loss: 12.0429\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.0138%\n",
            " Finished configuration H=128, D=0.1, LR=0.0005, B=8 → Avg Val Loss: 10.5499, Avg Accuracy: 4.6942%\n",
            "\n",
            " Running 68/81: H=128, D=0.1, LR=0.0005, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7226, Val Loss = 16.3291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7265, Val Loss = 17.7754\n",
            "     Epoch 10: Train Loss = 0.7231, Val Loss = 14.9081\n",
            "     Epoch 15: Train Loss = 0.7159, Val Loss = 17.8091\n",
            "     Epoch 20: Train Loss = 0.7107, Val Loss = 19.3136\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 1 finished with best val loss: 12.3636\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.7984%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7534, Val Loss = 12.4555\n",
            "     Epoch 5: Train Loss = 0.7139, Val Loss = 13.3280\n",
            "     Epoch 10: Train Loss = 0.7201, Val Loss = 14.3916\n",
            "     Epoch 15: Train Loss = 0.7164, Val Loss = 14.5928\n",
            "     Epoch 20: Train Loss = 0.7161, Val Loss = 18.0532\n",
            "    ⏹️ Early stopping at epoch 24\n",
            " Run 2 finished with best val loss: 12.1682\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.6396%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7404, Val Loss = 16.8948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7177, Val Loss = 13.3436\n",
            "     Epoch 10: Train Loss = 0.7148, Val Loss = 14.7170\n",
            "     Epoch 15: Train Loss = 0.7210, Val Loss = 12.9431\n",
            "     Epoch 20: Train Loss = 0.7212, Val Loss = 17.0334\n",
            "     Epoch 25: Train Loss = 0.7264, Val Loss = 14.5445\n",
            "    ⏹️ Early stopping at epoch 27\n",
            " Run 3 finished with best val loss: 12.7074\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1210%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7412, Val Loss = 11.2041\n",
            "     Epoch 5: Train Loss = 0.7255, Val Loss = 14.1256\n",
            "     Epoch 10: Train Loss = 0.7193, Val Loss = 14.5794\n",
            "     Epoch 15: Train Loss = 0.7183, Val Loss = 17.9548\n",
            "     Epoch 20: Train Loss = 0.7208, Val Loss = 14.5099\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 4 finished with best val loss: 10.6092\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.6102%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7837, Val Loss = 10.9535\n",
            "     Epoch 5: Train Loss = 0.7335, Val Loss = 12.1915\n",
            "     Epoch 10: Train Loss = 0.7239, Val Loss = 12.7676\n",
            "     Epoch 15: Train Loss = 0.7163, Val Loss = 17.0136\n",
            "     Epoch 20: Train Loss = 0.7182, Val Loss = 18.4561\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 10.9535\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.2638%\n",
            " Finished configuration H=128, D=0.1, LR=0.0005, B=16 → Avg Val Loss: 11.7604, Avg Accuracy: 4.8866%\n",
            "\n",
            " Running 69/81: H=128, D=0.1, LR=0.0005, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7605, Val Loss = 12.1880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7258, Val Loss = 13.5074\n",
            "     Epoch 10: Train Loss = 0.7191, Val Loss = 13.1736\n",
            "     Epoch 15: Train Loss = 0.7219, Val Loss = 15.7324\n",
            "     Epoch 20: Train Loss = 0.7265, Val Loss = 15.8465\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 1 finished with best val loss: 11.5222\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3574%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7593, Val Loss = 14.0083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7213, Val Loss = 14.2828\n",
            "     Epoch 10: Train Loss = 0.7173, Val Loss = 15.8712\n",
            "     Epoch 15: Train Loss = 0.7167, Val Loss = 15.2793\n",
            "     Epoch 20: Train Loss = 0.7211, Val Loss = 15.5710\n",
            "    ⏹️ Early stopping at epoch 24\n",
            " Run 2 finished with best val loss: 12.7838\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.6050%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8196, Val Loss = 14.7752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7217, Val Loss = 14.7217\n",
            "     Epoch 10: Train Loss = 0.7224, Val Loss = 14.1038\n",
            "     Epoch 15: Train Loss = 0.7207, Val Loss = 16.6627\n",
            "     Epoch 20: Train Loss = 0.7179, Val Loss = 15.9865\n",
            "     Epoch 25: Train Loss = 0.7162, Val Loss = 16.2351\n",
            "     Epoch 30: Train Loss = 0.7157, Val Loss = 13.9689\n",
            "     Epoch 35: Train Loss = 0.7179, Val Loss = 15.7940\n",
            "     Epoch 40: Train Loss = 0.7202, Val Loss = 18.8924\n",
            "     Epoch 45: Train Loss = 0.7165, Val Loss = 16.2071\n",
            "     Epoch 50: Train Loss = 0.7224, Val Loss = 16.8740\n",
            "    ⏹️ Early stopping at epoch 50\n",
            " Run 3 finished with best val loss: 13.9689\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.7451%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7506, Val Loss = 12.7572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7274, Val Loss = 14.1649\n",
            "     Epoch 10: Train Loss = 0.7257, Val Loss = 13.0512\n",
            "     Epoch 15: Train Loss = 0.7265, Val Loss = 14.5787\n",
            "     Epoch 20: Train Loss = 0.7181, Val Loss = 14.8064\n",
            "     Epoch 25: Train Loss = 0.7184, Val Loss = 19.5715\n",
            "     Epoch 30: Train Loss = 0.7205, Val Loss = 14.8997\n",
            "    ⏹️ Early stopping at epoch 32\n",
            " Run 4 finished with best val loss: 11.6760\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.6148%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7475, Val Loss = 17.7371\n",
            "     Epoch 5: Train Loss = 0.7258, Val Loss = 13.3999\n",
            "     Epoch 10: Train Loss = 0.7198, Val Loss = 15.4888\n",
            "     Epoch 15: Train Loss = 0.7198, Val Loss = 15.1384\n",
            "     Epoch 20: Train Loss = 0.7184, Val Loss = 16.8799\n",
            "     Epoch 25: Train Loss = 0.7215, Val Loss = 16.3810\n",
            "    ⏹️ Early stopping at epoch 26\n",
            " Run 5 finished with best val loss: 12.4893\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2324%\n",
            " Finished configuration H=128, D=0.1, LR=0.0005, B=32 → Avg Val Loss: 12.4880, Avg Accuracy: 4.7110%\n",
            "\n",
            " Running 70/81: H=128, D=0.1, LR=0.001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7419, Val Loss = 15.2660\n",
            "     Epoch 5: Train Loss = 0.7195, Val Loss = 12.3378\n",
            "     Epoch 10: Train Loss = 0.7247, Val Loss = 17.6881\n",
            "     Epoch 15: Train Loss = 0.7160, Val Loss = 19.0828\n",
            "     Epoch 20: Train Loss = 0.7250, Val Loss = 12.7195\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 1 finished with best val loss: 10.8604\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1603%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7369, Val Loss = 15.8098\n",
            "     Epoch 5: Train Loss = 0.7340, Val Loss = 14.0053\n",
            "     Epoch 10: Train Loss = 0.7196, Val Loss = 17.8118\n",
            "     Epoch 15: Train Loss = 0.7193, Val Loss = 15.4620\n",
            "     Epoch 20: Train Loss = 0.7202, Val Loss = 19.1156\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 2 finished with best val loss: 10.4330\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.9164%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7530, Val Loss = 9.0879\n",
            "     Epoch 5: Train Loss = 0.7243, Val Loss = 19.3013\n",
            "     Epoch 10: Train Loss = 0.7234, Val Loss = 12.1899\n",
            "     Epoch 15: Train Loss = 0.7220, Val Loss = 12.0811\n",
            "     Epoch 20: Train Loss = 0.7231, Val Loss = 14.5507\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 9.0879\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1483%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7373, Val Loss = 11.8644\n",
            "     Epoch 5: Train Loss = 0.7171, Val Loss = 12.9489\n",
            "     Epoch 10: Train Loss = 0.7181, Val Loss = 14.5677\n",
            "     Epoch 15: Train Loss = 0.7168, Val Loss = 20.2742\n",
            "     Epoch 20: Train Loss = 0.7165, Val Loss = 14.2988\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 11.8644\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2591%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7453, Val Loss = 18.2759\n",
            "     Epoch 5: Train Loss = 0.7269, Val Loss = 15.4765\n",
            "     Epoch 10: Train Loss = 0.7314, Val Loss = 16.2566\n",
            "     Epoch 15: Train Loss = 0.7242, Val Loss = 14.6325\n",
            "     Epoch 20: Train Loss = 0.7223, Val Loss = 14.6076\n",
            "     Epoch 25: Train Loss = 0.7199, Val Loss = 12.9774\n",
            "    ⏹️ Early stopping at epoch 26\n",
            " Run 5 finished with best val loss: 11.2655\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.7051%\n",
            " Finished configuration H=128, D=0.1, LR=0.001, B=8 → Avg Val Loss: 10.7022, Avg Accuracy: 4.4378%\n",
            "\n",
            " Running 71/81: H=128, D=0.1, LR=0.001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7582, Val Loss = 18.3440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7265, Val Loss = 14.6808\n",
            "     Epoch 10: Train Loss = 0.7217, Val Loss = 14.5775\n",
            "     Epoch 15: Train Loss = 0.7168, Val Loss = 14.6476\n",
            "     Epoch 20: Train Loss = 0.7211, Val Loss = 14.0681\n",
            "     Epoch 25: Train Loss = 0.7242, Val Loss = 14.3604\n",
            "     Epoch 30: Train Loss = 0.7189, Val Loss = 17.8987\n",
            "     Epoch 35: Train Loss = 0.7173, Val Loss = 17.8624\n",
            "    ⏹️ Early stopping at epoch 39\n",
            " Run 1 finished with best val loss: 13.7121\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.6522%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7347, Val Loss = 10.5009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7182, Val Loss = 20.2198\n",
            "     Epoch 10: Train Loss = 0.7286, Val Loss = 19.0177\n",
            "     Epoch 15: Train Loss = 0.7113, Val Loss = 13.2267\n",
            "     Epoch 20: Train Loss = 0.7215, Val Loss = 14.1100\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 2 finished with best val loss: 10.4803\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.7931%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7350, Val Loss = 17.4098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7255, Val Loss = 12.5704\n",
            "     Epoch 10: Train Loss = 0.7177, Val Loss = 19.1752\n",
            "     Epoch 15: Train Loss = 0.7187, Val Loss = 13.2007\n",
            "     Epoch 20: Train Loss = 0.7211, Val Loss = 17.9045\n",
            "     Epoch 25: Train Loss = 0.7159, Val Loss = 19.2818\n",
            "     Epoch 30: Train Loss = 0.7213, Val Loss = 15.7718\n",
            "    ⏹️ Early stopping at epoch 32\n",
            " Run 3 finished with best val loss: 12.3543\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.2694%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7293, Val Loss = 16.2338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7225, Val Loss = 13.2440\n",
            "     Epoch 10: Train Loss = 0.7260, Val Loss = 15.8628\n",
            "     Epoch 15: Train Loss = 0.7216, Val Loss = 18.1765\n",
            "     Epoch 20: Train Loss = 0.7264, Val Loss = 17.2260\n",
            "     Epoch 25: Train Loss = 0.7156, Val Loss = 18.5289\n",
            "    ⏹️ Early stopping at epoch 26\n",
            " Run 4 finished with best val loss: 11.9767\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.7735%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7387, Val Loss = 18.4753\n",
            "     Epoch 5: Train Loss = 0.7362, Val Loss = 13.5415\n",
            "     Epoch 10: Train Loss = 0.7201, Val Loss = 15.4033\n",
            "     Epoch 15: Train Loss = 0.7266, Val Loss = 17.3560\n",
            "     Epoch 20: Train Loss = 0.7174, Val Loss = 13.6662\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 5 finished with best val loss: 10.6124\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4096%\n",
            " Finished configuration H=128, D=0.1, LR=0.001, B=16 → Avg Val Loss: 11.8272, Avg Accuracy: 4.9795%\n",
            "\n",
            " Running 72/81: H=128, D=0.1, LR=0.001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7529, Val Loss = 15.1036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7265, Val Loss = 15.3978\n",
            "     Epoch 10: Train Loss = 0.7336, Val Loss = 15.9210\n",
            "     Epoch 15: Train Loss = 0.7310, Val Loss = 17.9823\n",
            "     Epoch 20: Train Loss = 0.7241, Val Loss = 15.8513\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 1 finished with best val loss: 12.5102\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.2335%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7377, Val Loss = 17.0973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7283, Val Loss = 14.7248\n",
            "     Epoch 10: Train Loss = 0.7254, Val Loss = 13.5088\n",
            "     Epoch 15: Train Loss = 0.7130, Val Loss = 18.8461\n",
            "     Epoch 20: Train Loss = 0.7141, Val Loss = 13.6029\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 2 finished with best val loss: 11.5256\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.6514%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7493, Val Loss = 19.0441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7203, Val Loss = 17.8309\n",
            "     Epoch 10: Train Loss = 0.7234, Val Loss = 16.4957\n",
            "     Epoch 15: Train Loss = 0.7253, Val Loss = 16.7521\n",
            "     Epoch 20: Train Loss = 0.7180, Val Loss = 20.0665\n",
            "     Epoch 25: Train Loss = 0.7180, Val Loss = 18.4885\n",
            "    ⏹️ Early stopping at epoch 28\n",
            " Run 3 finished with best val loss: 11.9108\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.5778%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7531, Val Loss = 15.1518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7306, Val Loss = 12.6136\n",
            "     Epoch 10: Train Loss = 0.7152, Val Loss = 14.4099\n",
            "     Epoch 15: Train Loss = 0.7224, Val Loss = 15.7304\n",
            "     Epoch 20: Train Loss = 0.7164, Val Loss = 17.6027\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 4 finished with best val loss: 10.3567\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2036%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7669, Val Loss = 13.1855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7379, Val Loss = 14.5982\n",
            "     Epoch 10: Train Loss = 0.7199, Val Loss = 12.9157\n",
            "     Epoch 15: Train Loss = 0.7220, Val Loss = 14.0626\n",
            "     Epoch 20: Train Loss = 0.7190, Val Loss = 15.8693\n",
            "    ⏹️ Early stopping at epoch 24\n",
            " Run 5 finished with best val loss: 11.3413\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.2230%\n",
            " Finished configuration H=128, D=0.1, LR=0.001, B=32 → Avg Val Loss: 11.5289, Avg Accuracy: 4.9779%\n",
            "\n",
            " Running 73/81: H=128, D=0.2, LR=0.0001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7578, Val Loss = 13.5377\n",
            "     Epoch 5: Train Loss = 0.7252, Val Loss = 13.5985\n",
            "     Epoch 10: Train Loss = 0.7287, Val Loss = 13.8230\n",
            "     Epoch 15: Train Loss = 0.7315, Val Loss = 14.9893\n",
            "     Epoch 20: Train Loss = 0.7214, Val Loss = 15.3252\n",
            "     Epoch 25: Train Loss = 0.7282, Val Loss = 14.8810\n",
            "     Epoch 30: Train Loss = 0.7211, Val Loss = 14.9717\n",
            "    ⏹️ Early stopping at epoch 31\n",
            " Run 1 finished with best val loss: 13.0964\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3863%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7804, Val Loss = 14.2888\n",
            "     Epoch 5: Train Loss = 0.7268, Val Loss = 14.8660\n",
            "     Epoch 10: Train Loss = 0.7280, Val Loss = 14.9221\n",
            "     Epoch 15: Train Loss = 0.7256, Val Loss = 15.4497\n",
            "     Epoch 20: Train Loss = 0.7215, Val Loss = 16.2248\n",
            "     Epoch 25: Train Loss = 0.7212, Val Loss = 15.8010\n",
            "    ⏹️ Early stopping at epoch 27\n",
            " Run 2 finished with best val loss: 13.6106\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1560%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8045, Val Loss = 7.4004\n",
            "     Epoch 5: Train Loss = 0.7309, Val Loss = 12.3737\n",
            "     Epoch 10: Train Loss = 0.7205, Val Loss = 14.3257\n",
            "     Epoch 15: Train Loss = 0.7322, Val Loss = 13.7953\n",
            "     Epoch 20: Train Loss = 0.7236, Val Loss = 14.1605\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 7.4004\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9378%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7655, Val Loss = 10.5210\n",
            "     Epoch 5: Train Loss = 0.7250, Val Loss = 13.1950\n",
            "     Epoch 10: Train Loss = 0.7257, Val Loss = 12.5899\n",
            "     Epoch 15: Train Loss = 0.7139, Val Loss = 13.0528\n",
            "     Epoch 20: Train Loss = 0.7217, Val Loss = 14.8948\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 10.5210\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1793%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.8524, Val Loss = 10.3556\n",
            "     Epoch 5: Train Loss = 0.7264, Val Loss = 13.1479\n",
            "     Epoch 10: Train Loss = 0.7329, Val Loss = 13.1376\n",
            "     Epoch 15: Train Loss = 0.7144, Val Loss = 12.9726\n",
            "     Epoch 20: Train Loss = 0.7261, Val Loss = 13.3224\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 10.3556\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7378%\n",
            " Finished configuration H=128, D=0.2, LR=0.0001, B=8 → Avg Val Loss: 10.9968, Avg Accuracy: 4.0794%\n",
            "\n",
            " Running 74/81: H=128, D=0.2, LR=0.0001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7705, Val Loss = 12.7298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7275, Val Loss = 15.1105\n",
            "     Epoch 10: Train Loss = 0.7185, Val Loss = 13.5281\n",
            "     Epoch 15: Train Loss = 0.7279, Val Loss = 13.5297\n",
            "     Epoch 20: Train Loss = 0.7223, Val Loss = 14.0807\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 12.7298\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.9445%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7761, Val Loss = 12.1136\n",
            "     Epoch 5: Train Loss = 0.7404, Val Loss = 14.1073\n",
            "     Epoch 10: Train Loss = 0.7323, Val Loss = 13.3086\n",
            "     Epoch 15: Train Loss = 0.7261, Val Loss = 13.2781\n",
            "     Epoch 20: Train Loss = 0.7218, Val Loss = 15.0075\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 12.1136\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1963%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7733, Val Loss = 9.2647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7250, Val Loss = 12.3119\n",
            "     Epoch 10: Train Loss = 0.7200, Val Loss = 13.1829\n",
            "     Epoch 15: Train Loss = 0.7215, Val Loss = 13.0060\n",
            "     Epoch 20: Train Loss = 0.7283, Val Loss = 13.6670\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 9.2647\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8507%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7822, Val Loss = 11.6104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7312, Val Loss = 13.3600\n",
            "     Epoch 10: Train Loss = 0.7173, Val Loss = 13.4458\n",
            "     Epoch 15: Train Loss = 0.7181, Val Loss = 13.1895\n",
            "     Epoch 20: Train Loss = 0.7224, Val Loss = 13.1631\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 11.6104\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.6632%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7966, Val Loss = 11.3389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7422, Val Loss = 13.8160\n",
            "     Epoch 10: Train Loss = 0.7300, Val Loss = 13.2570\n",
            "     Epoch 15: Train Loss = 0.7255, Val Loss = 13.6292\n",
            "     Epoch 20: Train Loss = 0.7309, Val Loss = 12.5269\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 11.3389\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5064%\n",
            " Finished configuration H=128, D=0.2, LR=0.0001, B=16 → Avg Val Loss: 11.4115, Avg Accuracy: 3.8322%\n",
            "\n",
            " Running 75/81: H=128, D=0.2, LR=0.0001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7760, Val Loss = 9.8998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7247, Val Loss = 14.0889\n",
            "     Epoch 10: Train Loss = 0.7251, Val Loss = 13.6136\n",
            "     Epoch 15: Train Loss = 0.7318, Val Loss = 14.1907\n",
            "     Epoch 20: Train Loss = 0.7258, Val Loss = 13.9253\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 9.8998\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7939%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.8219, Val Loss = 7.8246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7239, Val Loss = 14.6802\n",
            "     Epoch 10: Train Loss = 0.7231, Val Loss = 12.5352\n",
            "     Epoch 15: Train Loss = 0.7292, Val Loss = 12.6707\n",
            "     Epoch 20: Train Loss = 0.7297, Val Loss = 12.9236\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 2 finished with best val loss: 7.8246\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5663%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.8070, Val Loss = 8.9708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7303, Val Loss = 14.0236\n",
            "     Epoch 10: Train Loss = 0.7249, Val Loss = 13.4172\n",
            "     Epoch 15: Train Loss = 0.7225, Val Loss = 14.0008\n",
            "     Epoch 20: Train Loss = 0.7232, Val Loss = 13.5125\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 3 finished with best val loss: 8.9708\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7662%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7701, Val Loss = 9.4404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7341, Val Loss = 12.8519\n",
            "     Epoch 10: Train Loss = 0.7287, Val Loss = 12.8335\n",
            "     Epoch 15: Train Loss = 0.7259, Val Loss = 12.0292\n",
            "     Epoch 20: Train Loss = 0.7242, Val Loss = 12.9498\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 9.4404\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.5810%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.9484, Val Loss = 5.4605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7244, Val Loss = 14.0963\n",
            "     Epoch 10: Train Loss = 0.7364, Val Loss = 14.2303\n",
            "     Epoch 15: Train Loss = 0.7263, Val Loss = 15.1304\n",
            "     Epoch 20: Train Loss = 0.7217, Val Loss = 15.6410\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 5 finished with best val loss: 5.4605\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3259%\n",
            " Finished configuration H=128, D=0.2, LR=0.0001, B=32 → Avg Val Loss: 8.3192, Avg Accuracy: 3.8066%\n",
            "\n",
            " Running 76/81: H=128, D=0.2, LR=0.0005, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7457, Val Loss = 8.7220\n",
            "     Epoch 5: Train Loss = 0.7240, Val Loss = 14.7799\n",
            "     Epoch 10: Train Loss = 0.7242, Val Loss = 13.1452\n",
            "     Epoch 15: Train Loss = 0.7157, Val Loss = 14.8996\n",
            "     Epoch 20: Train Loss = 0.7239, Val Loss = 20.3897\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 8.7220\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.8586%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7518, Val Loss = 17.1429\n",
            "     Epoch 5: Train Loss = 0.7293, Val Loss = 17.1578\n",
            "     Epoch 10: Train Loss = 0.7354, Val Loss = 14.2632\n",
            "     Epoch 15: Train Loss = 0.7166, Val Loss = 15.4511\n",
            "     Epoch 20: Train Loss = 0.7178, Val Loss = 12.6916\n",
            "     Epoch 25: Train Loss = 0.7243, Val Loss = 15.0546\n",
            "     Epoch 30: Train Loss = 0.7240, Val Loss = 14.2333\n",
            "    ⏹️ Early stopping at epoch 31\n",
            " Run 2 finished with best val loss: 11.0229\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.7241%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7372, Val Loss = 13.4962\n",
            "     Epoch 5: Train Loss = 0.7297, Val Loss = 13.2794\n",
            "     Epoch 10: Train Loss = 0.7226, Val Loss = 17.9401\n",
            "     Epoch 15: Train Loss = 0.7193, Val Loss = 13.9408\n",
            "     Epoch 20: Train Loss = 0.7171, Val Loss = 18.1867\n",
            "     Epoch 25: Train Loss = 0.7260, Val Loss = 16.9962\n",
            "     Epoch 30: Train Loss = 0.7254, Val Loss = 14.8812\n",
            "    ⏹️ Early stopping at epoch 32\n",
            " Run 3 finished with best val loss: 11.6796\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.1431%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7546, Val Loss = 10.3004\n",
            "     Epoch 5: Train Loss = 0.7316, Val Loss = 17.5510\n",
            "     Epoch 10: Train Loss = 0.7233, Val Loss = 14.5039\n",
            "     Epoch 15: Train Loss = 0.7264, Val Loss = 20.2014\n",
            "     Epoch 20: Train Loss = 0.7192, Val Loss = 13.7005\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 4 finished with best val loss: 8.8448\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.2310%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7391, Val Loss = 13.1388\n",
            "     Epoch 5: Train Loss = 0.7268, Val Loss = 11.7507\n",
            "     Epoch 10: Train Loss = 0.7253, Val Loss = 11.5837\n",
            "     Epoch 15: Train Loss = 0.7264, Val Loss = 11.9190\n",
            "     Epoch 20: Train Loss = 0.7220, Val Loss = 15.9917\n",
            "     Epoch 25: Train Loss = 0.7213, Val Loss = 15.6599\n",
            "     Epoch 30: Train Loss = 0.7178, Val Loss = 17.7411\n",
            "    ⏹️ Early stopping at epoch 30\n",
            " Run 5 finished with best val loss: 11.5837\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.0330%\n",
            " Finished configuration H=128, D=0.2, LR=0.0005, B=8 → Avg Val Loss: 10.3706, Avg Accuracy: 4.9980%\n",
            "\n",
            " Running 77/81: H=128, D=0.2, LR=0.0005, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7790, Val Loss = 10.3058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7300, Val Loss = 12.3549\n",
            "     Epoch 10: Train Loss = 0.7286, Val Loss = 11.8304\n",
            "     Epoch 15: Train Loss = 0.7173, Val Loss = 14.1430\n",
            "     Epoch 20: Train Loss = 0.7232, Val Loss = 13.9752\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 1 finished with best val loss: 10.3058\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8923%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7429, Val Loss = 13.5463\n",
            "     Epoch 5: Train Loss = 0.7257, Val Loss = 14.0466\n",
            "     Epoch 10: Train Loss = 0.7310, Val Loss = 13.6645\n",
            "     Epoch 15: Train Loss = 0.7254, Val Loss = 13.2076\n",
            "     Epoch 20: Train Loss = 0.7177, Val Loss = 14.6228\n",
            "     Epoch 25: Train Loss = 0.7144, Val Loss = 17.0323\n",
            "     Epoch 30: Train Loss = 0.7235, Val Loss = 15.1038\n",
            "    ⏹️ Early stopping at epoch 34\n",
            " Run 2 finished with best val loss: 11.4224\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3079%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7564, Val Loss = 13.7512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7192, Val Loss = 11.3202\n",
            "     Epoch 10: Train Loss = 0.7278, Val Loss = 13.8865\n",
            "     Epoch 15: Train Loss = 0.7273, Val Loss = 16.5317\n",
            "     Epoch 20: Train Loss = 0.7264, Val Loss = 16.6761\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 3 finished with best val loss: 9.8720\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.4677%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7536, Val Loss = 13.4776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7299, Val Loss = 15.7647\n",
            "     Epoch 10: Train Loss = 0.7216, Val Loss = 14.3448\n",
            "     Epoch 15: Train Loss = 0.7269, Val Loss = 14.3902\n",
            "     Epoch 20: Train Loss = 0.7193, Val Loss = 15.2120\n",
            "     Epoch 25: Train Loss = 0.7235, Val Loss = 14.9262\n",
            "    ⏹️ Early stopping at epoch 29\n",
            " Run 4 finished with best val loss: 12.6461\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3156%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7734, Val Loss = 15.6702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7251, Val Loss = 15.3307\n",
            "     Epoch 10: Train Loss = 0.7216, Val Loss = 13.7675\n",
            "     Epoch 15: Train Loss = 0.7233, Val Loss = 18.3132\n",
            "     Epoch 20: Train Loss = 0.7112, Val Loss = 16.4458\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 5 finished with best val loss: 11.8926\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.1606%\n",
            " Finished configuration H=128, D=0.2, LR=0.0005, B=16 → Avg Val Loss: 11.2278, Avg Accuracy: 4.4288%\n",
            "\n",
            " Running 78/81: H=128, D=0.2, LR=0.0005, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7616, Val Loss = 16.7647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7467, Val Loss = 14.0620\n",
            "     Epoch 10: Train Loss = 0.7286, Val Loss = 15.6033\n",
            "     Epoch 15: Train Loss = 0.7270, Val Loss = 14.8178\n",
            "     Epoch 20: Train Loss = 0.7213, Val Loss = 16.3862\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 1 finished with best val loss: 12.4779\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2847%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7544, Val Loss = 14.8755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7228, Val Loss = 11.6359\n",
            "     Epoch 10: Train Loss = 0.7155, Val Loss = 14.1617\n",
            "     Epoch 15: Train Loss = 0.7182, Val Loss = 14.4429\n",
            "     Epoch 20: Train Loss = 0.7235, Val Loss = 13.4307\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 2 finished with best val loss: 10.8476\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3403%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7493, Val Loss = 14.8859\n",
            "     Epoch 5: Train Loss = 0.7419, Val Loss = 12.9478\n",
            "     Epoch 10: Train Loss = 0.7266, Val Loss = 14.2741\n",
            "     Epoch 15: Train Loss = 0.7292, Val Loss = 14.1717\n",
            "     Epoch 20: Train Loss = 0.7255, Val Loss = 16.4622\n",
            "     Epoch 25: Train Loss = 0.7256, Val Loss = 15.9365\n",
            "    ⏹️ Early stopping at epoch 25\n",
            " Run 3 finished with best val loss: 12.9478\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.5729%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7523, Val Loss = 15.7579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7149, Val Loss = 12.6621\n",
            "     Epoch 10: Train Loss = 0.7269, Val Loss = 15.3602\n",
            "     Epoch 15: Train Loss = 0.7177, Val Loss = 14.2204\n",
            "     Epoch 20: Train Loss = 0.7220, Val Loss = 16.1224\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 4 finished with best val loss: 12.0802\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3260%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.8253, Val Loss = 15.0881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7210, Val Loss = 11.7712\n",
            "     Epoch 10: Train Loss = 0.7264, Val Loss = 12.9756\n",
            "     Epoch 15: Train Loss = 0.7162, Val Loss = 14.7173\n",
            "     Epoch 20: Train Loss = 0.7210, Val Loss = 14.5525\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 5 finished with best val loss: 11.2168\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.0971%\n",
            " Finished configuration H=128, D=0.2, LR=0.0005, B=32 → Avg Val Loss: 11.9140, Avg Accuracy: 4.3242%\n",
            "\n",
            " Running 79/81: H=128, D=0.2, LR=0.001, B=8\n",
            "   Run 1/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7460, Val Loss = 23.5453\n",
            "     Epoch 5: Train Loss = 0.7260, Val Loss = 12.8897\n",
            "     Epoch 10: Train Loss = 0.7287, Val Loss = 14.0564\n",
            "     Epoch 15: Train Loss = 0.7199, Val Loss = 15.7829\n",
            "     Epoch 20: Train Loss = 0.7263, Val Loss = 11.6968\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 1 finished with best val loss: 7.2583\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.8148%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7363, Val Loss = 16.4913\n",
            "     Epoch 5: Train Loss = 0.7283, Val Loss = 12.8942\n",
            "     Epoch 10: Train Loss = 0.7305, Val Loss = 12.2374\n",
            "     Epoch 15: Train Loss = 0.7188, Val Loss = 16.6024\n",
            "     Epoch 20: Train Loss = 0.7292, Val Loss = 13.5108\n",
            "     Epoch 25: Train Loss = 0.7173, Val Loss = 14.3916\n",
            "     Epoch 30: Train Loss = 0.7221, Val Loss = 18.2381\n",
            "    ⏹️ Early stopping at epoch 32\n",
            " Run 2 finished with best val loss: 11.5416\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.9755%\n",
            "   Run 3/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7568, Val Loss = 13.4124\n",
            "     Epoch 5: Train Loss = 0.7253, Val Loss = 12.5060\n",
            "     Epoch 10: Train Loss = 0.7306, Val Loss = 13.8417\n",
            "     Epoch 15: Train Loss = 0.7219, Val Loss = 14.7729\n",
            "     Epoch 20: Train Loss = 0.7233, Val Loss = 14.6055\n",
            "     Epoch 25: Train Loss = 0.7174, Val Loss = 20.0199\n",
            "    ⏹️ Early stopping at epoch 28\n",
            " Run 3 finished with best val loss: 10.9180\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.3897%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7448, Val Loss = 11.7222\n",
            "     Epoch 5: Train Loss = 0.7266, Val Loss = 11.6611\n",
            "     Epoch 10: Train Loss = 0.7292, Val Loss = 14.5626\n",
            "     Epoch 15: Train Loss = 0.7237, Val Loss = 13.6467\n",
            "     Epoch 20: Train Loss = 0.7278, Val Loss = 16.1574\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 4 finished with best val loss: 10.2349\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.6999%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7491, Val Loss = 11.6879\n",
            "     Epoch 5: Train Loss = 0.7228, Val Loss = 12.1716\n",
            "     Epoch 10: Train Loss = 0.7218, Val Loss = 18.0533\n",
            "     Epoch 15: Train Loss = 0.7232, Val Loss = 16.8928\n",
            "     Epoch 20: Train Loss = 0.7283, Val Loss = 13.0854\n",
            "    ⏹️ Early stopping at epoch 24\n",
            " Run 5 finished with best val loss: 11.6292\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1136%\n",
            " Finished configuration H=128, D=0.2, LR=0.001, B=8 → Avg Val Loss: 10.3164, Avg Accuracy: 4.5987%\n",
            "\n",
            " Running 80/81: H=128, D=0.2, LR=0.001, B=16\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7499, Val Loss = 16.6445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7268, Val Loss = 12.7678\n",
            "     Epoch 10: Train Loss = 0.7267, Val Loss = 14.1955\n",
            "     Epoch 15: Train Loss = 0.7385, Val Loss = 15.3225\n",
            "     Epoch 20: Train Loss = 0.7233, Val Loss = 13.9417\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 1 finished with best val loss: 11.5872\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.1158%\n",
            "   Run 2/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7497, Val Loss = 14.3437\n",
            "     Epoch 5: Train Loss = 0.7379, Val Loss = 16.4313\n",
            "     Epoch 10: Train Loss = 0.7230, Val Loss = 11.9071\n",
            "     Epoch 15: Train Loss = 0.7273, Val Loss = 16.9185\n",
            "     Epoch 20: Train Loss = 0.7204, Val Loss = 13.4409\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 2 finished with best val loss: 10.7247\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.6150%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7473, Val Loss = 14.1075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7248, Val Loss = 13.7174\n",
            "     Epoch 10: Train Loss = 0.7315, Val Loss = 17.1285\n",
            "     Epoch 15: Train Loss = 0.7236, Val Loss = 13.0631\n",
            "     Epoch 20: Train Loss = 0.7247, Val Loss = 15.6799\n",
            "    ⏹️ Early stopping at epoch 21\n",
            " Run 3 finished with best val loss: 12.5127\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2448%\n",
            "   Run 4/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7455, Val Loss = 9.5221\n",
            "     Epoch 5: Train Loss = 0.7294, Val Loss = 12.1126\n",
            "     Epoch 10: Train Loss = 0.7303, Val Loss = 14.8128\n",
            "     Epoch 15: Train Loss = 0.7301, Val Loss = 14.6656\n",
            "     Epoch 20: Train Loss = 0.7263, Val Loss = 17.9571\n",
            "    ⏹️ Early stopping at epoch 20\n",
            " Run 4 finished with best val loss: 9.5221\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.0224%\n",
            "   Run 5/5 ...      Epoch 0: Train Loss = 0.7559, Val Loss = 14.3906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7277, Val Loss = 14.1586\n",
            "     Epoch 10: Train Loss = 0.7183, Val Loss = 19.0949\n",
            "     Epoch 15: Train Loss = 0.7212, Val Loss = 18.5657\n",
            "     Epoch 20: Train Loss = 0.7165, Val Loss = 18.3991\n",
            "     Epoch 25: Train Loss = 0.7216, Val Loss = 18.1547\n",
            "    ⏹️ Early stopping at epoch 28\n",
            " Run 5 finished with best val loss: 12.2988\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2692%\n",
            " Finished configuration H=128, D=0.2, LR=0.001, B=16 → Avg Val Loss: 11.3291, Avg Accuracy: 4.4534%\n",
            "\n",
            " Running 81/81: H=128, D=0.2, LR=0.001, B=32\n",
            "   Run 1/5 ...      Epoch 0: Train Loss = 0.7610, Val Loss = 17.4524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7300, Val Loss = 14.2055\n",
            "     Epoch 10: Train Loss = 0.7346, Val Loss = 13.4335\n",
            "     Epoch 15: Train Loss = 0.7248, Val Loss = 17.6982\n",
            "     Epoch 20: Train Loss = 0.7166, Val Loss = 19.1232\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 1 finished with best val loss: 12.5404\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 4.2498%\n",
            "   Run 2/5 ...      Epoch 0: Train Loss = 0.7512, Val Loss = 12.6602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7282, Val Loss = 14.6118\n",
            "     Epoch 10: Train Loss = 0.7256, Val Loss = 15.5002\n",
            "     Epoch 15: Train Loss = 0.7224, Val Loss = 14.8595\n",
            "     Epoch 20: Train Loss = 0.7181, Val Loss = 17.6223\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 2 finished with best val loss: 11.8371\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 6.0282%\n",
            "   Run 3/5 ...      Epoch 0: Train Loss = 0.7473, Val Loss = 13.7222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7333, Val Loss = 14.7187\n",
            "     Epoch 10: Train Loss = 0.7256, Val Loss = 17.5745\n",
            "     Epoch 15: Train Loss = 0.7226, Val Loss = 16.9362\n",
            "     Epoch 20: Train Loss = 0.7256, Val Loss = 19.3939\n",
            "    ⏹️ Early stopping at epoch 23\n",
            " Run 3 finished with best val loss: 11.7509\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.4522%\n",
            "   Run 4/5 ...      Epoch 0: Train Loss = 0.7616, Val Loss = 15.9073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 5: Train Loss = 0.7219, Val Loss = 15.2468\n",
            "     Epoch 10: Train Loss = 0.7279, Val Loss = 14.7242\n",
            "     Epoch 15: Train Loss = 0.7169, Val Loss = 19.6433\n",
            "     Epoch 20: Train Loss = 0.7211, Val Loss = 13.3441\n",
            "    ⏹️ Early stopping at epoch 22\n",
            " Run 4 finished with best val loss: 12.0626\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 5.5327%\n",
            "   Run 5/5 ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Epoch 0: Train Loss = 0.7527, Val Loss = 14.6802\n",
            "     Epoch 5: Train Loss = 0.7291, Val Loss = 15.5843\n",
            "     Epoch 10: Train Loss = 0.7295, Val Loss = 13.2456\n",
            "     Epoch 15: Train Loss = 0.7192, Val Loss = 14.6171\n",
            "     Epoch 20: Train Loss = 0.7184, Val Loss = 13.2029\n",
            "     Epoch 25: Train Loss = 0.7258, Val Loss = 18.7821\n",
            "     Epoch 30: Train Loss = 0.7211, Val Loss = 14.4535\n",
            "     Epoch 35: Train Loss = 0.7292, Val Loss = 14.1048\n",
            "    ⏹️ Early stopping at epoch 36\n",
            " Run 5 finished with best val loss: 11.9025\n",
            "Original Error Percentage (Test Dataset): 4.0399%\n",
            "Corrected Error Percentage (Test Dataset): 3.8833%\n",
            " Finished configuration H=128, D=0.2, LR=0.001, B=32 → Avg Val Loss: 12.0187, Avg Accuracy: 5.0292%\n",
            "\n",
            " Top 5 Hyperparameter Configurations:\n",
            " 1. {'hidden_size': 32, 'dropout_rate': 0.0, 'learning_rate': 0.0001, 'batch_size': 16, 'avg_val_loss': 5.729285934902974, 'avg_accuracy': 3.4770964456291322}\n",
            " 2. {'hidden_size': 32, 'dropout_rate': 0.2, 'learning_rate': 0.0001, 'batch_size': 32, 'avg_val_loss': 6.4012051866543995, 'avg_accuracy': 3.4636447596199305}\n",
            " 3. {'hidden_size': 64, 'dropout_rate': 0.2, 'learning_rate': 0.0001, 'batch_size': 16, 'avg_val_loss': 6.647971623149138, 'avg_accuracy': 3.6280988066714785}\n",
            " 4. {'hidden_size': 32, 'dropout_rate': 0.1, 'learning_rate': 0.0001, 'batch_size': 16, 'avg_val_loss': 6.739226408825805, 'avg_accuracy': 3.4852787090210016}\n",
            " 5. {'hidden_size': 32, 'dropout_rate': 0.0, 'learning_rate': 0.0001, 'batch_size': 32, 'avg_val_loss': 6.817487828463119, 'avg_accuracy': 3.479100656354926}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-438-ab28ec98d12e>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n"
          ]
        }
      ],
      "source": [
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# # Define model\n",
        "# input_size = 1\n",
        "# hidden_size1 = 64\n",
        "# dropout_rate = 0.1\n",
        "# learning_rate = 0.0001\n",
        "# num_epochs = 500\n",
        "# patience = 30\n",
        "\n",
        "# bias_model = BiasPredictor(input_size=input_size, hidden_size1=hidden_size1, dropout_rate=dropout_rate).to(device)\n",
        "# criterion = nn.MSELoss()\n",
        "# optimizer = optim.Adam(bias_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# # Train the model (don't need to save the model yet)\n",
        "# best_val_loss = np.inf\n",
        "# best_epoch = 0\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     bias_model.train()\n",
        "#     train_loss = 0.0\n",
        "#     for X_batch, y_batch in train_loader:\n",
        "#         X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = bias_model(X_batch)\n",
        "#         loss = criterion(outputs, y_batch)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         train_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "#     train_loss /= len(train_loader.dataset)\n",
        "\n",
        "#     bias_model.eval()\n",
        "#     val_loss = 0.0\n",
        "#     with torch.no_grad():\n",
        "#         for X_batch, y_batch in val_loader:\n",
        "#             X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "#             outputs = bias_model(X_batch)\n",
        "#             loss = criterion(outputs, y_batch)\n",
        "#             val_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "#     val_loss /= len(val_loader.dataset)\n",
        "\n",
        "#     if val_loss < best_val_loss:\n",
        "#         best_val_loss = val_loss\n",
        "#         best_epoch = epoch\n",
        "#     elif epoch - best_epoch >= patience:\n",
        "#         print(f\"Stopping early at epoch {epoch}\")\n",
        "#         break\n",
        "\n",
        "#     print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define hyperparameter search space\n",
        "hidden_sizes = [32, 64, 128]\n",
        "dropout_rates = [0.0, 0.1, 0.2]\n",
        "learning_rates = [0.0001, 0.0005, 0.001]\n",
        "batch_sizes = [8, 16, 32]\n",
        "\n",
        "# Total number of hyperparameter combinations\n",
        "total_combinations = len(hidden_sizes) * len(dropout_rates) * len(learning_rates) * len(batch_sizes)\n",
        "combination_counter = 0\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Iterate over all hyperparameter combinations\n",
        "for hidden_size, dropout_rate, learning_rate, batch_size in itertools.product(hidden_sizes, dropout_rates, learning_rates, batch_sizes):\n",
        "    combination_counter += 1\n",
        "    print(f\"\\n Running {combination_counter}/{total_combinations}: H={hidden_size}, D={dropout_rate}, LR={learning_rate}, B={batch_size}\")\n",
        "\n",
        "    val_losses = []\n",
        "    accuracies = []  # To track accuracies for each run\n",
        "    for run in range(5):  # Run each combination 5 times\n",
        "        print(f\"   Run {run + 1}/5 ...\", end=\" \", flush=True)\n",
        "\n",
        "        # Define DataLoaders with the current batch size\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        # Define the model\n",
        "        bias_model = BiasPredictor(input_size=1, hidden_size=hidden_size, dropout_rate=dropout_rate).to(device)\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(bias_model.parameters(), lr=learning_rate)\n",
        "\n",
        "        # Training setup\n",
        "        best_val_loss = np.inf\n",
        "        best_epoch = 0\n",
        "        patience = 20\n",
        "        num_epochs = 500\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(num_epochs):\n",
        "            bias_model.train()\n",
        "            train_loss = 0.0\n",
        "            for X_batch, y_batch in train_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = bias_model(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "            train_loss /= len(train_loader.dataset)\n",
        "\n",
        "            # Validation\n",
        "            bias_model.eval()\n",
        "            val_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for X_batch, y_batch in val_loader:\n",
        "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                    outputs = bias_model(X_batch)\n",
        "                    loss = criterion(outputs, y_batch)\n",
        "                    val_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "            val_loss /= len(val_loader.dataset)\n",
        "\n",
        "            # Print progress every 50 epochs\n",
        "            if epoch % 5 == 0:\n",
        "                print(f\"     Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_epoch = epoch\n",
        "            elif epoch - best_epoch >= patience:\n",
        "                print(f\"    ⏹️ Early stopping at epoch {epoch}\")\n",
        "                break  # Stop training if no improvement\n",
        "\n",
        "        val_losses.append(best_val_loss)  # Store best val loss for this run\n",
        "        print(f\" Run {run + 1} finished with best val loss: {best_val_loss:.4f}\")\n",
        "\n",
        "        # Evaluate accuracy after each run\n",
        "        combined_X = torch.cat((X_train, X_val, X_test), dim=0)\n",
        "        combined_y = torch.cat((y_train, y_val, y_test), dim=0)\n",
        "\n",
        "        # Convert combined_X to tensor and scale if necessary\n",
        "        X_scaled_tensor = torch.tensor(combined_X, dtype=torch.float32).unsqueeze(1)\n",
        "        bias_model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = bias_model(X_scaled_tensor.to(device)).cpu().numpy()\n",
        "\n",
        "        # Unscale outputs\n",
        "        outputs_unscaled = y_scaler.inverse_transform(y_pred.reshape(y_pred.shape[0], -1))\n",
        "\n",
        "        # Calculate error percentages\n",
        "        new_df[\"Bias_Pred\"] = outputs_unscaled\n",
        "        new_df[\"Corrected_LSTM_Pred\"] = new_df[\"LSTM_Pred\"] + new_df[\"Bias_Pred\"]\n",
        "\n",
        "        original_error_percent_test = np.mean(np.abs(new_df[\"Bias\"].iloc[train_size + val_size:]) / (np.abs(new_df[\"Target\"].iloc[train_size + val_size:]) + 1e-8)) * 100\n",
        "        corrected_error_percent_test = np.mean(np.abs(new_df[\"Target\"].iloc[train_size + val_size:] - new_df[\"Corrected_LSTM_Pred\"].iloc[train_size + val_size:]) / (np.abs(new_df[\"Target\"].iloc[train_size + val_size:]) + 1e-8)) * 100\n",
        "\n",
        "        print(f\"Original Error Percentage (Test Dataset): {original_error_percent_test:.4f}%\")\n",
        "        print(f\"Corrected Error Percentage (Test Dataset): {corrected_error_percent_test:.4f}%\")\n",
        "\n",
        "        # Store accuracy for this run\n",
        "        accuracies.append(corrected_error_percent_test)\n",
        "\n",
        "    # After all 5 trials, calculate the average accuracy\n",
        "    avg_val_loss = np.mean(val_losses)\n",
        "    avg_accuracy = np.mean(accuracies)  # Calculate the average error percentage over all runs\n",
        "\n",
        "    results.append({\n",
        "        \"hidden_size\": hidden_size,\n",
        "        \"dropout_rate\": dropout_rate,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"avg_val_loss\": avg_val_loss,\n",
        "        \"avg_accuracy\": avg_accuracy\n",
        "    })\n",
        "\n",
        "    print(f\" Finished configuration H={hidden_size}, D={dropout_rate}, LR={learning_rate}, B={batch_size} → Avg Val Loss: {avg_val_loss:.4f}, Avg Accuracy: {avg_accuracy:.4f}%\")\n",
        "\n",
        "# Sort results by lowest validation loss\n",
        "results.sort(key=lambda x: x[\"avg_val_loss\"])\n",
        "\n",
        "# Print top 5 configurations\n",
        "print(\"\\n Top 5 Hyperparameter Configurations:\")\n",
        "for i, res in enumerate(results[:5]):\n",
        "    print(f\" {i+1}. {res}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
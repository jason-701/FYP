{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "df_encoded = pd.get_dummies(df, columns=['gender', 'smoking_history'], drop_first=True)\n",
    "testDF = df_encoded.sample(frac=1).reset_index(drop=True)\n",
    "x_unscaled = testDF.drop(['diabetes'], axis=1)\n",
    "y = testDF['diabetes']\n",
    "\n",
    "# Normalize the data\n",
    "numerical_columns = x_unscaled.select_dtypes(include=np.number).columns\n",
    "boolean_columns = x_unscaled.select_dtypes(include=bool).columns\n",
    "scaler = StandardScaler()\n",
    "temp = pd.DataFrame(scaler.fit_transform(x_unscaled[numerical_columns]), columns=numerical_columns)\n",
    "x_scaled = pd.concat([temp, x_unscaled[boolean_columns]], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Encoder model with reduced complexity and dropout\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, encoding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "# Define the Decoder model with reduced complexity and dropout\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoding_dim, input_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROG\\AppData\\Local\\Temp/ipykernel_23240/3703475411.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder.load_state_dict(torch.load(encoder_model_file))\n",
      "C:\\Users\\ROG\\AppData\\Local\\Temp/ipykernel_23240/3703475411.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  decoder.load_state_dict(torch.load(decoder_model_file))\n"
     ]
    }
   ],
   "source": [
    "# Define input dimensions\n",
    "input_dim = x_train.shape[1]\n",
    "encoding_dim = 8\n",
    "\n",
    "# Load the trained autoencoder models\n",
    "encoder_model_file = './models/encoder2.pth'\n",
    "decoder_model_file = './models/decoder2.pth'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder = Encoder(input_dim, encoding_dim).to(device)\n",
    "decoder = Decoder(encoding_dim, input_dim).to(device)\n",
    "encoder.load_state_dict(torch.load(encoder_model_file))\n",
    "decoder.load_state_dict(torch.load(decoder_model_file))\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Define the Autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = Autoencoder(encoder, decoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error correction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Accuracy: 97.20%\n",
      "Total correct predictions: 19441\n",
      "Total wrong predictions: 559\n",
      "Number of 0s predicted as 1s (False Positives): 33\n",
      "Number of 1s predicted as 0s (False Negatives): 526\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def error_correction_function(mlp, autoencoder, x, threshold=5.0, bias_factor=0.1):\n",
    "    # Calculate reconstruction error\n",
    "    with torch.no_grad():\n",
    "        encoded = autoencoder.encoder(torch.tensor(x, dtype=torch.float32).to(device))\n",
    "        reconstructed = autoencoder.decoder(encoded).cpu().numpy()\n",
    "    reconstruction_error = np.mean(np.square(x - reconstructed), axis=1)\n",
    "    \n",
    "    # Add reconstruction error as an additional feature\n",
    "    x_augmented = np.hstack((x, reconstruction_error.reshape(-1, 1)))\n",
    "    \n",
    "    # Make predictions with the MLP model\n",
    "    y_pred_proba = mlp.predict_proba(x_augmented)[:, 1]  # Get the probability of the positive class\n",
    "    \n",
    "    # Adjust predictions based on reconstruction error\n",
    "    high_error_indices = np.where(reconstruction_error > (threshold / 100))[0]\n",
    "    y_pred_proba_corrected = y_pred_proba.copy()\n",
    "    y_pred_proba_corrected[high_error_indices] += bias_factor  # Add bias to high error predictions\n",
    "    y_pred_proba_corrected = np.clip(y_pred_proba_corrected, 0, 1)  # Ensure probabilities are within [0, 1]\n",
    "    \n",
    "    # Convert probabilities to binary predictions\n",
    "    y_pred_corrected = (y_pred_proba_corrected > 0.5).astype(int)\n",
    "    \n",
    "    return y_pred_corrected\n",
    "\n",
    "# Use the error correction function to make predictions\n",
    "y_pred_corrected = error_correction_function(mlp, autoencoder, x_test.values)\n",
    "\n",
    "# Calculate corrected accuracy\n",
    "corrected_accuracy = accuracy_score(y_test, y_pred_corrected)\n",
    "print(f\"Corrected Accuracy: {corrected_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_corrected)\n",
    "\n",
    "# Extract values from confusion matrix\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "print(f\"Total correct predictions: {tn + tp}\")\n",
    "print(f\"Total wrong predictions: {fp + fn}\")\n",
    "print(f\"Number of 0s predicted as 1s (False Positives): {fp}\")\n",
    "print(f\"Number of 1s predicted as 0s (False Negatives): {fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROG\\AppData\\Local\\Temp/ipykernel_23240/1470853420.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  original_mlp.load_state_dict(torch.load(mlp_model_file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original MLP Accuracy: 96.84%\n",
      "Total correct predictions: 19367\n",
      "Total wrong predictions: 633\n",
      "Number of 0s predicted as 1s (False Positives): 25\n",
      "Number of 1s predicted as 0s (False Negatives): 608\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Define the original MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Load the original MLP model\n",
    "mlp_model_file = './models/mlp_model_resampled_0.1.pth'\n",
    "input_dim = x_train.shape[1]\n",
    "original_mlp = MLP(input_dim).to(device)\n",
    "original_mlp.load_state_dict(torch.load(mlp_model_file))\n",
    "original_mlp.eval()\n",
    "\n",
    "# Evaluate the original MLP model\n",
    "with torch.no_grad():\n",
    "    x_test_tensor = torch.tensor(x_test.values, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "    y_pred_original = original_mlp(x_test_tensor).cpu().numpy().flatten()\n",
    "    y_pred_original = (y_pred_original > 0.5).astype(int)  # Convert to binary predictions\n",
    "\n",
    "# Calculate accuracy\n",
    "original_accuracy = accuracy_score(y_test, y_pred_original)\n",
    "print(f\"Original MLP Accuracy: {original_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix_original = confusion_matrix(y_test, y_pred_original)\n",
    "\n",
    "# Extract values from confusion matrix\n",
    "tn, fp, fn, tp = conf_matrix_original.ravel()\n",
    "\n",
    "print(f\"Total correct predictions: {tn + tp}\")\n",
    "print(f\"Total wrong predictions: {fp + fn}\")\n",
    "print(f\"Number of 0s predicted as 1s (False Positives): {fp}\")\n",
    "print(f\"Number of 1s predicted as 0s (False Negatives): {fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

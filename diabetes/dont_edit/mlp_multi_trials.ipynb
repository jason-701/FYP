{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history',\n",
      "       'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Preprocessing</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "smoking_history        0\n",
      "bmi                    0\n",
      "HbA1c_level            0\n",
      "blood_glucose_level    0\n",
      "diabetes               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_counts = df.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:yellow\">No columns have null values</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique values in gender : 3\n",
      "number of unique values in age : 102\n",
      "number of unique values in hypertension : 2\n",
      "number of unique values in heart_disease : 2\n",
      "number of unique values in smoking_history : 6\n",
      "number of unique values in bmi : 4247\n",
      "number of unique values in HbA1c_level : 18\n",
      "number of unique values in blood_glucose_level : 18\n",
      "number of unique values in diabetes : 2\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(\"number of unique values in\", i, \":\", df[i].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:yellow\">One-hot encoding for gender and smoking_history</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  hypertension  heart_disease    bmi  HbA1c_level  blood_glucose_level  \\\n",
      "0  80.0             0              1  25.19          6.6                  140   \n",
      "1  54.0             0              0  27.32          6.6                   80   \n",
      "2  28.0             0              0  27.32          5.7                  158   \n",
      "3  36.0             0              0  23.45          5.0                  155   \n",
      "4  76.0             1              1  20.14          4.8                  155   \n",
      "\n",
      "   diabetes  gender_Male  gender_Other  smoking_history_current  \\\n",
      "0         0            0             0                        0   \n",
      "1         0            0             0                        0   \n",
      "2         0            1             0                        0   \n",
      "3         0            0             0                        1   \n",
      "4         0            1             0                        1   \n",
      "\n",
      "   smoking_history_ever  smoking_history_former  smoking_history_never  \\\n",
      "0                     0                       0                      1   \n",
      "1                     0                       0                      0   \n",
      "2                     0                       0                      1   \n",
      "3                     0                       0                      0   \n",
      "4                     0                       0                      0   \n",
      "\n",
      "   smoking_history_not current  \n",
      "0                            0  \n",
      "1                            0  \n",
      "2                            0  \n",
      "3                            0  \n",
      "4                            0  \n"
     ]
    }
   ],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['gender', 'smoking_history'], drop_first=True)\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:yellow\">Normalizing the data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index(['age', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level',\n",
      "       'blood_glucose_level', 'diabetes', 'gender_Male', 'gender_Other',\n",
      "       'smoking_history_current', 'smoking_history_ever',\n",
      "       'smoking_history_former', 'smoking_history_never',\n",
      "       'smoking_history_not current'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "boolean_columns = df_encoded.select_dtypes(include=bool).columns\n",
    "numerical_columns = df_encoded.select_dtypes(include=np.number).columns\n",
    "print(boolean_columns)\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled and Scaled DataFrame:\n",
      "        age  hypertension  heart_disease       bmi  HbA1c_level  \\\n",
      "0  1.692704     -0.284439       4.936379 -0.321056     1.001706   \n",
      "1  0.538006     -0.284439      -0.202578 -0.000116     1.001706   \n",
      "2 -0.616691     -0.284439      -0.202578 -0.000116     0.161108   \n",
      "3 -0.261399     -0.284439      -0.202578 -0.583232    -0.492690   \n",
      "4  1.515058      3.515687       4.936379 -1.081970    -0.679490   \n",
      "\n",
      "   blood_glucose_level  gender_Male  gender_Other  smoking_history_current  \\\n",
      "0             0.047704            0             0                        0   \n",
      "1            -1.426210            0             0                        0   \n",
      "2             0.489878            1             0                        0   \n",
      "3             0.416183            0             0                        1   \n",
      "4             0.416183            1             0                        1   \n",
      "\n",
      "   smoking_history_ever  smoking_history_former  smoking_history_never  \\\n",
      "0                     0                       0                      1   \n",
      "1                     0                       0                      0   \n",
      "2                     0                       0                      1   \n",
      "3                     0                       0                      0   \n",
      "4                     0                       0                      0   \n",
      "\n",
      "   smoking_history_not current  diabetes  \n",
      "0                            0         0  \n",
      "1                            0         0  \n",
      "2                            0         0  \n",
      "3                            0         0  \n",
      "4                            0         0  \n",
      "\n",
      "Class Distribution After Resampling:\n",
      "0    91500\n",
      "1     8500\n",
      "Name: diabetes, dtype: int64\n",
      "\n",
      "Class distribution before resampling:\n",
      "0    91500\n",
      "1     8500\n",
      "Name: diabetes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df_encoded.drop(columns=['diabetes'])\n",
    "y = df_encoded['diabetes']\n",
    "\n",
    "# Identify numerical, boolean, and one-hot encoded columns\n",
    "numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "boolean_columns = X.select_dtypes(include=['bool']).columns\n",
    "one_hot_encoded_columns = X.columns.difference(numerical_columns.union(boolean_columns))\n",
    "\n",
    "# Resample the data using SMOTE\n",
    "# smote = SMOTE(random_state=42, sampling_strategy=0.10)\n",
    "\n",
    "# Nevermind let's not do the resampling for now\n",
    "X_resampled, y_resampled = X,y\n",
    "\n",
    "# Normalize the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_resampled_numerical = pd.DataFrame(scaler.fit_transform(X_resampled[numerical_columns]), columns=numerical_columns)\n",
    "\n",
    "# Combine the normalized numerical features with the boolean and one-hot encoded features\n",
    "X_resampled_scaled = pd.concat([X_resampled_numerical, X_resampled[boolean_columns].reset_index(drop=True), X_resampled[one_hot_encoded_columns].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Add the target variable back to the DataFrame\n",
    "df_resampled_scaled = pd.concat([X_resampled_scaled, y_resampled.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Display the first few rows of the resampled and scaled DataFrame\n",
    "print(\"Resampled and Scaled DataFrame:\")\n",
    "print(df_resampled_scaled.head())\n",
    "\n",
    "# Check the class distribution after resampling\n",
    "print(\"\\nClass Distribution After Resampling:\")\n",
    "print(df_resampled_scaled['diabetes'].value_counts())\n",
    "\n",
    "print(\"\\nClass distribution before resampling:\")\n",
    "print(df['diabetes'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:yellow\">Train test split</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 69997\n",
      "Validation set size: 15003\n",
      "Test set size: 15000\n"
     ]
    }
   ],
   "source": [
    "x = df_resampled_scaled.drop('diabetes', axis=1)\n",
    "y = df_resampled_scaled['diabetes']\n",
    "\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.1765, random_state=42)\n",
    "\n",
    "print(f\"Train set size: {len(x_train)}\")\n",
    "print(f\"Validation set size: {len(x_val)}\")\n",
    "print(f\"Test set size: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:yellow\">Training an MLP model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# # Check if CUDA is available and print the device being used\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # Convert data to PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "# y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "# X_test_tensor = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "# y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# # Create DataLoader\n",
    "# train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(MLP, self).__init__()\n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Linear(input_dim, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, 32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(32, 1),\n",
    "#             nn.Sigmoid()  # Sigmoid for binary classification\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)\n",
    "\n",
    "\n",
    "# # Initialize the model, loss function, and optimizer\n",
    "# input_dim = x_train.shape[1]\n",
    "# model = MLP(input_dim).to(device)\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Define the path to the saved model file\n",
    "# model_file = './models/mlp_model.pth'\n",
    "\n",
    "# # Check if the model file exists\n",
    "# if os.path.exists(model_file):\n",
    "#     print(\"Model file exists. Loading the model...\")\n",
    "#     model.load_state_dict(torch.load(model_file))\n",
    "# else:\n",
    "#     print(\"Model file does not exist. Training a new model...\")\n",
    "\n",
    "#     # Train the model\n",
    "#     num_epochs = 50\n",
    "#     best_loss = float('inf')\n",
    "#     patience = 3\n",
    "#     patience_counter = 0\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         for X_batch, y_batch in train_loader:\n",
    "#             X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(X_batch)\n",
    "#             loss = criterion(outputs, y_batch)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             running_loss += loss.item() * X_batch.size(0)\n",
    "        \n",
    "#         epoch_loss = running_loss / len(train_loader.dataset)\n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "#         # Early stopping\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         with torch.no_grad():\n",
    "#             for X_batch, y_batch in test_loader:\n",
    "#                 X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "#                 outputs = model(X_batch)\n",
    "#                 loss = criterion(outputs, y_batch)\n",
    "#                 val_loss += loss.item() * X_batch.size(0)\n",
    "        \n",
    "#         val_loss /= len(test_loader.dataset)\n",
    "#         print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "#         if val_loss < best_loss:\n",
    "#             best_loss = val_loss\n",
    "#             patience_counter = 0\n",
    "#         else:\n",
    "#             patience_counter += 1\n",
    "#             if patience_counter >= patience:\n",
    "#                 print(\"Early stopping triggered.\")\n",
    "#                 break\n",
    "\n",
    "#     # Save the trained model after training is complete\n",
    "#     torch.save(model.state_dict(), model_file)\n",
    "#     print(\"Model trained and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, dropout):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_mlp(train_dataset, val_dataset, batch_size, hidden_size, learning_rate, dropout, num_epochs, patience, model_file='./models/mlp_model.pth'):\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    input_dim = train_dataset.tensors[0].shape[1]\n",
    "    model = MLP(input_dim, hidden_size, dropout).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Check if the model file exists\n",
    "    if os.path.exists(model_file):\n",
    "        print(\"Model file exists. Loading the model...\")\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "    else:\n",
    "        print(\"Model file does not exist. Training a new model...\")\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item() * X_batch.size(0)\n",
    "            \n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "            # Early stopping\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in val_loader:\n",
    "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                    outputs = model(X_batch)\n",
    "                    loss = criterion(outputs, y_batch)\n",
    "                    val_loss += loss.item() * X_batch.size(0)\n",
    "            \n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "        # Save the trained model after training is complete\n",
    "        torch.save(model.state_dict(), model_file)\n",
    "        print(\"Model trained and saved.\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_tensor = torch.tensor(x_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters\n",
    "# batch_size = 32\n",
    "# hidden_size = 64\n",
    "# learning_rate = 0.001\n",
    "# dropout = 0.2\n",
    "# num_epochs = 250\n",
    "# patience = 20\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = train_mlp(train_dataset, val_dataset, batch_size, hidden_size, learning_rate, dropout, num_epochs, patience)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# # Evaluate the model\n",
    "# model.eval()\n",
    "# test_loss = 0.0\n",
    "# with torch.no_grad():\n",
    "#     for X_batch, y_batch in test_loader:\n",
    "#         X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "#         outputs = model(X_batch)\n",
    "\n",
    "# # Calculate Mean Absolute Error (MAE)\n",
    "# test_mae = 0.0\n",
    "# with torch.no_grad():\n",
    "#     for X_batch, y_batch in test_loader:\n",
    "#         X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "#         outputs = model(X_batch)\n",
    "#         mae = torch.mean(torch.abs(outputs - y_batch))\n",
    "#         test_mae += mae.item() * X_batch.size(0)\n",
    "\n",
    "# test_mae /= len(test_loader.dataset)\n",
    "# print(f'Test MAE: {test_mae:.4f}')\n",
    "\n",
    "# # Calculate Prediction Accuracy\n",
    "# correct_predictions = 0\n",
    "# total_predictions = 0\n",
    "# with torch.no_grad():\n",
    "#     for X_batch, y_batch in test_loader:\n",
    "#         X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "#         outputs = model(X_batch)  # Outputs are probabilities due to sigmoid\n",
    "#         predictions = (outputs > 0.5).float()  # Convert probabilities to binary predictions\n",
    "#         correct_predictions += torch.sum(predictions == y_batch).item()\n",
    "#         total_predictions += y_batch.size(0)\n",
    "\n",
    "# accuracy = correct_predictions / total_predictions\n",
    "# print(\"Total Predictions:\", total_predictions)\n",
    "# print(\"Correct Predictions:\", correct_predictions)\n",
    "# print(\"Incorrect Predictions:\", total_predictions - correct_predictions)\n",
    "# print(f'Prediction Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/10\n",
      "Using device: cuda\n",
      "Model file does not exist. Training a new model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.1446\n",
      "Validation Loss: 0.1023\n",
      "Epoch [2/50], Loss: 0.1076\n",
      "Validation Loss: 0.0916\n",
      "Epoch [3/50], Loss: 0.0981\n",
      "Validation Loss: 0.0863\n",
      "Epoch [4/50], Loss: 0.0938\n",
      "Validation Loss: 0.0829\n",
      "Epoch [5/50], Loss: 0.0912\n",
      "Validation Loss: 0.0817\n",
      "Epoch [6/50], Loss: 0.0892\n",
      "Validation Loss: 0.0807\n",
      "Epoch [7/50], Loss: 0.0882\n",
      "Validation Loss: 0.0796\n",
      "Epoch [8/50], Loss: 0.0873\n",
      "Validation Loss: 0.0796\n",
      "Epoch [9/50], Loss: 0.0867\n",
      "Validation Loss: 0.0793\n",
      "Epoch [10/50], Loss: 0.0862\n",
      "Validation Loss: 0.0790\n",
      "Epoch [11/50], Loss: 0.0854\n",
      "Validation Loss: 0.0793\n",
      "Epoch [12/50], Loss: 0.0853\n",
      "Validation Loss: 0.0791\n",
      "Epoch [13/50], Loss: 0.0847\n",
      "Validation Loss: 0.0784\n",
      "Epoch [14/50], Loss: 0.0842\n",
      "Validation Loss: 0.0786\n",
      "Epoch [15/50], Loss: 0.0845\n",
      "Validation Loss: 0.0781\n",
      "Epoch [16/50], Loss: 0.0844\n",
      "Validation Loss: 0.0782\n",
      "Epoch [17/50], Loss: 0.0833\n",
      "Validation Loss: 0.0782\n",
      "Epoch [18/50], Loss: 0.0837\n",
      "Validation Loss: 0.0784\n",
      "Epoch [19/50], Loss: 0.0833\n",
      "Validation Loss: 0.0783\n",
      "Epoch [20/50], Loss: 0.0836\n",
      "Validation Loss: 0.0784\n",
      "Epoch [21/50], Loss: 0.0836\n",
      "Validation Loss: 0.0782\n",
      "Epoch [22/50], Loss: 0.0836\n",
      "Validation Loss: 0.0783\n",
      "Epoch [23/50], Loss: 0.0836\n",
      "Validation Loss: 0.0781\n",
      "Epoch [24/50], Loss: 0.0834\n",
      "Validation Loss: 0.0780\n",
      "Epoch [25/50], Loss: 0.0834\n",
      "Validation Loss: 0.0792\n",
      "Epoch [26/50], Loss: 0.0834\n",
      "Validation Loss: 0.0782\n",
      "Epoch [27/50], Loss: 0.0829\n",
      "Validation Loss: 0.0792\n",
      "Epoch [28/50], Loss: 0.0830\n",
      "Validation Loss: 0.0782\n",
      "Epoch [29/50], Loss: 0.0826\n",
      "Validation Loss: 0.0785\n",
      "Epoch [30/50], Loss: 0.0830\n",
      "Validation Loss: 0.0786\n",
      "Epoch [31/50], Loss: 0.0830\n",
      "Validation Loss: 0.0789\n",
      "Epoch [32/50], Loss: 0.0830\n",
      "Validation Loss: 0.0792\n",
      "Epoch [33/50], Loss: 0.0833\n",
      "Validation Loss: 0.0785\n",
      "Epoch [34/50], Loss: 0.0829\n",
      "Validation Loss: 0.0786\n",
      "Early stopping triggered.\n",
      "Model trained and saved.\n",
      "Saved model: ./models/mlp_model_trial_1.pth\n",
      "Accuracy: 0.9718\n",
      "Precision: 0.9931\n",
      "Recall: 0.6752\n",
      "F1-score: 0.8039\n",
      "Trial 2/10\n",
      "Using device: cuda\n",
      "Model file does not exist. Training a new model...\n",
      "Epoch [1/50], Loss: 0.1455\n",
      "Validation Loss: 0.1024\n",
      "Epoch [2/50], Loss: 0.1072\n",
      "Validation Loss: 0.0904\n",
      "Epoch [3/50], Loss: 0.0976\n",
      "Validation Loss: 0.0860\n",
      "Epoch [4/50], Loss: 0.0935\n",
      "Validation Loss: 0.0832\n",
      "Epoch [5/50], Loss: 0.0908\n",
      "Validation Loss: 0.0817\n",
      "Epoch [6/50], Loss: 0.0882\n",
      "Validation Loss: 0.0814\n",
      "Epoch [7/50], Loss: 0.0875\n",
      "Validation Loss: 0.0801\n",
      "Epoch [8/50], Loss: 0.0873\n",
      "Validation Loss: 0.0801\n",
      "Epoch [9/50], Loss: 0.0856\n",
      "Validation Loss: 0.0808\n",
      "Epoch [10/50], Loss: 0.0856\n",
      "Validation Loss: 0.0792\n",
      "Epoch [11/50], Loss: 0.0852\n",
      "Validation Loss: 0.0806\n",
      "Epoch [12/50], Loss: 0.0849\n",
      "Validation Loss: 0.0791\n",
      "Epoch [13/50], Loss: 0.0850\n",
      "Validation Loss: 0.0786\n",
      "Epoch [14/50], Loss: 0.0843\n",
      "Validation Loss: 0.0785\n",
      "Epoch [15/50], Loss: 0.0842\n",
      "Validation Loss: 0.0782\n",
      "Epoch [16/50], Loss: 0.0841\n",
      "Validation Loss: 0.0783\n",
      "Epoch [17/50], Loss: 0.0839\n",
      "Validation Loss: 0.0787\n",
      "Epoch [18/50], Loss: 0.0839\n",
      "Validation Loss: 0.0783\n",
      "Epoch [19/50], Loss: 0.0832\n",
      "Validation Loss: 0.0783\n",
      "Epoch [20/50], Loss: 0.0835\n",
      "Validation Loss: 0.0787\n",
      "Epoch [21/50], Loss: 0.0834\n",
      "Validation Loss: 0.0829\n",
      "Epoch [22/50], Loss: 0.0832\n",
      "Validation Loss: 0.0789\n",
      "Epoch [23/50], Loss: 0.0833\n",
      "Validation Loss: 0.0785\n",
      "Epoch [24/50], Loss: 0.0831\n",
      "Validation Loss: 0.0787\n",
      "Epoch [25/50], Loss: 0.0832\n",
      "Validation Loss: 0.0807\n",
      "Early stopping triggered.\n",
      "Model trained and saved.\n",
      "Saved model: ./models/mlp_model_trial_2.pth\n",
      "Accuracy: 0.9704\n",
      "Precision: 0.9605\n",
      "Recall: 0.6822\n",
      "F1-score: 0.7978\n",
      "Trial 3/10\n",
      "Using device: cuda\n",
      "Model file does not exist. Training a new model...\n",
      "Epoch [1/50], Loss: 0.1469\n",
      "Validation Loss: 0.1020\n",
      "Epoch [2/50], Loss: 0.1071\n",
      "Validation Loss: 0.0916\n",
      "Epoch [3/50], Loss: 0.0978\n",
      "Validation Loss: 0.0851\n",
      "Epoch [4/50], Loss: 0.0933\n",
      "Validation Loss: 0.0826\n",
      "Epoch [5/50], Loss: 0.0906\n",
      "Validation Loss: 0.0808\n",
      "Epoch [6/50], Loss: 0.0889\n",
      "Validation Loss: 0.0807\n",
      "Epoch [7/50], Loss: 0.0871\n",
      "Validation Loss: 0.0801\n",
      "Epoch [8/50], Loss: 0.0862\n",
      "Validation Loss: 0.0798\n",
      "Epoch [9/50], Loss: 0.0864\n",
      "Validation Loss: 0.0789\n",
      "Epoch [10/50], Loss: 0.0851\n",
      "Validation Loss: 0.0787\n",
      "Epoch [11/50], Loss: 0.0849\n",
      "Validation Loss: 0.0797\n",
      "Epoch [12/50], Loss: 0.0847\n",
      "Validation Loss: 0.0786\n",
      "Epoch [13/50], Loss: 0.0844\n",
      "Validation Loss: 0.0791\n",
      "Epoch [14/50], Loss: 0.0847\n",
      "Validation Loss: 0.0791\n",
      "Epoch [15/50], Loss: 0.0839\n",
      "Validation Loss: 0.0785\n",
      "Epoch [16/50], Loss: 0.0844\n",
      "Validation Loss: 0.0786\n",
      "Epoch [17/50], Loss: 0.0843\n",
      "Validation Loss: 0.0785\n",
      "Epoch [18/50], Loss: 0.0838\n",
      "Validation Loss: 0.0787\n",
      "Epoch [19/50], Loss: 0.0837\n",
      "Validation Loss: 0.0789\n",
      "Epoch [20/50], Loss: 0.0840\n",
      "Validation Loss: 0.0787\n",
      "Epoch [21/50], Loss: 0.0838\n",
      "Validation Loss: 0.0784\n",
      "Epoch [22/50], Loss: 0.0833\n",
      "Validation Loss: 0.0784\n",
      "Epoch [23/50], Loss: 0.0835\n",
      "Validation Loss: 0.0786\n",
      "Epoch [24/50], Loss: 0.0836\n",
      "Validation Loss: 0.0782\n",
      "Epoch [25/50], Loss: 0.0831\n",
      "Validation Loss: 0.0794\n",
      "Epoch [26/50], Loss: 0.0835\n",
      "Validation Loss: 0.0783\n",
      "Epoch [27/50], Loss: 0.0834\n",
      "Validation Loss: 0.0787\n",
      "Epoch [28/50], Loss: 0.0827\n",
      "Validation Loss: 0.0787\n",
      "Epoch [29/50], Loss: 0.0833\n",
      "Validation Loss: 0.0789\n",
      "Epoch [30/50], Loss: 0.0833\n",
      "Validation Loss: 0.0785\n",
      "Epoch [31/50], Loss: 0.0836\n",
      "Validation Loss: 0.0809\n",
      "Epoch [32/50], Loss: 0.0830\n",
      "Validation Loss: 0.0784\n",
      "Epoch [33/50], Loss: 0.0829\n",
      "Validation Loss: 0.0785\n",
      "Epoch [34/50], Loss: 0.0829\n",
      "Validation Loss: 0.0785\n",
      "Early stopping triggered.\n",
      "Model trained and saved.\n",
      "Saved model: ./models/mlp_model_trial_3.pth\n",
      "Accuracy: 0.9714\n",
      "Precision: 0.9931\n",
      "Recall: 0.6706\n",
      "F1-score: 0.8006\n",
      "Trial 4/10\n",
      "Using device: cuda\n",
      "Model file does not exist. Training a new model...\n",
      "Epoch [1/50], Loss: 0.1431\n",
      "Validation Loss: 0.1024\n",
      "Epoch [2/50], Loss: 0.1085\n",
      "Validation Loss: 0.0931\n",
      "Epoch [3/50], Loss: 0.0998\n",
      "Validation Loss: 0.0869\n",
      "Epoch [4/50], Loss: 0.0945\n",
      "Validation Loss: 0.0835\n",
      "Epoch [5/50], Loss: 0.0908\n",
      "Validation Loss: 0.0811\n",
      "Epoch [6/50], Loss: 0.0883\n",
      "Validation Loss: 0.0803\n",
      "Epoch [7/50], Loss: 0.0871\n",
      "Validation Loss: 0.0803\n",
      "Epoch [8/50], Loss: 0.0863\n",
      "Validation Loss: 0.0792\n",
      "Epoch [9/50], Loss: 0.0853\n",
      "Validation Loss: 0.0800\n",
      "Epoch [10/50], Loss: 0.0854\n",
      "Validation Loss: 0.0807\n",
      "Epoch [11/50], Loss: 0.0849\n",
      "Validation Loss: 0.0782\n",
      "Epoch [12/50], Loss: 0.0848\n",
      "Validation Loss: 0.0796\n",
      "Epoch [13/50], Loss: 0.0842\n",
      "Validation Loss: 0.0794\n",
      "Epoch [14/50], Loss: 0.0840\n",
      "Validation Loss: 0.0797\n",
      "Epoch [15/50], Loss: 0.0836\n",
      "Validation Loss: 0.0783\n",
      "Epoch [16/50], Loss: 0.0840\n",
      "Validation Loss: 0.0784\n",
      "Epoch [17/50], Loss: 0.0832\n",
      "Validation Loss: 0.0785\n",
      "Epoch [18/50], Loss: 0.0838\n",
      "Validation Loss: 0.0783\n",
      "Epoch [19/50], Loss: 0.0835\n",
      "Validation Loss: 0.0796\n",
      "Epoch [20/50], Loss: 0.0835\n",
      "Validation Loss: 0.0797\n",
      "Epoch [21/50], Loss: 0.0831\n",
      "Validation Loss: 0.0786\n",
      "Early stopping triggered.\n",
      "Model trained and saved.\n",
      "Saved model: ./models/mlp_model_trial_4.pth\n",
      "Accuracy: 0.9717\n",
      "Precision: 1.0000\n",
      "Recall: 0.6698\n",
      "F1-score: 0.8022\n",
      "Trial 5/10\n",
      "Using device: cuda\n",
      "Model file does not exist. Training a new model...\n",
      "Epoch [1/50], Loss: 0.1390\n",
      "Validation Loss: 0.1021\n",
      "Epoch [2/50], Loss: 0.1060\n",
      "Validation Loss: 0.0908\n",
      "Epoch [3/50], Loss: 0.0973\n",
      "Validation Loss: 0.0860\n",
      "Epoch [4/50], Loss: 0.0922\n",
      "Validation Loss: 0.0831\n",
      "Epoch [5/50], Loss: 0.0900\n",
      "Validation Loss: 0.0813\n",
      "Epoch [6/50], Loss: 0.0886\n",
      "Validation Loss: 0.0810\n",
      "Epoch [7/50], Loss: 0.0871\n",
      "Validation Loss: 0.0797\n",
      "Epoch [8/50], Loss: 0.0862\n",
      "Validation Loss: 0.0788\n",
      "Epoch [9/50], Loss: 0.0854\n",
      "Validation Loss: 0.0788\n",
      "Epoch [10/50], Loss: 0.0849\n",
      "Validation Loss: 0.0789\n",
      "Epoch [11/50], Loss: 0.0848\n",
      "Validation Loss: 0.0786\n",
      "Epoch [12/50], Loss: 0.0846\n",
      "Validation Loss: 0.0789\n",
      "Epoch [13/50], Loss: 0.0842\n",
      "Validation Loss: 0.0786\n",
      "Epoch [14/50], Loss: 0.0841\n",
      "Validation Loss: 0.0784\n",
      "Epoch [15/50], Loss: 0.0843\n",
      "Validation Loss: 0.0788\n",
      "Epoch [16/50], Loss: 0.0841\n",
      "Validation Loss: 0.0786\n",
      "Epoch [17/50], Loss: 0.0836\n",
      "Validation Loss: 0.0785\n",
      "Epoch [18/50], Loss: 0.0838\n",
      "Validation Loss: 0.0785\n",
      "Epoch [19/50], Loss: 0.0840\n",
      "Validation Loss: 0.0787\n",
      "Epoch [20/50], Loss: 0.0837\n",
      "Validation Loss: 0.0788\n",
      "Epoch [21/50], Loss: 0.0833\n",
      "Validation Loss: 0.0783\n",
      "Epoch [22/50], Loss: 0.0830\n",
      "Validation Loss: 0.0788\n",
      "Epoch [23/50], Loss: 0.0833\n",
      "Validation Loss: 0.0784\n",
      "Epoch [24/50], Loss: 0.0833\n",
      "Validation Loss: 0.0785\n",
      "Epoch [25/50], Loss: 0.0834\n",
      "Validation Loss: 0.0785\n",
      "Epoch [26/50], Loss: 0.0831\n",
      "Validation Loss: 0.0788\n",
      "Epoch [27/50], Loss: 0.0827\n",
      "Validation Loss: 0.0787\n",
      "Epoch [28/50], Loss: 0.0826\n",
      "Validation Loss: 0.0790\n",
      "Epoch [29/50], Loss: 0.0826\n",
      "Validation Loss: 0.0786\n",
      "Epoch [30/50], Loss: 0.0827\n",
      "Validation Loss: 0.0789\n",
      "Epoch [31/50], Loss: 0.0828\n",
      "Validation Loss: 0.0783\n",
      "Epoch [32/50], Loss: 0.0826\n",
      "Validation Loss: 0.0784\n",
      "Epoch [33/50], Loss: 0.0827\n",
      "Validation Loss: 0.0790\n",
      "Epoch [34/50], Loss: 0.0828\n",
      "Validation Loss: 0.0790\n",
      "Epoch [35/50], Loss: 0.0827\n",
      "Validation Loss: 0.0786\n",
      "Epoch [36/50], Loss: 0.0827\n",
      "Validation Loss: 0.0785\n",
      "Epoch [37/50], Loss: 0.0827\n",
      "Validation Loss: 0.0787\n",
      "Epoch [38/50], Loss: 0.0822\n",
      "Validation Loss: 0.0790\n",
      "Epoch [39/50], Loss: 0.0824\n",
      "Validation Loss: 0.0793\n",
      "Epoch [40/50], Loss: 0.0824\n",
      "Validation Loss: 0.0782\n",
      "Epoch [41/50], Loss: 0.0823\n",
      "Validation Loss: 0.0784\n",
      "Epoch [42/50], Loss: 0.0827\n",
      "Validation Loss: 0.0788\n",
      "Epoch [43/50], Loss: 0.0818\n",
      "Validation Loss: 0.0788\n",
      "Epoch [44/50], Loss: 0.0822\n",
      "Validation Loss: 0.0789\n",
      "Epoch [45/50], Loss: 0.0818\n",
      "Validation Loss: 0.0789\n",
      "Epoch [46/50], Loss: 0.0819\n",
      "Validation Loss: 0.0787\n",
      "Epoch [47/50], Loss: 0.0820\n",
      "Validation Loss: 0.0787\n",
      "Epoch [48/50], Loss: 0.0821\n",
      "Validation Loss: 0.0788\n",
      "Epoch [49/50], Loss: 0.0821\n",
      "Validation Loss: 0.0787\n",
      "Epoch [50/50], Loss: 0.0817\n",
      "Validation Loss: 0.0797\n",
      "Early stopping triggered.\n",
      "Model trained and saved.\n",
      "Saved model: ./models/mlp_model_trial_5.pth\n",
      "Accuracy: 0.9713\n",
      "Precision: 0.9776\n",
      "Recall: 0.6799\n",
      "F1-score: 0.8020\n",
      "Trial 6/10\n",
      "Using device: cuda\n",
      "Model file does not exist. Training a new model...\n",
      "Epoch [1/50], Loss: 0.1450\n",
      "Validation Loss: 0.1034\n",
      "Epoch [2/50], Loss: 0.1060\n",
      "Validation Loss: 0.0914\n",
      "Epoch [3/50], Loss: 0.0975\n",
      "Validation Loss: 0.0847\n",
      "Epoch [4/50], Loss: 0.0929\n",
      "Validation Loss: 0.0832\n",
      "Epoch [5/50], Loss: 0.0910\n",
      "Validation Loss: 0.0822\n",
      "Epoch [6/50], Loss: 0.0890\n",
      "Validation Loss: 0.0819\n",
      "Epoch [7/50], Loss: 0.0881\n",
      "Validation Loss: 0.0796\n",
      "Epoch [8/50], Loss: 0.0875\n",
      "Validation Loss: 0.0802\n",
      "Epoch [9/50], Loss: 0.0863\n",
      "Validation Loss: 0.0796\n",
      "Epoch [10/50], Loss: 0.0858\n",
      "Validation Loss: 0.0803\n",
      "Epoch [11/50], Loss: 0.0853\n",
      "Validation Loss: 0.0796\n",
      "Epoch [12/50], Loss: 0.0852\n",
      "Validation Loss: 0.0788\n",
      "Epoch [13/50], Loss: 0.0849\n",
      "Validation Loss: 0.0796\n",
      "Epoch [14/50], Loss: 0.0844\n",
      "Validation Loss: 0.0788\n",
      "Epoch [15/50], Loss: 0.0841\n",
      "Validation Loss: 0.0788\n",
      "Epoch [16/50], Loss: 0.0840\n",
      "Validation Loss: 0.0782\n",
      "Epoch [17/50], Loss: 0.0842\n",
      "Validation Loss: 0.0790\n",
      "Epoch [18/50], Loss: 0.0840\n",
      "Validation Loss: 0.0788\n",
      "Epoch [19/50], Loss: 0.0839\n",
      "Validation Loss: 0.0784\n",
      "Epoch [20/50], Loss: 0.0835\n",
      "Validation Loss: 0.0782\n",
      "Epoch [21/50], Loss: 0.0834\n",
      "Validation Loss: 0.0783\n",
      "Epoch [22/50], Loss: 0.0830\n",
      "Validation Loss: 0.0789\n",
      "Epoch [23/50], Loss: 0.0835\n",
      "Validation Loss: 0.0788\n",
      "Epoch [24/50], Loss: 0.0831\n",
      "Validation Loss: 0.0785\n",
      "Epoch [25/50], Loss: 0.0835\n",
      "Validation Loss: 0.0785\n",
      "Epoch [26/50], Loss: 0.0831\n",
      "Validation Loss: 0.0785\n",
      "Epoch [27/50], Loss: 0.0832\n",
      "Validation Loss: 0.0783\n",
      "Epoch [28/50], Loss: 0.0835\n",
      "Validation Loss: 0.0783\n",
      "Epoch [29/50], Loss: 0.0831\n",
      "Validation Loss: 0.0786\n",
      "Epoch [30/50], Loss: 0.0826\n",
      "Validation Loss: 0.0786\n",
      "Early stopping triggered.\n",
      "Model trained and saved.\n",
      "Saved model: ./models/mlp_model_trial_6.pth\n",
      "Accuracy: 0.9718\n",
      "Precision: 0.9988\n",
      "Recall: 0.6713\n",
      "F1-score: 0.8030\n",
      "Trial 7/10\n",
      "Using device: cuda\n",
      "Model file does not exist. Training a new model...\n",
      "Epoch [1/50], Loss: 0.1428\n",
      "Validation Loss: 0.1029\n",
      "Epoch [2/50], Loss: 0.1082\n",
      "Validation Loss: 0.0913\n",
      "Epoch [3/50], Loss: 0.0987\n",
      "Validation Loss: 0.0846\n",
      "Epoch [4/50], Loss: 0.0933\n",
      "Validation Loss: 0.0825\n",
      "Epoch [5/50], Loss: 0.0895\n",
      "Validation Loss: 0.0805\n",
      "Epoch [6/50], Loss: 0.0877\n",
      "Validation Loss: 0.0796\n",
      "Epoch [7/50], Loss: 0.0873\n",
      "Validation Loss: 0.0793\n",
      "Epoch [8/50], Loss: 0.0861\n",
      "Validation Loss: 0.0788\n",
      "Epoch [9/50], Loss: 0.0858\n",
      "Validation Loss: 0.0789\n",
      "Epoch [10/50], Loss: 0.0846\n",
      "Validation Loss: 0.0790\n",
      "Epoch [11/50], Loss: 0.0844\n",
      "Validation Loss: 0.0791\n",
      "Epoch [12/50], Loss: 0.0845\n",
      "Validation Loss: 0.0784\n",
      "Epoch [13/50], Loss: 0.0842\n",
      "Validation Loss: 0.0787\n",
      "Epoch [14/50], Loss: 0.0840\n",
      "Validation Loss: 0.0788\n",
      "Epoch [15/50], Loss: 0.0836\n",
      "Validation Loss: 0.0786\n",
      "Epoch [16/50], Loss: 0.0836\n",
      "Validation Loss: 0.0780\n",
      "Epoch [17/50], Loss: 0.0835\n",
      "Validation Loss: 0.0782\n",
      "Epoch [18/50], Loss: 0.0837\n",
      "Validation Loss: 0.0781\n",
      "Epoch [19/50], Loss: 0.0833\n",
      "Validation Loss: 0.0782\n",
      "Epoch [20/50], Loss: 0.0830\n",
      "Validation Loss: 0.0789\n",
      "Epoch [21/50], Loss: 0.0830\n",
      "Validation Loss: 0.0786\n",
      "Epoch [22/50], Loss: 0.0831\n",
      "Validation Loss: 0.0780\n",
      "Epoch [23/50], Loss: 0.0832\n",
      "Validation Loss: 0.0781\n",
      "Epoch [24/50], Loss: 0.0827\n",
      "Validation Loss: 0.0781\n",
      "Epoch [25/50], Loss: 0.0834\n",
      "Validation Loss: 0.0781\n",
      "Epoch [26/50], Loss: 0.0826\n",
      "Validation Loss: 0.0782\n",
      "Early stopping triggered.\n",
      "Model trained and saved.\n",
      "Saved model: ./models/mlp_model_trial_7.pth\n",
      "Accuracy: 0.9717\n",
      "Precision: 0.9965\n",
      "Recall: 0.6721\n",
      "F1-score: 0.8028\n",
      "Trial 8/10\n",
      "Using device: cuda\n",
      "Model file does not exist. Training a new model...\n",
      "Epoch [1/50], Loss: 0.1397\n",
      "Validation Loss: 0.1027\n",
      "Epoch [2/50], Loss: 0.1065\n",
      "Validation Loss: 0.0926\n",
      "Epoch [3/50], Loss: 0.0980\n",
      "Validation Loss: 0.0862\n",
      "Epoch [4/50], Loss: 0.0924\n",
      "Validation Loss: 0.0824\n",
      "Epoch [5/50], Loss: 0.0901\n",
      "Validation Loss: 0.0806\n",
      "Epoch [6/50], Loss: 0.0877\n",
      "Validation Loss: 0.0801\n",
      "Epoch [7/50], Loss: 0.0871\n",
      "Validation Loss: 0.0799\n",
      "Epoch [8/50], Loss: 0.0857\n",
      "Validation Loss: 0.0795\n",
      "Epoch [9/50], Loss: 0.0849\n",
      "Validation Loss: 0.0793\n",
      "Epoch [10/50], Loss: 0.0852\n",
      "Validation Loss: 0.0788\n",
      "Epoch [11/50], Loss: 0.0847\n",
      "Validation Loss: 0.0787\n",
      "Epoch [12/50], Loss: 0.0843\n",
      "Validation Loss: 0.0789\n",
      "Epoch [13/50], Loss: 0.0841\n",
      "Validation Loss: 0.0790\n",
      "Epoch [14/50], Loss: 0.0840\n",
      "Validation Loss: 0.0794\n",
      "Epoch [15/50], Loss: 0.0839\n",
      "Validation Loss: 0.0790\n",
      "Epoch [16/50], Loss: 0.0841\n",
      "Validation Loss: 0.0790\n",
      "Epoch [17/50], Loss: 0.0835\n",
      "Validation Loss: 0.0788\n",
      "Epoch [18/50], Loss: 0.0835\n",
      "Validation Loss: 0.0786\n",
      "Epoch [19/50], Loss: 0.0832\n",
      "Validation Loss: 0.0791\n",
      "Epoch [20/50], Loss: 0.0832\n",
      "Validation Loss: 0.0784\n",
      "Epoch [21/50], Loss: 0.0834\n",
      "Validation Loss: 0.0787\n",
      "Epoch [22/50], Loss: 0.0832\n",
      "Validation Loss: 0.0792\n",
      "Epoch [23/50], Loss: 0.0830\n",
      "Validation Loss: 0.0786\n",
      "Epoch [24/50], Loss: 0.0831\n",
      "Validation Loss: 0.0786\n",
      "Epoch [25/50], Loss: 0.0828\n",
      "Validation Loss: 0.0785\n",
      "Epoch [26/50], Loss: 0.0826\n",
      "Validation Loss: 0.0797\n",
      "Epoch [27/50], Loss: 0.0825\n",
      "Validation Loss: 0.0786\n",
      "Epoch [28/50], Loss: 0.0831\n",
      "Validation Loss: 0.0785\n",
      "Epoch [29/50], Loss: 0.0827\n",
      "Validation Loss: 0.0784\n",
      "Epoch [30/50], Loss: 0.0830\n",
      "Validation Loss: 0.0787\n",
      "Epoch [31/50], Loss: 0.0826\n",
      "Validation Loss: 0.0789\n",
      "Epoch [32/50], Loss: 0.0829\n",
      "Validation Loss: 0.0781\n",
      "Epoch [33/50], Loss: 0.0823\n",
      "Validation Loss: 0.0787\n",
      "Epoch [34/50], Loss: 0.0829\n",
      "Validation Loss: 0.0794\n",
      "Epoch [35/50], Loss: 0.0823\n",
      "Validation Loss: 0.0788\n",
      "Epoch [36/50], Loss: 0.0821\n",
      "Validation Loss: 0.0785\n",
      "Epoch [37/50], Loss: 0.0830\n",
      "Validation Loss: 0.0787\n",
      "Epoch [38/50], Loss: 0.0823\n",
      "Validation Loss: 0.0786\n",
      "Epoch [39/50], Loss: 0.0823\n",
      "Validation Loss: 0.0783\n",
      "Epoch [40/50], Loss: 0.0829\n",
      "Validation Loss: 0.0789\n",
      "Epoch [41/50], Loss: 0.0829\n",
      "Validation Loss: 0.0794\n",
      "Epoch [42/50], Loss: 0.0821\n",
      "Validation Loss: 0.0785\n",
      "Early stopping triggered.\n",
      "Model trained and saved.\n",
      "Saved model: ./models/mlp_model_trial_8.pth\n",
      "Accuracy: 0.9717\n",
      "Precision: 0.9954\n",
      "Recall: 0.6721\n",
      "F1-score: 0.8024\n",
      "Trial 9/10\n",
      "Using device: cuda\n",
      "Model file does not exist. Training a new model...\n",
      "Epoch [1/50], Loss: 0.1391\n",
      "Validation Loss: 0.1001\n",
      "Epoch [2/50], Loss: 0.1046\n",
      "Validation Loss: 0.0908\n",
      "Epoch [3/50], Loss: 0.0961\n",
      "Validation Loss: 0.0847\n",
      "Epoch [4/50], Loss: 0.0920\n",
      "Validation Loss: 0.0826\n",
      "Epoch [5/50], Loss: 0.0896\n",
      "Validation Loss: 0.0817\n",
      "Epoch [6/50], Loss: 0.0884\n",
      "Validation Loss: 0.0800\n",
      "Epoch [7/50], Loss: 0.0871\n",
      "Validation Loss: 0.0800\n",
      "Epoch [8/50], Loss: 0.0862\n",
      "Validation Loss: 0.0808\n",
      "Epoch [9/50], Loss: 0.0863\n",
      "Validation Loss: 0.0790\n",
      "Epoch [10/50], Loss: 0.0848\n",
      "Validation Loss: 0.0791\n",
      "Epoch [11/50], Loss: 0.0853\n",
      "Validation Loss: 0.0782\n",
      "Epoch [12/50], Loss: 0.0845\n",
      "Validation Loss: 0.0786\n",
      "Epoch [13/50], Loss: 0.0842\n",
      "Validation Loss: 0.0791\n",
      "Epoch [14/50], Loss: 0.0846\n",
      "Validation Loss: 0.0784\n",
      "Epoch [15/50], Loss: 0.0842\n",
      "Validation Loss: 0.0788\n",
      "Epoch [16/50], Loss: 0.0841\n",
      "Validation Loss: 0.0790\n",
      "Epoch [17/50], Loss: 0.0841\n",
      "Validation Loss: 0.0782\n",
      "Epoch [18/50], Loss: 0.0839\n",
      "Validation Loss: 0.0785\n",
      "Epoch [19/50], Loss: 0.0837\n",
      "Validation Loss: 0.0785\n",
      "Epoch [20/50], Loss: 0.0836\n",
      "Validation Loss: 0.0794\n",
      "Epoch [21/50], Loss: 0.0837\n",
      "Validation Loss: 0.0787\n",
      "Early stopping triggered.\n",
      "Model trained and saved.\n",
      "Saved model: ./models/mlp_model_trial_9.pth\n",
      "Accuracy: 0.9717\n",
      "Precision: 0.9931\n",
      "Recall: 0.6737\n",
      "F1-score: 0.8028\n",
      "Trial 10/10\n",
      "Using device: cuda\n",
      "Model file does not exist. Training a new model...\n",
      "Epoch [1/50], Loss: 0.1460\n",
      "Validation Loss: 0.1034\n",
      "Epoch [2/50], Loss: 0.1074\n",
      "Validation Loss: 0.0904\n",
      "Epoch [3/50], Loss: 0.0974\n",
      "Validation Loss: 0.0859\n",
      "Epoch [4/50], Loss: 0.0922\n",
      "Validation Loss: 0.0820\n",
      "Epoch [5/50], Loss: 0.0901\n",
      "Validation Loss: 0.0816\n",
      "Epoch [6/50], Loss: 0.0887\n",
      "Validation Loss: 0.0803\n",
      "Epoch [7/50], Loss: 0.0877\n",
      "Validation Loss: 0.0803\n",
      "Epoch [8/50], Loss: 0.0868\n",
      "Validation Loss: 0.0790\n",
      "Epoch [9/50], Loss: 0.0856\n",
      "Validation Loss: 0.0791\n",
      "Epoch [10/50], Loss: 0.0860\n",
      "Validation Loss: 0.0796\n",
      "Epoch [11/50], Loss: 0.0853\n",
      "Validation Loss: 0.0790\n",
      "Epoch [12/50], Loss: 0.0845\n",
      "Validation Loss: 0.0784\n",
      "Epoch [13/50], Loss: 0.0848\n",
      "Validation Loss: 0.0785\n",
      "Epoch [14/50], Loss: 0.0842\n",
      "Validation Loss: 0.0789\n",
      "Epoch [15/50], Loss: 0.0842\n",
      "Validation Loss: 0.0783\n",
      "Epoch [16/50], Loss: 0.0837\n",
      "Validation Loss: 0.0793\n",
      "Epoch [17/50], Loss: 0.0839\n",
      "Validation Loss: 0.0787\n",
      "Epoch [18/50], Loss: 0.0836\n",
      "Validation Loss: 0.0786\n",
      "Epoch [19/50], Loss: 0.0838\n",
      "Validation Loss: 0.0783\n",
      "Epoch [20/50], Loss: 0.0840\n",
      "Validation Loss: 0.0786\n",
      "Epoch [21/50], Loss: 0.0830\n",
      "Validation Loss: 0.0782\n",
      "Epoch [22/50], Loss: 0.0834\n",
      "Validation Loss: 0.0796\n",
      "Epoch [23/50], Loss: 0.0830\n",
      "Validation Loss: 0.0785\n",
      "Epoch [24/50], Loss: 0.0832\n",
      "Validation Loss: 0.0784\n",
      "Epoch [25/50], Loss: 0.0828\n",
      "Validation Loss: 0.0782\n",
      "Epoch [26/50], Loss: 0.0831\n",
      "Validation Loss: 0.0780\n",
      "Epoch [27/50], Loss: 0.0833\n",
      "Validation Loss: 0.0782\n",
      "Epoch [28/50], Loss: 0.0831\n",
      "Validation Loss: 0.0781\n",
      "Epoch [29/50], Loss: 0.0830\n",
      "Validation Loss: 0.0783\n",
      "Epoch [30/50], Loss: 0.0832\n",
      "Validation Loss: 0.0781\n",
      "Epoch [31/50], Loss: 0.0828\n",
      "Validation Loss: 0.0781\n",
      "Epoch [32/50], Loss: 0.0828\n",
      "Validation Loss: 0.0784\n",
      "Epoch [33/50], Loss: 0.0823\n",
      "Validation Loss: 0.0781\n",
      "Epoch [34/50], Loss: 0.0828\n",
      "Validation Loss: 0.0783\n",
      "Epoch [35/50], Loss: 0.0824\n",
      "Validation Loss: 0.0784\n",
      "Epoch [36/50], Loss: 0.0830\n",
      "Validation Loss: 0.0784\n",
      "Early stopping triggered.\n",
      "Model trained and saved.\n",
      "Saved model: ./models/mlp_model_trial_10.pth\n",
      "Accuracy: 0.9717\n",
      "Precision: 0.9988\n",
      "Recall: 0.6706\n",
      "F1-score: 0.8024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Hyperparameters\n",
    "hidden_sizes = 128\n",
    "learning_rates = 0.001\n",
    "dropouts = 0.3\n",
    "batch_sizes = 64\n",
    "num_epochs = 50\n",
    "patience = 10\n",
    "\n",
    "# Store results for each trial\n",
    "results = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Trial {i+1}/10\")\n",
    "\n",
    "    # Define a unique model file for each trial\n",
    "    model_file = f'./models/mlp_model_trial_{i+1}.pth'\n",
    "\n",
    "    model = train_mlp(train_dataset, val_dataset, batch_sizes, hidden_sizes, learning_rates, dropouts, num_epochs, patience, model_file=model_file)\n",
    "    model.eval()\n",
    "\n",
    "    # Lists to store ground truth labels and predictions\n",
    "    y_true_list = []\n",
    "    y_pred_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch)  # Get predictions (probabilities from sigmoid)\n",
    "            predictions = (outputs > 0.5).float()  # Convert probabilities to binary (0 or 1)\n",
    "\n",
    "            y_true_list.extend(y_batch.cpu().numpy())  # Store ground truth labels\n",
    "            y_pred_list.extend(predictions.cpu().numpy())  # Store predictions\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    y_true = np.array(y_true_list)\n",
    "    y_pred = np.array(y_pred_list)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    # Store results for this trial\n",
    "    results.append({\n",
    "        \"trial\": i+1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    })\n",
    "\n",
    "    # Print results for this trial\n",
    "    print(f\"Saved model: {model_file}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Convert results to a DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.971800</td>\n",
       "      <td>0.993127</td>\n",
       "      <td>0.675234</td>\n",
       "      <td>0.803894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.970400</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.797814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.971400</td>\n",
       "      <td>0.993080</td>\n",
       "      <td>0.670561</td>\n",
       "      <td>0.800558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669782</td>\n",
       "      <td>0.802239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.971267</td>\n",
       "      <td>0.977604</td>\n",
       "      <td>0.679907</td>\n",
       "      <td>0.802021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.971800</td>\n",
       "      <td>0.998841</td>\n",
       "      <td>0.671340</td>\n",
       "      <td>0.802981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>0.996536</td>\n",
       "      <td>0.672118</td>\n",
       "      <td>0.802791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.995386</td>\n",
       "      <td>0.672118</td>\n",
       "      <td>0.802417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.993111</td>\n",
       "      <td>0.673676</td>\n",
       "      <td>0.802784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>0.998840</td>\n",
       "      <td>0.670561</td>\n",
       "      <td>0.802423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial  accuracy  precision    recall  f1_score\n",
       "0      1  0.971800   0.993127  0.675234  0.803894\n",
       "1      2  0.970400   0.960526  0.682243  0.797814\n",
       "2      3  0.971400   0.993080  0.670561  0.800558\n",
       "3      4  0.971733   1.000000  0.669782  0.802239\n",
       "4      5  0.971267   0.977604  0.679907  0.802021\n",
       "5      6  0.971800   0.998841  0.671340  0.802981\n",
       "6      7  0.971733   0.996536  0.672118  0.802791\n",
       "7      8  0.971667   0.995386  0.672118  0.802417\n",
       "8      9  0.971667   0.993111  0.673676  0.802784\n",
       "9     10  0.971733   0.998840  0.670561  0.802423"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.971800</td>\n",
       "      <td>0.993127</td>\n",
       "      <td>0.675234</td>\n",
       "      <td>0.803894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.971800</td>\n",
       "      <td>0.998841</td>\n",
       "      <td>0.671340</td>\n",
       "      <td>0.802981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>0.996536</td>\n",
       "      <td>0.672118</td>\n",
       "      <td>0.802791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.993111</td>\n",
       "      <td>0.673676</td>\n",
       "      <td>0.802784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>0.998840</td>\n",
       "      <td>0.670561</td>\n",
       "      <td>0.802423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.995386</td>\n",
       "      <td>0.672118</td>\n",
       "      <td>0.802417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669782</td>\n",
       "      <td>0.802239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.971267</td>\n",
       "      <td>0.977604</td>\n",
       "      <td>0.679907</td>\n",
       "      <td>0.802021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.971400</td>\n",
       "      <td>0.993080</td>\n",
       "      <td>0.670561</td>\n",
       "      <td>0.800558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.970400</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.682243</td>\n",
       "      <td>0.797814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial  accuracy  precision    recall  f1_score\n",
       "0      1  0.971800   0.993127  0.675234  0.803894\n",
       "5      6  0.971800   0.998841  0.671340  0.802981\n",
       "6      7  0.971733   0.996536  0.672118  0.802791\n",
       "8      9  0.971667   0.993111  0.673676  0.802784\n",
       "9     10  0.971733   0.998840  0.670561  0.802423\n",
       "7      8  0.971667   0.995386  0.672118  0.802417\n",
       "3      4  0.971733   1.000000  0.669782  0.802239\n",
       "4      5  0.971267   0.977604  0.679907  0.802021\n",
       "2      3  0.971400   0.993080  0.670561  0.800558\n",
       "1      2  0.970400   0.960526  0.682243  0.797814"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by f1 score\n",
    "temp_df = results_df.sort_values(by='f1_score', ascending=False)\n",
    "temp_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

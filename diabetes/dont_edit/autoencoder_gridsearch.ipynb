{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FPSKf-hlkubi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.base import BaseEstimator, RegressorMixin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMe1WF9bkubk",
        "outputId": "fef31e34-071e-4917-df8d-3c751c837115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEsVDxBQkubl",
        "outputId": "f2cdf89c-bebd-4f4f-ce5d-193029c8e5a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history',\n",
            "       'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Read the CSV file\n",
        "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30pQO1uHkubm",
        "outputId": "e565bf0f-a28a-460e-a22d-0a7fe24aab42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    age  hypertension  heart_disease    bmi  HbA1c_level  blood_glucose_level  \\\n",
            "0  80.0             0              1  25.19          6.6                  140   \n",
            "1  54.0             0              0  27.32          6.6                   80   \n",
            "2  28.0             0              0  27.32          5.7                  158   \n",
            "3  36.0             0              0  23.45          5.0                  155   \n",
            "4  76.0             1              1  20.14          4.8                  155   \n",
            "\n",
            "   diabetes  gender_Male  gender_Other  smoking_history_current  \\\n",
            "0         0        False         False                    False   \n",
            "1         0        False         False                    False   \n",
            "2         0         True         False                    False   \n",
            "3         0        False         False                     True   \n",
            "4         0         True         False                     True   \n",
            "\n",
            "   smoking_history_ever  smoking_history_former  smoking_history_never  \\\n",
            "0                 False                   False                   True   \n",
            "1                 False                   False                  False   \n",
            "2                 False                   False                   True   \n",
            "3                 False                   False                  False   \n",
            "4                 False                   False                  False   \n",
            "\n",
            "   smoking_history_not current  \n",
            "0                        False  \n",
            "1                        False  \n",
            "2                        False  \n",
            "3                        False  \n",
            "4                        False  \n"
          ]
        }
      ],
      "source": [
        "df_encoded = pd.get_dummies(df, columns=['gender', 'smoking_history'], drop_first=True)\n",
        "print(df_encoded.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6QxqRmfvkubn"
      },
      "outputs": [],
      "source": [
        "testDF = df_encoded\n",
        "testDF = testDF.sample(frac=1).reset_index(drop=True)\n",
        "x_unscaled = testDF.drop(['diabetes'], axis=1)\n",
        "y = testDF['diabetes']\n",
        "\n",
        "# Normalize the data\n",
        "numerical_columns = x_unscaled.select_dtypes(include=np.number).columns\n",
        "# numerical_columns = ['age','bmi','HbA1c_level','blood_glucose_level']\n",
        "# boolean_columns = list(set(x_unscaled.columns) - set(numerical_columns))\n",
        "boolean_columns = x_unscaled.select_dtypes(include=bool).columns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "temp = pd.DataFrame(scaler.fit_transform(x_unscaled[numerical_columns]), columns=numerical_columns)\n",
        "x_scaled = pd.concat([temp, x_unscaled[boolean_columns]], axis=1)\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(x_scaled, y, test_size=0.3, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "boolean_cols = x_train.select_dtypes(include=bool).columns\n",
        "\n",
        "x_train[boolean_cols] = x_train[boolean_cols].astype(int)\n",
        "x_val[boolean_cols] = x_val[boolean_cols].astype(int)\n",
        "x_test[boolean_cols] = x_test[boolean_cols].astype(int)"
      ],
      "metadata": {
        "id": "M7n2T800puR0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pZ3Y7k0Pkubo"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.base import BaseEstimator, RegressorMixin\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# # Check if CUDA is available and print the device being used\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(f\"Using device: {device}\")\n",
        "\n",
        "# # Define the Encoder model with reduced complexity and dropout\n",
        "# class Encoder(nn.Module):\n",
        "#     def __init__(self, input_dim, encoding_dim):\n",
        "#         super(Encoder, self).__init__()\n",
        "#         self.encoder = nn.Sequential(\n",
        "#             nn.Linear(input_dim, 128),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.2),\n",
        "#             nn.Linear(128, 64),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.2),\n",
        "#             nn.Linear(64, encoding_dim)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.encoder(x)\n",
        "\n",
        "# # Define the Decoder model with reduced complexity and dropout\n",
        "# class Decoder(nn.Module):\n",
        "#     def __init__(self, encoding_dim, input_dim):\n",
        "#         super(Decoder, self).__init__()\n",
        "#         self.decoder = nn.Sequential(\n",
        "#             nn.Linear(encoding_dim, 64),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.2),\n",
        "#             nn.Linear(64, 128),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.2),\n",
        "#             nn.Linear(128, input_dim)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.decoder(x)\n",
        "\n",
        "\n",
        "# # model without dropout\n",
        "# # class Encoder(nn.Module):\n",
        "# #     def __init__(self, input_dim, encoding_dim):\n",
        "# #         super(Encoder, self).__init__()\n",
        "# #         self.encoder = nn.Sequential(\n",
        "# #             nn.Linear(input_dim, 128),\n",
        "# #             nn.ReLU(),\n",
        "# #             nn.Linear(128, 64),\n",
        "# #             nn.ReLU(),\n",
        "# #             nn.Linear(64, encoding_dim)\n",
        "# #         )\n",
        "\n",
        "# #     def forward(self, x):\n",
        "# #         return self.encoder(x)\n",
        "\n",
        "# # # Decoder without dropout\n",
        "# # class Decoder(nn.Module):\n",
        "# #     def __init__(self, encoding_dim, input_dim):\n",
        "# #         super(Decoder, self).__init__()\n",
        "# #         self.decoder = nn.Sequential(\n",
        "# #             nn.Linear(encoding_dim, 64),\n",
        "# #             nn.ReLU(),\n",
        "# #             nn.Linear(64, 128),\n",
        "# #             nn.ReLU(),\n",
        "# #             nn.Linear(128, input_dim)\n",
        "# #         )\n",
        "\n",
        "# #     def forward(self, x):\n",
        "# #         return self.decoder(x)\n",
        "\n",
        "\n",
        "\n",
        "# # Load and preprocess data\n",
        "# # Assuming x_train, x_test, y_train, and y_test are already defined and normalized\n",
        "# x_train_scaled = x_train.values if isinstance(x_train, pd.DataFrame) else x_train\n",
        "# x_val_scaled = x_val.values if isinstance(x_val, pd.DataFrame) else x_val\n",
        "# x_test_scaled = x_test.values if isinstance(x_test, pd.DataFrame) else x_test\n",
        "\n",
        "# # Define input dimensions\n",
        "# input_dim = x_train_scaled.shape[1]\n",
        "\n",
        "# # Model file paths\n",
        "# encoder_model_file = './models/encoder2.pth'\n",
        "# decoder_model_file = './models/decoder2.pth'\n",
        "\n",
        "# # Hyperparameters\n",
        "# encoding_dim = 8\n",
        "# learning_rate = 0.001\n",
        "# epochs = 1000\n",
        "# batch_size = 64\n",
        "# patience = 10\n",
        "\n",
        "# # Check if the model files exist\n",
        "# if os.path.exists(encoder_model_file) and os.path.exists(decoder_model_file):\n",
        "#     print(\"Model files exist. Loading the models...\")\n",
        "#     encoder = Encoder(input_dim, encoding_dim).to(device)\n",
        "#     decoder = Decoder(encoding_dim, input_dim).to(device)\n",
        "#     encoder.load_state_dict(torch.load(encoder_model_file))\n",
        "#     decoder.load_state_dict(torch.load(decoder_model_file))\n",
        "# else:\n",
        "#     print(\"Model files do not exist. Training new models...\")\n",
        "\n",
        "#     # Initialize the encoder and decoder models\n",
        "#     encoder = Encoder(input_dim, encoding_dim).to(device)\n",
        "#     decoder = Decoder(encoding_dim, input_dim).to(device)\n",
        "#     optimizer_encoder = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "#     optimizer_decoder = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "#     criterion = nn.MSELoss()\n",
        "\n",
        "#     # Track training loss\n",
        "#     encoder_losses = []\n",
        "#     decoder_losses = []\n",
        "\n",
        "#     # Train the Encoder separately\n",
        "#     encoder.train()\n",
        "#     best_val_loss = float('inf')\n",
        "#     patience_counter = 0\n",
        "#     for epoch in range(epochs):\n",
        "#         epoch_loss = 0\n",
        "#         dataloader = DataLoader(TensorDataset(torch.tensor(x_train_scaled, dtype=torch.float32).to(device), torch.tensor(x_train_scaled, dtype=torch.float32).to(device)), batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "#         for i, (batch_X, _) in enumerate(dataloader):\n",
        "#             batch_X = batch_X.to(device)\n",
        "#             optimizer_encoder.zero_grad()\n",
        "#             encoded = encoder(batch_X)\n",
        "#             # Pass the encoded output through the decoder\n",
        "#             decoded = decoder(encoded)\n",
        "#             # Calculate loss between decoder output and original input\n",
        "#             loss = criterion(decoded, batch_X)\n",
        "#             loss.backward()\n",
        "\n",
        "#             optimizer_encoder.step()\n",
        "#             optimizer_encoder.zero_grad()\n",
        "\n",
        "#             epoch_loss += loss.item()\n",
        "#         avg_loss = epoch_loss / len(dataloader)\n",
        "#         encoder_losses.append(avg_loss)\n",
        "#         print(f\"Epoch [{epoch+1}/{epochs}], Encoder Loss: {avg_loss:.4f}\")\n",
        "\n",
        "#         # Validation loss\n",
        "#         encoder.eval()\n",
        "#         decoder.eval()\n",
        "#         with torch.no_grad():\n",
        "#             val_encoded = encoder(torch.tensor(x_val_scaled, dtype=torch.float32).to(device))\n",
        "#             val_decoded = decoder(val_encoded)\n",
        "#             val_loss = criterion(val_decoded, torch.tensor(x_val_scaled, dtype=torch.float32).to(device)).item()\n",
        "#         print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "#         # Early stopping\n",
        "#         if val_loss < best_val_loss:\n",
        "#             best_val_loss = val_loss\n",
        "#             patience_counter = 0\n",
        "#         else:\n",
        "#             patience_counter += 1\n",
        "#             if patience_counter >= patience:\n",
        "#                 print(\"Early stopping triggered.\")\n",
        "#                 break\n",
        "\n",
        "#     # Train the Decoder separately\n",
        "#     encoded_train = encoder(torch.tensor(x_train_scaled, dtype=torch.float32).to(device)).detach()\n",
        "#     decoder.train()\n",
        "#     best_val_loss = float('inf')\n",
        "#     patience_counter = 0\n",
        "#     for epoch in range(epochs):\n",
        "#         epoch_loss = 0\n",
        "#         dataloader = DataLoader(TensorDataset(encoded_train, torch.tensor(x_train_scaled, dtype=torch.float32).to(device)), batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "#         for i, (batch_X, batch_y) in enumerate(dataloader):\n",
        "#             batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "#             optimizer_decoder.zero_grad()\n",
        "#             outputs = decoder(batch_X)\n",
        "#             # Calculate loss between decoder output and original input\n",
        "#             loss = criterion(outputs, batch_y)\n",
        "#             loss.backward()\n",
        "\n",
        "#             optimizer_decoder.step()\n",
        "#             optimizer_decoder.zero_grad()\n",
        "\n",
        "#             epoch_loss += loss.item()\n",
        "#         avg_loss = epoch_loss / len(dataloader)\n",
        "#         decoder_losses.append(avg_loss)\n",
        "#         print(f\"Epoch [{epoch+1}/{epochs}], Decoder Loss: {avg_loss:.4f}\")\n",
        "\n",
        "#         # Validation loss\n",
        "#         decoder.eval()\n",
        "#         with torch.no_grad():\n",
        "#             val_outputs = decoder(encoded_train)\n",
        "#             val_loss = criterion(val_outputs, torch.tensor(x_train_scaled, dtype=torch.float32).to(device)).item()\n",
        "#         print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "#         # Early stopping\n",
        "#         if val_loss < best_val_loss:\n",
        "#             best_val_loss = val_loss\n",
        "#             patience_counter = 0\n",
        "#         else:\n",
        "#             patience_counter += 1\n",
        "#             if patience_counter >= patience:\n",
        "#                 print(\"Early stopping triggered.\")\n",
        "#                 break\n",
        "\n",
        "#     # Save the trained models\n",
        "#     os.makedirs('./models', exist_ok=True)\n",
        "#     torch.save(encoder.state_dict(), encoder_model_file)\n",
        "#     torch.save(decoder.state_dict(), decoder_model_file)\n",
        "#     print(\"Models trained and saved.\")\n",
        "\n",
        "# # Combine Encoder and Decoder to form the Autoencoder\n",
        "# class Autoencoder(nn.Module):\n",
        "#     def __init__(self, encoder, decoder):\n",
        "#         super(Autoencoder, self).__init__()\n",
        "#         self.encoder = encoder\n",
        "#         self.decoder = decoder\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         encoded = self.encoder(x)\n",
        "#         decoded = self.decoder(encoded)\n",
        "#         return decoded\n",
        "\n",
        "# autoencoder = Autoencoder(encoder, decoder).to(device)\n",
        "# autoencoder.eval()\n",
        "\n",
        "# # Calculate reconstruction error on the test set\n",
        "# with torch.no_grad():\n",
        "#     reconstructed_test = autoencoder(torch.tensor(x_test_scaled, dtype=torch.float32).to(device)).cpu().numpy()\n",
        "\n",
        "# # Calculate Reconstruction Error Percentage\n",
        "# reconstruction_error_percentage = (\n",
        "#     np.mean(np.abs(x_test_scaled - reconstructed_test) / (np.abs(x_test_scaled) + 1e-8), axis=1) * 100\n",
        "# )  # Prevent division by zero using 1e-8\n",
        "\n",
        "# reconstruction_error_percentage_mean = np.mean(reconstruction_error_percentage)\n",
        "\n",
        "# def calculate_error_for_index(index):\n",
        "#     return np.mean(np.abs(x_test_scaled[index] - reconstructed_test[index]) / (np.abs(x_test_scaled[index]) + 1e-8)) * 100\n",
        "\n",
        "# greater_than_mean = 0\n",
        "# less_than_20 = 0\n",
        "# for i in range(x_test_scaled.shape[0]):\n",
        "#     if (calculate_error_for_index(i) > reconstruction_error_percentage_mean):\n",
        "#         greater_than_mean += 1\n",
        "#     elif (calculate_error_for_index(i) < 25):\n",
        "#         less_than_20 += 1\n",
        "\n",
        "# print(\"Number of outliers: \", greater_than_mean)\n",
        "# print(\"Number of inliers: \", less_than_20)\n",
        "# print(\"Error percentage mean: \", reconstruction_error_percentage_mean)\n",
        "\n",
        "\n",
        "# # calcualting the mse and mae\n",
        "# mse = np.mean((x_test_scaled - reconstructed_test) ** 2)\n",
        "# mae = np.mean(np.abs(x_test_scaled - reconstructed_test))\n",
        "\n",
        "# print(\"Mean Squared Error: \", mse)\n",
        "# print(\"Mean Absolute Error: \", mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVi6jc2Fkubp",
        "outputId": "02adc44b-67a6-436d-ce6c-0e1b8e488982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_size, encoding_dim, dropout):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size // 2, encoding_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoding_dim, hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size // 2, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "def train_autoencoder(x_train, x_val, learning_rate=0.001, hidden_size=128, batch_size=64, dropout=0.2, encoding_dim=8, epochs=200, patience=10, model_path='./models/autoencoder.pth'):\n",
        "\n",
        "    x_train_scaled = x_train.values if isinstance(x_train, pd.DataFrame) else x_train\n",
        "    x_val_scaled = x_val.values if isinstance(x_val, pd.DataFrame) else x_val\n",
        "    input_dim = x_train_scaled.shape[1]\n",
        "\n",
        "    autoencoder = Autoencoder(input_dim, hidden_size, encoding_dim, dropout).to(device)\n",
        "    optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    dataloader = DataLoader(TensorDataset(torch.tensor(x_train_scaled, dtype=torch.float32).to(device)), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        autoencoder.train()\n",
        "        for batch_X, in dataloader:\n",
        "            batch_X = batch_X.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = autoencoder(batch_X)\n",
        "            loss = criterion(outputs, batch_X)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "\n",
        "        autoencoder.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = autoencoder(torch.tensor(x_val_scaled, dtype=torch.float32).to(device))\n",
        "            val_loss = criterion(val_outputs, torch.tensor(x_val_scaled, dtype=torch.float32).to(device)).item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            # torch.save(autoencoder.state_dict(), model_path)\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    print(\"Training complete. Best model saved.\")\n",
        "    return autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZNJ8b_zHkubq"
      },
      "outputs": [],
      "source": [
        "# # Hyperparaemters\n",
        "# learning_rate = 0.001\n",
        "# hidden_size = 128\n",
        "# batch_size = 64\n",
        "# dropout = 0.2\n",
        "# encoding_dim = 8\n",
        "\n",
        "# model_path = './models/autoencoder.pth'\n",
        "# autoencoder_model = train_autoencoder(x_train, x_val, learning_rate=learning_rate, hidden_size=hidden_size, batch_size=batch_size, dropout=dropout, encoding_dim=encoding_dim, epochs=200, patience=10, model_path=model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s2QAfV92kubr"
      },
      "outputs": [],
      "source": [
        "# x_train_scaled = x_train.values if isinstance(x_train, pd.DataFrame) else x_train\n",
        "# x_val_scaled = x_val.values if isinstance(x_val, pd.DataFrame) else x_val\n",
        "# x_test_scaled = x_test.values if isinstance(x_test, pd.DataFrame) else x_test\n",
        "\n",
        "\n",
        "# # Calculate reconstruction error on the test set\n",
        "# with torch.no_grad():\n",
        "#     reconstructed_test = autoencoder_model(torch.tensor(x_test_scaled, dtype=torch.float32).to(device)).cpu().numpy()\n",
        "\n",
        "# # Calculate Reconstruction Error Percentage\n",
        "# reconstruction_error_percentage = (\n",
        "#     np.mean(np.abs(x_test_scaled - reconstructed_test) / (np.abs(x_test_scaled) + 1e-8), axis=1) * 100\n",
        "# )  # Prevent division by zero using 1e-8\n",
        "\n",
        "# reconstruction_error_percentage_mean = np.mean(reconstruction_error_percentage)\n",
        "\n",
        "# print(\"Error percentage mean: \", reconstruction_error_percentage_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK8ZpDlgkubs"
      },
      "source": [
        "\n",
        "\n",
        "<span style=\"color: yellow; font-size: 36px;\">Using the error percentage might not be the best evaluation metric, as some features in the training data have very small values, and a slight absolute error can result in a high error percentage</span>\n",
        "\n",
        "<span style=\"color: yellow; font-size: 36px;\">Instead, it is better to focus on other metrics such as MSE and MAE</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gb7XeZtFkubt"
      },
      "outputs": [],
      "source": [
        "# mae_per_column = np.abs(x_test_scaled - reconstructed_test)\n",
        "# mae_per_row = np.mean(mae_per_column, axis=1)\n",
        "# print(f\"Average MAE = {np.mean(mae_per_row)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "d2tMk9QAkubu"
      },
      "outputs": [],
      "source": [
        "# # scatter plot mae\n",
        "# plt.scatter(range(len(mae_per_row)), mae_per_row)\n",
        "# plt.xlabel('Index')\n",
        "# plt.ylabel('Mean Absolute Error')\n",
        "# plt.title('Mean Absolute Error per Row')\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ovAdJt1Okubv"
      },
      "outputs": [],
      "source": [
        "# from sklearn.manifold import TSNE\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Random sample 1000 points from the test set\n",
        "# np.random.seed(42)\n",
        "# indices = np.random.choice(x_test_scaled.shape[0], 1000, replace=False)\n",
        "# x_test_sample = x_test_scaled[indices]\n",
        "# reconstructed_test_sample = reconstructed_test[indices]\n",
        "\n",
        "# # Combine original and reconstructed vectors\n",
        "# X_combined = np.vstack([x_test_sample, reconstructed_test_sample])\n",
        "# labels = [\"Original\"] * len(x_test_sample) + [\"Reconstructed\"] * len(reconstructed_test_sample)\n",
        "\n",
        "# # Apply t-SNE\n",
        "# tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "# X_tsne = tsne.fit_transform(X_combined)\n",
        "\n",
        "# # Plot\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# plt.scatter(X_tsne[:len(x_test_sample), 0], X_tsne[:len(x_test_sample), 1], label=\"Original\", alpha=0.5)\n",
        "# plt.scatter(X_tsne[len(x_test_sample):, 0], X_tsne[len(x_test_sample):, 1], label=\"Reconstructed\", alpha=0.5)\n",
        "# plt.legend()\n",
        "# plt.title(\"t-SNE Visualization of Original vs. Reconstructed Data\")\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "URLm_WZfkubv"
      },
      "outputs": [],
      "source": [
        "# from sklearn.decomposition import PCA\n",
        "\n",
        "# X_combined = np.vstack([x_test_sample, reconstructed_test_sample])\n",
        "\n",
        "# # Apply PCA\n",
        "# pca = PCA(n_components=2)\n",
        "# X_pca = pca.fit_transform(X_combined)\n",
        "\n",
        "# # Plot\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# plt.scatter(X_pca[:len(x_test_sample), 0], X_pca[:len(x_test_sample), 1], label=\"Original\", alpha=0.5)\n",
        "# plt.scatter(X_pca[len(x_test_sample):, 0], X_pca[len(x_test_sample):, 1], label=\"Reconstructed\", alpha=0.5)\n",
        "# plt.legend()\n",
        "# plt.title(\"PCA Projection of Original vs. Reconstructed Data\")\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX8ZT7zlkubv",
        "outputId": "297aef80-0d0e-4708-d2bc-aa8d82ebb2a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch [41/200], Loss: 0.0894, Val Loss: 0.0428\n",
            "Epoch [42/200], Loss: 0.0901, Val Loss: 0.0432\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1877, Val Loss: 0.0887\n",
            "Epoch [2/200], Loss: 0.1361, Val Loss: 0.0789\n",
            "Epoch [3/200], Loss: 0.1305, Val Loss: 0.0820\n",
            "Epoch [4/200], Loss: 0.1274, Val Loss: 0.0793\n",
            "Epoch [5/200], Loss: 0.1249, Val Loss: 0.0769\n",
            "Epoch [6/200], Loss: 0.1233, Val Loss: 0.0835\n",
            "Epoch [7/200], Loss: 0.1218, Val Loss: 0.0780\n",
            "Epoch [8/200], Loss: 0.1202, Val Loss: 0.0795\n",
            "Epoch [9/200], Loss: 0.1197, Val Loss: 0.0758\n",
            "Epoch [10/200], Loss: 0.1177, Val Loss: 0.0756\n",
            "Epoch [11/200], Loss: 0.1169, Val Loss: 0.0749\n",
            "Epoch [12/200], Loss: 0.1159, Val Loss: 0.0744\n",
            "Epoch [13/200], Loss: 0.1139, Val Loss: 0.0766\n",
            "Epoch [14/200], Loss: 0.1126, Val Loss: 0.0775\n",
            "Epoch [15/200], Loss: 0.1127, Val Loss: 0.0778\n",
            "Epoch [16/200], Loss: 0.1113, Val Loss: 0.0758\n",
            "Epoch [17/200], Loss: 0.1110, Val Loss: 0.0774\n",
            "Epoch [18/200], Loss: 0.1102, Val Loss: 0.0767\n",
            "Epoch [19/200], Loss: 0.1093, Val Loss: 0.0698\n",
            "Epoch [20/200], Loss: 0.1082, Val Loss: 0.0701\n",
            "Epoch [21/200], Loss: 0.1080, Val Loss: 0.0669\n",
            "Epoch [22/200], Loss: 0.1062, Val Loss: 0.0656\n",
            "Epoch [23/200], Loss: 0.1062, Val Loss: 0.0680\n",
            "Epoch [24/200], Loss: 0.1056, Val Loss: 0.0653\n",
            "Epoch [25/200], Loss: 0.1051, Val Loss: 0.0652\n",
            "Epoch [26/200], Loss: 0.1034, Val Loss: 0.0630\n",
            "Epoch [27/200], Loss: 0.1034, Val Loss: 0.0630\n",
            "Epoch [28/200], Loss: 0.1033, Val Loss: 0.0653\n",
            "Epoch [29/200], Loss: 0.1028, Val Loss: 0.0638\n",
            "Epoch [30/200], Loss: 0.1021, Val Loss: 0.0620\n",
            "Epoch [31/200], Loss: 0.1020, Val Loss: 0.0615\n",
            "Epoch [32/200], Loss: 0.1021, Val Loss: 0.0606\n",
            "Epoch [33/200], Loss: 0.0999, Val Loss: 0.0562\n",
            "Epoch [34/200], Loss: 0.0990, Val Loss: 0.0608\n",
            "Epoch [35/200], Loss: 0.0985, Val Loss: 0.0608\n",
            "Epoch [36/200], Loss: 0.0976, Val Loss: 0.0555\n",
            "Epoch [37/200], Loss: 0.0982, Val Loss: 0.0552\n",
            "Epoch [38/200], Loss: 0.0980, Val Loss: 0.0573\n",
            "Epoch [39/200], Loss: 0.0981, Val Loss: 0.0578\n",
            "Epoch [40/200], Loss: 0.0970, Val Loss: 0.0562\n",
            "Epoch [41/200], Loss: 0.0991, Val Loss: 0.0558\n",
            "Epoch [42/200], Loss: 0.0977, Val Loss: 0.0553\n",
            "Epoch [43/200], Loss: 0.0967, Val Loss: 0.0554\n",
            "Epoch [44/200], Loss: 0.0973, Val Loss: 0.0578\n",
            "Epoch [45/200], Loss: 0.0960, Val Loss: 0.0547\n",
            "Epoch [46/200], Loss: 0.0964, Val Loss: 0.0556\n",
            "Epoch [47/200], Loss: 0.0969, Val Loss: 0.0556\n",
            "Epoch [48/200], Loss: 0.0973, Val Loss: 0.0588\n",
            "Epoch [49/200], Loss: 0.0972, Val Loss: 0.0557\n",
            "Epoch [50/200], Loss: 0.0976, Val Loss: 0.0558\n",
            "Epoch [51/200], Loss: 0.0981, Val Loss: 0.0561\n",
            "Epoch [52/200], Loss: 0.0982, Val Loss: 0.0553\n",
            "Epoch [53/200], Loss: 0.0983, Val Loss: 0.0577\n",
            "Epoch [54/200], Loss: 0.0974, Val Loss: 0.0591\n",
            "Epoch [55/200], Loss: 0.0968, Val Loss: 0.0570\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1749, Val Loss: 0.0818\n",
            "Epoch [2/200], Loss: 0.1303, Val Loss: 0.0772\n",
            "Epoch [3/200], Loss: 0.1252, Val Loss: 0.0730\n",
            "Epoch [4/200], Loss: 0.1227, Val Loss: 0.0674\n",
            "Epoch [5/200], Loss: 0.1181, Val Loss: 0.0635\n",
            "Epoch [6/200], Loss: 0.1162, Val Loss: 0.0641\n",
            "Epoch [7/200], Loss: 0.1152, Val Loss: 0.0621\n",
            "Epoch [8/200], Loss: 0.1136, Val Loss: 0.0613\n",
            "Epoch [9/200], Loss: 0.1128, Val Loss: 0.0605\n",
            "Epoch [10/200], Loss: 0.1116, Val Loss: 0.0622\n",
            "Epoch [11/200], Loss: 0.1107, Val Loss: 0.0576\n",
            "Epoch [12/200], Loss: 0.1097, Val Loss: 0.0575\n",
            "Epoch [13/200], Loss: 0.1086, Val Loss: 0.0582\n",
            "Epoch [14/200], Loss: 0.1077, Val Loss: 0.0538\n",
            "Epoch [15/200], Loss: 0.1073, Val Loss: 0.0550\n",
            "Epoch [16/200], Loss: 0.1057, Val Loss: 0.0563\n",
            "Epoch [17/200], Loss: 0.1046, Val Loss: 0.0555\n",
            "Epoch [18/200], Loss: 0.1035, Val Loss: 0.0535\n",
            "Epoch [19/200], Loss: 0.1026, Val Loss: 0.0549\n",
            "Epoch [20/200], Loss: 0.1015, Val Loss: 0.0539\n",
            "Epoch [21/200], Loss: 0.1013, Val Loss: 0.0510\n",
            "Epoch [22/200], Loss: 0.1012, Val Loss: 0.0536\n",
            "Epoch [23/200], Loss: 0.1010, Val Loss: 0.0537\n",
            "Epoch [24/200], Loss: 0.1001, Val Loss: 0.0504\n",
            "Epoch [25/200], Loss: 0.0992, Val Loss: 0.0546\n",
            "Epoch [26/200], Loss: 0.0986, Val Loss: 0.0531\n",
            "Epoch [27/200], Loss: 0.0981, Val Loss: 0.0479\n",
            "Epoch [28/200], Loss: 0.0981, Val Loss: 0.0522\n",
            "Epoch [29/200], Loss: 0.0977, Val Loss: 0.0522\n",
            "Epoch [30/200], Loss: 0.0975, Val Loss: 0.0530\n",
            "Epoch [31/200], Loss: 0.0974, Val Loss: 0.0488\n",
            "Epoch [32/200], Loss: 0.0971, Val Loss: 0.0506\n",
            "Epoch [33/200], Loss: 0.0962, Val Loss: 0.0471\n",
            "Epoch [34/200], Loss: 0.0962, Val Loss: 0.0519\n",
            "Epoch [35/200], Loss: 0.0962, Val Loss: 0.0524\n",
            "Epoch [36/200], Loss: 0.0947, Val Loss: 0.0503\n",
            "Epoch [37/200], Loss: 0.0945, Val Loss: 0.0514\n",
            "Epoch [38/200], Loss: 0.0946, Val Loss: 0.0468\n",
            "Epoch [39/200], Loss: 0.0939, Val Loss: 0.0452\n",
            "Epoch [40/200], Loss: 0.0941, Val Loss: 0.0484\n",
            "Epoch [41/200], Loss: 0.0929, Val Loss: 0.0473\n",
            "Epoch [42/200], Loss: 0.0924, Val Loss: 0.0470\n",
            "Epoch [43/200], Loss: 0.0932, Val Loss: 0.0470\n",
            "Epoch [44/200], Loss: 0.0916, Val Loss: 0.0471\n",
            "Epoch [45/200], Loss: 0.0918, Val Loss: 0.0465\n",
            "Epoch [46/200], Loss: 0.0904, Val Loss: 0.0526\n",
            "Epoch [47/200], Loss: 0.0912, Val Loss: 0.0439\n",
            "Epoch [48/200], Loss: 0.0907, Val Loss: 0.0456\n",
            "Epoch [49/200], Loss: 0.0904, Val Loss: 0.0468\n",
            "Epoch [50/200], Loss: 0.0901, Val Loss: 0.0508\n",
            "Epoch [51/200], Loss: 0.0901, Val Loss: 0.0488\n",
            "Epoch [52/200], Loss: 0.0903, Val Loss: 0.0486\n",
            "Epoch [53/200], Loss: 0.0887, Val Loss: 0.0448\n",
            "Epoch [54/200], Loss: 0.0898, Val Loss: 0.0484\n",
            "Epoch [55/200], Loss: 0.0885, Val Loss: 0.0451\n",
            "Epoch [56/200], Loss: 0.0884, Val Loss: 0.0485\n",
            "Epoch [57/200], Loss: 0.0894, Val Loss: 0.0445\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1801, Val Loss: 0.0865\n",
            "Epoch [2/200], Loss: 0.1355, Val Loss: 0.0870\n",
            "Epoch [3/200], Loss: 0.1286, Val Loss: 0.0756\n",
            "Epoch [4/200], Loss: 0.1256, Val Loss: 0.0758\n",
            "Epoch [5/200], Loss: 0.1240, Val Loss: 0.0731\n",
            "Epoch [6/200], Loss: 0.1223, Val Loss: 0.0744\n",
            "Epoch [7/200], Loss: 0.1213, Val Loss: 0.0749\n",
            "Epoch [8/200], Loss: 0.1203, Val Loss: 0.0733\n",
            "Epoch [9/200], Loss: 0.1191, Val Loss: 0.0732\n",
            "Epoch [10/200], Loss: 0.1162, Val Loss: 0.0675\n",
            "Epoch [11/200], Loss: 0.1153, Val Loss: 0.0665\n",
            "Epoch [12/200], Loss: 0.1129, Val Loss: 0.0633\n",
            "Epoch [13/200], Loss: 0.1108, Val Loss: 0.0586\n",
            "Epoch [14/200], Loss: 0.1101, Val Loss: 0.0583\n",
            "Epoch [15/200], Loss: 0.1082, Val Loss: 0.0604\n",
            "Epoch [16/200], Loss: 0.1061, Val Loss: 0.0536\n",
            "Epoch [17/200], Loss: 0.1051, Val Loss: 0.0564\n",
            "Epoch [18/200], Loss: 0.1024, Val Loss: 0.0515\n",
            "Epoch [19/200], Loss: 0.1004, Val Loss: 0.0546\n",
            "Epoch [20/200], Loss: 0.0979, Val Loss: 0.0511\n",
            "Epoch [21/200], Loss: 0.0972, Val Loss: 0.0534\n",
            "Epoch [22/200], Loss: 0.0961, Val Loss: 0.0530\n",
            "Epoch [23/200], Loss: 0.0952, Val Loss: 0.0575\n",
            "Epoch [24/200], Loss: 0.0942, Val Loss: 0.0565\n",
            "Epoch [25/200], Loss: 0.0939, Val Loss: 0.0569\n",
            "Epoch [26/200], Loss: 0.0925, Val Loss: 0.0539\n",
            "Epoch [27/200], Loss: 0.0915, Val Loss: 0.0496\n",
            "Epoch [28/200], Loss: 0.0909, Val Loss: 0.0513\n",
            "Epoch [29/200], Loss: 0.0905, Val Loss: 0.0577\n",
            "Epoch [30/200], Loss: 0.0905, Val Loss: 0.0539\n",
            "Epoch [31/200], Loss: 0.0890, Val Loss: 0.0556\n",
            "Epoch [32/200], Loss: 0.0895, Val Loss: 0.0517\n",
            "Epoch [33/200], Loss: 0.0892, Val Loss: 0.0535\n",
            "Epoch [34/200], Loss: 0.0892, Val Loss: 0.0556\n",
            "Epoch [35/200], Loss: 0.0887, Val Loss: 0.0537\n",
            "Epoch [36/200], Loss: 0.0890, Val Loss: 0.0545\n",
            "Epoch [37/200], Loss: 0.0889, Val Loss: 0.0522\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=32, BS=16, Dropout=0.1, EncDim=8 -> MAE=0.1306, Error%=323840437.8875\n",
            "Running: LR=0.001, HS=32, BS=16, Dropout=0.2, EncDim=8\n",
            "65 / 81 completed\n",
            "Epoch [1/200], Loss: 0.2652, Val Loss: 0.1592\n",
            "Epoch [2/200], Loss: 0.2117, Val Loss: 0.1361\n",
            "Epoch [3/200], Loss: 0.1998, Val Loss: 0.1303\n",
            "Epoch [4/200], Loss: 0.1923, Val Loss: 0.1196\n",
            "Epoch [5/200], Loss: 0.1855, Val Loss: 0.1163\n",
            "Epoch [6/200], Loss: 0.1809, Val Loss: 0.1133\n",
            "Epoch [7/200], Loss: 0.1777, Val Loss: 0.1151\n",
            "Epoch [8/200], Loss: 0.1734, Val Loss: 0.1084\n",
            "Epoch [9/200], Loss: 0.1729, Val Loss: 0.1068\n",
            "Epoch [10/200], Loss: 0.1707, Val Loss: 0.1071\n",
            "Epoch [11/200], Loss: 0.1703, Val Loss: 0.1030\n",
            "Epoch [12/200], Loss: 0.1683, Val Loss: 0.0978\n",
            "Epoch [13/200], Loss: 0.1689, Val Loss: 0.1056\n",
            "Epoch [14/200], Loss: 0.1675, Val Loss: 0.1048\n",
            "Epoch [15/200], Loss: 0.1669, Val Loss: 0.1029\n",
            "Epoch [16/200], Loss: 0.1664, Val Loss: 0.1041\n",
            "Epoch [17/200], Loss: 0.1655, Val Loss: 0.1029\n",
            "Epoch [18/200], Loss: 0.1654, Val Loss: 0.1020\n",
            "Epoch [19/200], Loss: 0.1627, Val Loss: 0.1031\n",
            "Epoch [20/200], Loss: 0.1650, Val Loss: 0.1009\n",
            "Epoch [21/200], Loss: 0.1638, Val Loss: 0.1103\n",
            "Epoch [22/200], Loss: 0.1649, Val Loss: 0.1031\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2518, Val Loss: 0.1292\n",
            "Epoch [2/200], Loss: 0.1993, Val Loss: 0.1182\n",
            "Epoch [3/200], Loss: 0.1915, Val Loss: 0.1172\n",
            "Epoch [4/200], Loss: 0.1873, Val Loss: 0.1171\n",
            "Epoch [5/200], Loss: 0.1846, Val Loss: 0.1111\n",
            "Epoch [6/200], Loss: 0.1806, Val Loss: 0.1093\n",
            "Epoch [7/200], Loss: 0.1758, Val Loss: 0.1042\n",
            "Epoch [8/200], Loss: 0.1728, Val Loss: 0.1049\n",
            "Epoch [9/200], Loss: 0.1703, Val Loss: 0.1059\n",
            "Epoch [10/200], Loss: 0.1680, Val Loss: 0.1028\n",
            "Epoch [11/200], Loss: 0.1659, Val Loss: 0.1041\n",
            "Epoch [12/200], Loss: 0.1653, Val Loss: 0.0997\n",
            "Epoch [13/200], Loss: 0.1642, Val Loss: 0.1031\n",
            "Epoch [14/200], Loss: 0.1638, Val Loss: 0.1064\n",
            "Epoch [15/200], Loss: 0.1630, Val Loss: 0.1004\n",
            "Epoch [16/200], Loss: 0.1624, Val Loss: 0.1008\n",
            "Epoch [17/200], Loss: 0.1622, Val Loss: 0.0958\n",
            "Epoch [18/200], Loss: 0.1617, Val Loss: 0.1004\n",
            "Epoch [19/200], Loss: 0.1616, Val Loss: 0.1022\n",
            "Epoch [20/200], Loss: 0.1611, Val Loss: 0.1049\n",
            "Epoch [21/200], Loss: 0.1616, Val Loss: 0.0997\n",
            "Epoch [22/200], Loss: 0.1612, Val Loss: 0.0955\n",
            "Epoch [23/200], Loss: 0.1607, Val Loss: 0.1060\n",
            "Epoch [24/200], Loss: 0.1607, Val Loss: 0.0971\n",
            "Epoch [25/200], Loss: 0.1602, Val Loss: 0.0996\n",
            "Epoch [26/200], Loss: 0.1606, Val Loss: 0.1076\n",
            "Epoch [27/200], Loss: 0.1598, Val Loss: 0.1001\n",
            "Epoch [28/200], Loss: 0.1600, Val Loss: 0.1024\n",
            "Epoch [29/200], Loss: 0.1599, Val Loss: 0.1038\n",
            "Epoch [30/200], Loss: 0.1598, Val Loss: 0.0950\n",
            "Epoch [31/200], Loss: 0.1596, Val Loss: 0.1008\n",
            "Epoch [32/200], Loss: 0.1591, Val Loss: 0.0969\n",
            "Epoch [33/200], Loss: 0.1599, Val Loss: 0.1014\n",
            "Epoch [34/200], Loss: 0.1591, Val Loss: 0.0995\n",
            "Epoch [35/200], Loss: 0.1582, Val Loss: 0.0967\n",
            "Epoch [36/200], Loss: 0.1599, Val Loss: 0.0982\n",
            "Epoch [37/200], Loss: 0.1595, Val Loss: 0.1017\n",
            "Epoch [38/200], Loss: 0.1614, Val Loss: 0.1000\n",
            "Epoch [39/200], Loss: 0.1600, Val Loss: 0.1023\n",
            "Epoch [40/200], Loss: 0.1599, Val Loss: 0.1048\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2602, Val Loss: 0.1380\n",
            "Epoch [2/200], Loss: 0.2033, Val Loss: 0.1335\n",
            "Epoch [3/200], Loss: 0.1969, Val Loss: 0.1235\n",
            "Epoch [4/200], Loss: 0.1910, Val Loss: 0.1218\n",
            "Epoch [5/200], Loss: 0.1869, Val Loss: 0.1169\n",
            "Epoch [6/200], Loss: 0.1838, Val Loss: 0.1137\n",
            "Epoch [7/200], Loss: 0.1815, Val Loss: 0.1137\n",
            "Epoch [8/200], Loss: 0.1791, Val Loss: 0.1124\n",
            "Epoch [9/200], Loss: 0.1770, Val Loss: 0.1098\n",
            "Epoch [10/200], Loss: 0.1771, Val Loss: 0.1077\n",
            "Epoch [11/200], Loss: 0.1758, Val Loss: 0.1158\n",
            "Epoch [12/200], Loss: 0.1743, Val Loss: 0.1093\n",
            "Epoch [13/200], Loss: 0.1744, Val Loss: 0.1116\n",
            "Epoch [14/200], Loss: 0.1741, Val Loss: 0.1144\n",
            "Epoch [15/200], Loss: 0.1732, Val Loss: 0.1085\n",
            "Epoch [16/200], Loss: 0.1719, Val Loss: 0.1194\n",
            "Epoch [17/200], Loss: 0.1719, Val Loss: 0.1111\n",
            "Epoch [18/200], Loss: 0.1711, Val Loss: 0.1176\n",
            "Epoch [19/200], Loss: 0.1713, Val Loss: 0.1087\n",
            "Epoch [20/200], Loss: 0.1711, Val Loss: 0.1175\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2464, Val Loss: 0.1407\n",
            "Epoch [2/200], Loss: 0.2028, Val Loss: 0.1336\n",
            "Epoch [3/200], Loss: 0.1933, Val Loss: 0.1242\n",
            "Epoch [4/200], Loss: 0.1886, Val Loss: 0.1316\n",
            "Epoch [5/200], Loss: 0.1863, Val Loss: 0.1227\n",
            "Epoch [6/200], Loss: 0.1830, Val Loss: 0.1219\n",
            "Epoch [7/200], Loss: 0.1824, Val Loss: 0.1173\n",
            "Epoch [8/200], Loss: 0.1799, Val Loss: 0.1186\n",
            "Epoch [9/200], Loss: 0.1778, Val Loss: 0.1164\n",
            "Epoch [10/200], Loss: 0.1762, Val Loss: 0.1112\n",
            "Epoch [11/200], Loss: 0.1758, Val Loss: 0.1099\n",
            "Epoch [12/200], Loss: 0.1746, Val Loss: 0.1106\n",
            "Epoch [13/200], Loss: 0.1739, Val Loss: 0.1100\n",
            "Epoch [14/200], Loss: 0.1724, Val Loss: 0.1051\n",
            "Epoch [15/200], Loss: 0.1715, Val Loss: 0.1071\n",
            "Epoch [16/200], Loss: 0.1715, Val Loss: 0.1138\n",
            "Epoch [17/200], Loss: 0.1706, Val Loss: 0.1035\n",
            "Epoch [18/200], Loss: 0.1707, Val Loss: 0.1070\n",
            "Epoch [19/200], Loss: 0.1712, Val Loss: 0.1060\n",
            "Epoch [20/200], Loss: 0.1709, Val Loss: 0.1062\n",
            "Epoch [21/200], Loss: 0.1706, Val Loss: 0.1036\n",
            "Epoch [22/200], Loss: 0.1703, Val Loss: 0.1056\n",
            "Epoch [23/200], Loss: 0.1711, Val Loss: 0.1023\n",
            "Epoch [24/200], Loss: 0.1700, Val Loss: 0.1033\n",
            "Epoch [25/200], Loss: 0.1688, Val Loss: 0.1061\n",
            "Epoch [26/200], Loss: 0.1704, Val Loss: 0.1055\n",
            "Epoch [27/200], Loss: 0.1696, Val Loss: 0.1054\n",
            "Epoch [28/200], Loss: 0.1690, Val Loss: 0.1074\n",
            "Epoch [29/200], Loss: 0.1684, Val Loss: 0.1018\n",
            "Epoch [30/200], Loss: 0.1695, Val Loss: 0.1052\n",
            "Epoch [31/200], Loss: 0.1691, Val Loss: 0.1053\n",
            "Epoch [32/200], Loss: 0.1693, Val Loss: 0.1048\n",
            "Epoch [33/200], Loss: 0.1688, Val Loss: 0.1054\n",
            "Epoch [34/200], Loss: 0.1682, Val Loss: 0.1067\n",
            "Epoch [35/200], Loss: 0.1687, Val Loss: 0.1097\n",
            "Epoch [36/200], Loss: 0.1686, Val Loss: 0.1068\n",
            "Epoch [37/200], Loss: 0.1680, Val Loss: 0.1016\n",
            "Epoch [38/200], Loss: 0.1667, Val Loss: 0.1027\n",
            "Epoch [39/200], Loss: 0.1674, Val Loss: 0.1005\n",
            "Epoch [40/200], Loss: 0.1668, Val Loss: 0.1013\n",
            "Epoch [41/200], Loss: 0.1668, Val Loss: 0.1062\n",
            "Epoch [42/200], Loss: 0.1683, Val Loss: 0.1049\n",
            "Epoch [43/200], Loss: 0.1665, Val Loss: 0.1018\n",
            "Epoch [44/200], Loss: 0.1669, Val Loss: 0.0995\n",
            "Epoch [45/200], Loss: 0.1679, Val Loss: 0.0992\n",
            "Epoch [46/200], Loss: 0.1668, Val Loss: 0.1001\n",
            "Epoch [47/200], Loss: 0.1667, Val Loss: 0.1035\n",
            "Epoch [48/200], Loss: 0.1671, Val Loss: 0.1017\n",
            "Epoch [49/200], Loss: 0.1663, Val Loss: 0.1000\n",
            "Epoch [50/200], Loss: 0.1659, Val Loss: 0.1003\n",
            "Epoch [51/200], Loss: 0.1666, Val Loss: 0.0976\n",
            "Epoch [52/200], Loss: 0.1662, Val Loss: 0.1026\n",
            "Epoch [53/200], Loss: 0.1663, Val Loss: 0.0988\n",
            "Epoch [54/200], Loss: 0.1661, Val Loss: 0.0987\n",
            "Epoch [55/200], Loss: 0.1653, Val Loss: 0.0972\n",
            "Epoch [56/200], Loss: 0.1636, Val Loss: 0.1052\n",
            "Epoch [57/200], Loss: 0.1647, Val Loss: 0.1006\n",
            "Epoch [58/200], Loss: 0.1644, Val Loss: 0.0996\n",
            "Epoch [59/200], Loss: 0.1625, Val Loss: 0.0984\n",
            "Epoch [60/200], Loss: 0.1636, Val Loss: 0.0992\n",
            "Epoch [61/200], Loss: 0.1645, Val Loss: 0.1011\n",
            "Epoch [62/200], Loss: 0.1620, Val Loss: 0.1033\n",
            "Epoch [63/200], Loss: 0.1641, Val Loss: 0.0963\n",
            "Epoch [64/200], Loss: 0.1621, Val Loss: 0.1047\n",
            "Epoch [65/200], Loss: 0.1622, Val Loss: 0.0973\n",
            "Epoch [66/200], Loss: 0.1621, Val Loss: 0.0983\n",
            "Epoch [67/200], Loss: 0.1621, Val Loss: 0.1001\n",
            "Epoch [68/200], Loss: 0.1623, Val Loss: 0.1021\n",
            "Epoch [69/200], Loss: 0.1618, Val Loss: 0.1044\n",
            "Epoch [70/200], Loss: 0.1617, Val Loss: 0.0990\n",
            "Epoch [71/200], Loss: 0.1599, Val Loss: 0.0997\n",
            "Epoch [72/200], Loss: 0.1621, Val Loss: 0.0966\n",
            "Epoch [73/200], Loss: 0.1616, Val Loss: 0.0963\n",
            "Epoch [74/200], Loss: 0.1607, Val Loss: 0.0983\n",
            "Epoch [75/200], Loss: 0.1618, Val Loss: 0.0981\n",
            "Epoch [76/200], Loss: 0.1593, Val Loss: 0.1019\n",
            "Epoch [77/200], Loss: 0.1603, Val Loss: 0.0992\n",
            "Epoch [78/200], Loss: 0.1607, Val Loss: 0.1011\n",
            "Epoch [79/200], Loss: 0.1606, Val Loss: 0.0954\n",
            "Epoch [80/200], Loss: 0.1617, Val Loss: 0.0971\n",
            "Epoch [81/200], Loss: 0.1608, Val Loss: 0.0984\n",
            "Epoch [82/200], Loss: 0.1607, Val Loss: 0.0971\n",
            "Epoch [83/200], Loss: 0.1605, Val Loss: 0.0953\n",
            "Epoch [84/200], Loss: 0.1596, Val Loss: 0.0995\n",
            "Epoch [85/200], Loss: 0.1580, Val Loss: 0.1007\n",
            "Epoch [86/200], Loss: 0.1599, Val Loss: 0.0987\n",
            "Epoch [87/200], Loss: 0.1615, Val Loss: 0.0965\n",
            "Epoch [88/200], Loss: 0.1595, Val Loss: 0.1014\n",
            "Epoch [89/200], Loss: 0.1598, Val Loss: 0.0945\n",
            "Epoch [90/200], Loss: 0.1583, Val Loss: 0.0962\n",
            "Epoch [91/200], Loss: 0.1600, Val Loss: 0.0984\n",
            "Epoch [92/200], Loss: 0.1588, Val Loss: 0.0959\n",
            "Epoch [93/200], Loss: 0.1590, Val Loss: 0.0962\n",
            "Epoch [94/200], Loss: 0.1584, Val Loss: 0.0983\n",
            "Epoch [95/200], Loss: 0.1591, Val Loss: 0.0972\n",
            "Epoch [96/200], Loss: 0.1580, Val Loss: 0.0984\n",
            "Epoch [97/200], Loss: 0.1588, Val Loss: 0.0917\n",
            "Epoch [98/200], Loss: 0.1596, Val Loss: 0.0935\n",
            "Epoch [99/200], Loss: 0.1588, Val Loss: 0.1003\n",
            "Epoch [100/200], Loss: 0.1593, Val Loss: 0.0945\n",
            "Epoch [101/200], Loss: 0.1590, Val Loss: 0.0971\n",
            "Epoch [102/200], Loss: 0.1582, Val Loss: 0.0956\n",
            "Epoch [103/200], Loss: 0.1580, Val Loss: 0.0957\n",
            "Epoch [104/200], Loss: 0.1583, Val Loss: 0.0959\n",
            "Epoch [105/200], Loss: 0.1586, Val Loss: 0.0957\n",
            "Epoch [106/200], Loss: 0.1595, Val Loss: 0.1051\n",
            "Epoch [107/200], Loss: 0.1585, Val Loss: 0.1008\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2670, Val Loss: 0.1389\n",
            "Epoch [2/200], Loss: 0.2077, Val Loss: 0.1319\n",
            "Epoch [3/200], Loss: 0.1981, Val Loss: 0.1156\n",
            "Epoch [4/200], Loss: 0.1915, Val Loss: 0.1179\n",
            "Epoch [5/200], Loss: 0.1877, Val Loss: 0.1144\n",
            "Epoch [6/200], Loss: 0.1850, Val Loss: 0.1162\n",
            "Epoch [7/200], Loss: 0.1836, Val Loss: 0.1129\n",
            "Epoch [8/200], Loss: 0.1820, Val Loss: 0.1115\n",
            "Epoch [9/200], Loss: 0.1797, Val Loss: 0.1122\n",
            "Epoch [10/200], Loss: 0.1791, Val Loss: 0.1093\n",
            "Epoch [11/200], Loss: 0.1770, Val Loss: 0.1086\n",
            "Epoch [12/200], Loss: 0.1758, Val Loss: 0.1099\n",
            "Epoch [13/200], Loss: 0.1747, Val Loss: 0.1054\n",
            "Epoch [14/200], Loss: 0.1723, Val Loss: 0.1049\n",
            "Epoch [15/200], Loss: 0.1711, Val Loss: 0.1048\n",
            "Epoch [16/200], Loss: 0.1703, Val Loss: 0.1057\n",
            "Epoch [17/200], Loss: 0.1697, Val Loss: 0.1103\n",
            "Epoch [18/200], Loss: 0.1680, Val Loss: 0.1046\n",
            "Epoch [19/200], Loss: 0.1679, Val Loss: 0.1045\n",
            "Epoch [20/200], Loss: 0.1675, Val Loss: 0.1019\n",
            "Epoch [21/200], Loss: 0.1665, Val Loss: 0.1034\n",
            "Epoch [22/200], Loss: 0.1659, Val Loss: 0.1048\n",
            "Epoch [23/200], Loss: 0.1650, Val Loss: 0.1012\n",
            "Epoch [24/200], Loss: 0.1641, Val Loss: 0.1021\n",
            "Epoch [25/200], Loss: 0.1646, Val Loss: 0.1044\n",
            "Epoch [26/200], Loss: 0.1642, Val Loss: 0.1085\n",
            "Epoch [27/200], Loss: 0.1634, Val Loss: 0.1042\n",
            "Epoch [28/200], Loss: 0.1621, Val Loss: 0.1007\n",
            "Epoch [29/200], Loss: 0.1631, Val Loss: 0.1018\n",
            "Epoch [30/200], Loss: 0.1620, Val Loss: 0.1017\n",
            "Epoch [31/200], Loss: 0.1630, Val Loss: 0.1008\n",
            "Epoch [32/200], Loss: 0.1632, Val Loss: 0.1063\n",
            "Epoch [33/200], Loss: 0.1631, Val Loss: 0.1020\n",
            "Epoch [34/200], Loss: 0.1627, Val Loss: 0.1030\n",
            "Epoch [35/200], Loss: 0.1625, Val Loss: 0.1032\n",
            "Epoch [36/200], Loss: 0.1622, Val Loss: 0.1100\n",
            "Epoch [37/200], Loss: 0.1616, Val Loss: 0.1022\n",
            "Epoch [38/200], Loss: 0.1620, Val Loss: 0.1060\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=32, BS=16, Dropout=0.2, EncDim=8 -> MAE=0.2070, Error%=571518945.9031\n",
            "Running: LR=0.001, HS=32, BS=32, Dropout=0.0, EncDim=8\n",
            "66 / 81 completed\n",
            "Epoch [1/200], Loss: 0.0739, Val Loss: 0.0239\n",
            "Epoch [2/200], Loss: 0.0207, Val Loss: 0.0161\n",
            "Epoch [3/200], Loss: 0.0145, Val Loss: 0.0132\n",
            "Epoch [4/200], Loss: 0.0084, Val Loss: 0.0054\n",
            "Epoch [5/200], Loss: 0.0050, Val Loss: 0.0048\n",
            "Epoch [6/200], Loss: 0.0047, Val Loss: 0.0047\n",
            "Epoch [7/200], Loss: 0.0046, Val Loss: 0.0046\n",
            "Epoch [8/200], Loss: 0.0045, Val Loss: 0.0046\n",
            "Epoch [9/200], Loss: 0.0044, Val Loss: 0.0044\n",
            "Epoch [10/200], Loss: 0.0044, Val Loss: 0.0049\n",
            "Epoch [11/200], Loss: 0.0044, Val Loss: 0.0044\n",
            "Epoch [12/200], Loss: 0.0043, Val Loss: 0.0042\n",
            "Epoch [13/200], Loss: 0.0036, Val Loss: 0.0032\n",
            "Epoch [14/200], Loss: 0.0022, Val Loss: 0.0022\n",
            "Epoch [15/200], Loss: 0.0020, Val Loss: 0.0019\n",
            "Epoch [16/200], Loss: 0.0019, Val Loss: 0.0020\n",
            "Epoch [17/200], Loss: 0.0018, Val Loss: 0.0019\n",
            "Epoch [18/200], Loss: 0.0017, Val Loss: 0.0017\n",
            "Epoch [19/200], Loss: 0.0017, Val Loss: 0.0018\n",
            "Epoch [20/200], Loss: 0.0017, Val Loss: 0.0020\n",
            "Epoch [21/200], Loss: 0.0017, Val Loss: 0.0017\n",
            "Epoch [22/200], Loss: 0.0017, Val Loss: 0.0017\n",
            "Epoch [23/200], Loss: 0.0017, Val Loss: 0.0017\n",
            "Epoch [24/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [25/200], Loss: 0.0017, Val Loss: 0.0017\n",
            "Epoch [26/200], Loss: 0.0016, Val Loss: 0.0019\n",
            "Epoch [27/200], Loss: 0.0016, Val Loss: 0.0018\n",
            "Epoch [28/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [29/200], Loss: 0.0016, Val Loss: 0.0018\n",
            "Epoch [30/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [31/200], Loss: 0.0015, Val Loss: 0.0015\n",
            "Epoch [32/200], Loss: 0.0014, Val Loss: 0.0015\n",
            "Epoch [33/200], Loss: 0.0013, Val Loss: 0.0018\n",
            "Epoch [34/200], Loss: 0.0012, Val Loss: 0.0017\n",
            "Epoch [35/200], Loss: 0.0012, Val Loss: 0.0012\n",
            "Epoch [36/200], Loss: 0.0011, Val Loss: 0.0011\n",
            "Epoch [37/200], Loss: 0.0011, Val Loss: 0.0011\n",
            "Epoch [38/200], Loss: 0.0010, Val Loss: 0.0012\n",
            "Epoch [39/200], Loss: 0.0010, Val Loss: 0.0010\n",
            "Epoch [40/200], Loss: 0.0010, Val Loss: 0.0011\n",
            "Epoch [41/200], Loss: 0.0009, Val Loss: 0.0010\n",
            "Epoch [42/200], Loss: 0.0009, Val Loss: 0.0010\n",
            "Epoch [43/200], Loss: 0.0008, Val Loss: 0.0012\n",
            "Epoch [44/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [45/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [46/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [47/200], Loss: 0.0008, Val Loss: 0.0007\n",
            "Epoch [48/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [49/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [50/200], Loss: 0.0007, Val Loss: 0.0008\n",
            "Epoch [51/200], Loss: 0.0007, Val Loss: 0.0009\n",
            "Epoch [52/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [53/200], Loss: 0.0007, Val Loss: 0.0008\n",
            "Epoch [54/200], Loss: 0.0007, Val Loss: 0.0008\n",
            "Epoch [55/200], Loss: 0.0007, Val Loss: 0.0008\n",
            "Epoch [56/200], Loss: 0.0007, Val Loss: 0.0008\n",
            "Epoch [57/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [58/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [59/200], Loss: 0.0007, Val Loss: 0.0008\n",
            "Epoch [60/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [61/200], Loss: 0.0007, Val Loss: 0.0006\n",
            "Epoch [62/200], Loss: 0.0007, Val Loss: 0.0008\n",
            "Epoch [63/200], Loss: 0.0007, Val Loss: 0.0006\n",
            "Epoch [64/200], Loss: 0.0007, Val Loss: 0.0008\n",
            "Epoch [65/200], Loss: 0.0007, Val Loss: 0.0006\n",
            "Epoch [66/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [67/200], Loss: 0.0006, Val Loss: 0.0007\n",
            "Epoch [68/200], Loss: 0.0006, Val Loss: 0.0007\n",
            "Epoch [69/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [70/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [71/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [72/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [73/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [74/200], Loss: 0.0005, Val Loss: 0.0007\n",
            "Epoch [75/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [76/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [77/200], Loss: 0.0005, Val Loss: 0.0007\n",
            "Epoch [78/200], Loss: 0.0005, Val Loss: 0.0007\n",
            "Epoch [79/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [80/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [81/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [82/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [83/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [84/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [85/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [86/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [87/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [88/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [89/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [90/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [91/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [92/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [93/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [94/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [95/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [96/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [97/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [98/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [99/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [100/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [101/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [102/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [103/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [104/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [105/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [106/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [107/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [108/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [109/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [110/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [111/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [112/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [113/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [114/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [115/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [116/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [117/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [118/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [119/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [120/200], Loss: 0.0003, Val Loss: 0.0005\n",
            "Epoch [121/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [122/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [123/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [124/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [125/200], Loss: 0.0002, Val Loss: 0.0004\n",
            "Epoch [126/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [127/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [128/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [129/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [130/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [131/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [132/200], Loss: 0.0002, Val Loss: 0.0004\n",
            "Epoch [133/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [134/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [135/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [136/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [137/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [138/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [139/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [140/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [141/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [142/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [143/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [144/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [145/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [146/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [147/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [148/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [149/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [150/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [151/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [152/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [153/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [154/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [155/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [156/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [157/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [158/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0763, Val Loss: 0.0216\n",
            "Epoch [2/200], Loss: 0.0168, Val Loss: 0.0151\n",
            "Epoch [3/200], Loss: 0.0126, Val Loss: 0.0105\n",
            "Epoch [4/200], Loss: 0.0091, Val Loss: 0.0074\n",
            "Epoch [5/200], Loss: 0.0063, Val Loss: 0.0055\n",
            "Epoch [6/200], Loss: 0.0049, Val Loss: 0.0045\n",
            "Epoch [7/200], Loss: 0.0043, Val Loss: 0.0043\n",
            "Epoch [8/200], Loss: 0.0041, Val Loss: 0.0040\n",
            "Epoch [9/200], Loss: 0.0039, Val Loss: 0.0039\n",
            "Epoch [10/200], Loss: 0.0038, Val Loss: 0.0040\n",
            "Epoch [11/200], Loss: 0.0037, Val Loss: 0.0038\n",
            "Epoch [12/200], Loss: 0.0037, Val Loss: 0.0036\n",
            "Epoch [13/200], Loss: 0.0036, Val Loss: 0.0037\n",
            "Epoch [14/200], Loss: 0.0035, Val Loss: 0.0035\n",
            "Epoch [15/200], Loss: 0.0035, Val Loss: 0.0034\n",
            "Epoch [16/200], Loss: 0.0034, Val Loss: 0.0034\n",
            "Epoch [17/200], Loss: 0.0033, Val Loss: 0.0037\n",
            "Epoch [18/200], Loss: 0.0033, Val Loss: 0.0033\n",
            "Epoch [19/200], Loss: 0.0033, Val Loss: 0.0037\n",
            "Epoch [20/200], Loss: 0.0032, Val Loss: 0.0033\n",
            "Epoch [21/200], Loss: 0.0032, Val Loss: 0.0032\n",
            "Epoch [22/200], Loss: 0.0032, Val Loss: 0.0032\n",
            "Epoch [23/200], Loss: 0.0031, Val Loss: 0.0031\n",
            "Epoch [24/200], Loss: 0.0031, Val Loss: 0.0032\n",
            "Epoch [25/200], Loss: 0.0030, Val Loss: 0.0030\n",
            "Epoch [26/200], Loss: 0.0030, Val Loss: 0.0030\n",
            "Epoch [27/200], Loss: 0.0029, Val Loss: 0.0031\n",
            "Epoch [28/200], Loss: 0.0030, Val Loss: 0.0030\n",
            "Epoch [29/200], Loss: 0.0029, Val Loss: 0.0030\n",
            "Epoch [30/200], Loss: 0.0029, Val Loss: 0.0030\n",
            "Epoch [31/200], Loss: 0.0029, Val Loss: 0.0029\n",
            "Epoch [32/200], Loss: 0.0029, Val Loss: 0.0029\n",
            "Epoch [33/200], Loss: 0.0028, Val Loss: 0.0031\n",
            "Epoch [34/200], Loss: 0.0028, Val Loss: 0.0029\n",
            "Epoch [35/200], Loss: 0.0029, Val Loss: 0.0038\n",
            "Epoch [36/200], Loss: 0.0028, Val Loss: 0.0028\n",
            "Epoch [37/200], Loss: 0.0028, Val Loss: 0.0030\n",
            "Epoch [38/200], Loss: 0.0028, Val Loss: 0.0031\n",
            "Epoch [39/200], Loss: 0.0027, Val Loss: 0.0029\n",
            "Epoch [40/200], Loss: 0.0028, Val Loss: 0.0028\n",
            "Epoch [41/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [42/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Epoch [43/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Epoch [44/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Epoch [45/200], Loss: 0.0027, Val Loss: 0.0030\n",
            "Epoch [46/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [47/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [48/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [49/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [50/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [51/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [52/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [53/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [54/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Epoch [55/200], Loss: 0.0026, Val Loss: 0.0027\n",
            "Epoch [56/200], Loss: 0.0026, Val Loss: 0.0028\n",
            "Epoch [57/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [58/200], Loss: 0.0026, Val Loss: 0.0027\n",
            "Epoch [59/200], Loss: 0.0026, Val Loss: 0.0028\n",
            "Epoch [60/200], Loss: 0.0026, Val Loss: 0.0027\n",
            "Epoch [61/200], Loss: 0.0026, Val Loss: 0.0028\n",
            "Epoch [62/200], Loss: 0.0026, Val Loss: 0.0027\n",
            "Epoch [63/200], Loss: 0.0026, Val Loss: 0.0027\n",
            "Epoch [64/200], Loss: 0.0026, Val Loss: 0.0027\n",
            "Epoch [65/200], Loss: 0.0025, Val Loss: 0.0026\n",
            "Epoch [66/200], Loss: 0.0024, Val Loss: 0.0025\n",
            "Epoch [67/200], Loss: 0.0018, Val Loss: 0.0009\n",
            "Epoch [68/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [69/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [70/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [71/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [72/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [73/200], Loss: 0.0004, Val Loss: 0.0008\n",
            "Epoch [74/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [75/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [76/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [77/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [78/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [79/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [80/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [81/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [82/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [83/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [84/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [85/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [86/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [87/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [88/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [89/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [90/200], Loss: 0.0001, Val Loss: 0.0005\n",
            "Epoch [91/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [92/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [93/200], Loss: 0.0001, Val Loss: 0.0004\n",
            "Epoch [94/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [95/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [96/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [97/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [98/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0955, Val Loss: 0.0300\n",
            "Epoch [2/200], Loss: 0.0194, Val Loss: 0.0132\n",
            "Epoch [3/200], Loss: 0.0112, Val Loss: 0.0099\n",
            "Epoch [4/200], Loss: 0.0096, Val Loss: 0.0094\n",
            "Epoch [5/200], Loss: 0.0090, Val Loss: 0.0090\n",
            "Epoch [6/200], Loss: 0.0085, Val Loss: 0.0080\n",
            "Epoch [7/200], Loss: 0.0077, Val Loss: 0.0077\n",
            "Epoch [8/200], Loss: 0.0057, Val Loss: 0.0044\n",
            "Epoch [9/200], Loss: 0.0041, Val Loss: 0.0040\n",
            "Epoch [10/200], Loss: 0.0038, Val Loss: 0.0040\n",
            "Epoch [11/200], Loss: 0.0038, Val Loss: 0.0037\n",
            "Epoch [12/200], Loss: 0.0037, Val Loss: 0.0037\n",
            "Epoch [13/200], Loss: 0.0036, Val Loss: 0.0037\n",
            "Epoch [14/200], Loss: 0.0037, Val Loss: 0.0036\n",
            "Epoch [15/200], Loss: 0.0036, Val Loss: 0.0036\n",
            "Epoch [16/200], Loss: 0.0036, Val Loss: 0.0045\n",
            "Epoch [17/200], Loss: 0.0036, Val Loss: 0.0036\n",
            "Epoch [18/200], Loss: 0.0035, Val Loss: 0.0036\n",
            "Epoch [19/200], Loss: 0.0035, Val Loss: 0.0037\n",
            "Epoch [20/200], Loss: 0.0035, Val Loss: 0.0035\n",
            "Epoch [21/200], Loss: 0.0022, Val Loss: 0.0014\n",
            "Epoch [22/200], Loss: 0.0013, Val Loss: 0.0013\n",
            "Epoch [23/200], Loss: 0.0013, Val Loss: 0.0013\n",
            "Epoch [24/200], Loss: 0.0013, Val Loss: 0.0013\n",
            "Epoch [25/200], Loss: 0.0013, Val Loss: 0.0013\n",
            "Epoch [26/200], Loss: 0.0013, Val Loss: 0.0013\n",
            "Epoch [27/200], Loss: 0.0012, Val Loss: 0.0015\n",
            "Epoch [28/200], Loss: 0.0012, Val Loss: 0.0012\n",
            "Epoch [29/200], Loss: 0.0012, Val Loss: 0.0012\n",
            "Epoch [30/200], Loss: 0.0011, Val Loss: 0.0012\n",
            "Epoch [31/200], Loss: 0.0011, Val Loss: 0.0012\n",
            "Epoch [32/200], Loss: 0.0010, Val Loss: 0.0010\n",
            "Epoch [33/200], Loss: 0.0010, Val Loss: 0.0015\n",
            "Epoch [34/200], Loss: 0.0009, Val Loss: 0.0009\n",
            "Epoch [35/200], Loss: 0.0009, Val Loss: 0.0010\n",
            "Epoch [36/200], Loss: 0.0009, Val Loss: 0.0010\n",
            "Epoch [37/200], Loss: 0.0009, Val Loss: 0.0010\n",
            "Epoch [38/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [39/200], Loss: 0.0008, Val Loss: 0.0009\n",
            "Epoch [40/200], Loss: 0.0009, Val Loss: 0.0009\n",
            "Epoch [41/200], Loss: 0.0008, Val Loss: 0.0009\n",
            "Epoch [42/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [43/200], Loss: 0.0008, Val Loss: 0.0009\n",
            "Epoch [44/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [45/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [46/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [47/200], Loss: 0.0007, Val Loss: 0.0008\n",
            "Epoch [48/200], Loss: 0.0007, Val Loss: 0.0012\n",
            "Epoch [49/200], Loss: 0.0007, Val Loss: 0.0008\n",
            "Epoch [50/200], Loss: 0.0007, Val Loss: 0.0008\n",
            "Epoch [51/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [52/200], Loss: 0.0007, Val Loss: 0.0010\n",
            "Epoch [53/200], Loss: 0.0007, Val Loss: 0.0006\n",
            "Epoch [54/200], Loss: 0.0006, Val Loss: 0.0008\n",
            "Epoch [55/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [56/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [57/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [58/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [59/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [60/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [61/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [62/200], Loss: 0.0005, Val Loss: 0.0007\n",
            "Epoch [63/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [64/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [65/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [66/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [67/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [68/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [69/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [70/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [71/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [72/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [73/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [74/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [75/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [76/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [77/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [78/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [79/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [80/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [81/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [82/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [83/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [84/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [85/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [86/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [87/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [88/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [89/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [90/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [91/200], Loss: 0.0001, Val Loss: 0.0003\n",
            "Epoch [92/200], Loss: 0.0002, Val Loss: 0.0006\n",
            "Epoch [93/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [94/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [95/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [96/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [97/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [98/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [99/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [100/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [101/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [102/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [103/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [104/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [105/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [106/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [107/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [108/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [109/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [110/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [111/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [112/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [113/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [114/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [115/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [116/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [117/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [118/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [119/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [120/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [121/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [122/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [123/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [124/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0973, Val Loss: 0.0406\n",
            "Epoch [2/200], Loss: 0.0257, Val Loss: 0.0221\n",
            "Epoch [3/200], Loss: 0.0209, Val Loss: 0.0184\n",
            "Epoch [4/200], Loss: 0.0145, Val Loss: 0.0110\n",
            "Epoch [5/200], Loss: 0.0095, Val Loss: 0.0091\n",
            "Epoch [6/200], Loss: 0.0087, Val Loss: 0.0088\n",
            "Epoch [7/200], Loss: 0.0058, Val Loss: 0.0049\n",
            "Epoch [8/200], Loss: 0.0044, Val Loss: 0.0042\n",
            "Epoch [9/200], Loss: 0.0041, Val Loss: 0.0043\n",
            "Epoch [10/200], Loss: 0.0039, Val Loss: 0.0040\n",
            "Epoch [11/200], Loss: 0.0038, Val Loss: 0.0038\n",
            "Epoch [12/200], Loss: 0.0037, Val Loss: 0.0037\n",
            "Epoch [13/200], Loss: 0.0036, Val Loss: 0.0038\n",
            "Epoch [14/200], Loss: 0.0036, Val Loss: 0.0037\n",
            "Epoch [15/200], Loss: 0.0035, Val Loss: 0.0035\n",
            "Epoch [16/200], Loss: 0.0034, Val Loss: 0.0034\n",
            "Epoch [17/200], Loss: 0.0033, Val Loss: 0.0036\n",
            "Epoch [18/200], Loss: 0.0026, Val Loss: 0.0013\n",
            "Epoch [19/200], Loss: 0.0009, Val Loss: 0.0014\n",
            "Epoch [20/200], Loss: 0.0008, Val Loss: 0.0006\n",
            "Epoch [21/200], Loss: 0.0007, Val Loss: 0.0006\n",
            "Epoch [22/200], Loss: 0.0007, Val Loss: 0.0016\n",
            "Epoch [23/200], Loss: 0.0007, Val Loss: 0.0008\n",
            "Epoch [24/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [25/200], Loss: 0.0006, Val Loss: 0.0007\n",
            "Epoch [26/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [27/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [28/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [29/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [30/200], Loss: 0.0005, Val Loss: 0.0003\n",
            "Epoch [31/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [32/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [33/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [34/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [35/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [36/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [37/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [38/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [39/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [40/200], Loss: 0.0003, Val Loss: 0.0005\n",
            "Epoch [41/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [42/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [43/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [44/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [45/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [46/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [47/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [48/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [49/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [50/200], Loss: 0.0002, Val Loss: 0.0012\n",
            "Epoch [51/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [52/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [53/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [54/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [55/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [56/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [57/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [58/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [59/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [60/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [61/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [62/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [63/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [64/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [65/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [66/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [67/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [68/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [69/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [70/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [71/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [72/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [73/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [74/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [75/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [76/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [77/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [78/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [79/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [80/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [81/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [82/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [83/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [84/200], Loss: 0.0001, Val Loss: 0.0003\n",
            "Epoch [85/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [86/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [87/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [88/200], Loss: 0.0001, Val Loss: 0.0003\n",
            "Epoch [89/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [90/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [91/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [92/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0908, Val Loss: 0.0254\n",
            "Epoch [2/200], Loss: 0.0236, Val Loss: 0.0224\n",
            "Epoch [3/200], Loss: 0.0213, Val Loss: 0.0171\n",
            "Epoch [4/200], Loss: 0.0115, Val Loss: 0.0077\n",
            "Epoch [5/200], Loss: 0.0070, Val Loss: 0.0067\n",
            "Epoch [6/200], Loss: 0.0063, Val Loss: 0.0060\n",
            "Epoch [7/200], Loss: 0.0059, Val Loss: 0.0058\n",
            "Epoch [8/200], Loss: 0.0049, Val Loss: 0.0034\n",
            "Epoch [9/200], Loss: 0.0025, Val Loss: 0.0024\n",
            "Epoch [10/200], Loss: 0.0021, Val Loss: 0.0021\n",
            "Epoch [11/200], Loss: 0.0020, Val Loss: 0.0021\n",
            "Epoch [12/200], Loss: 0.0019, Val Loss: 0.0020\n",
            "Epoch [13/200], Loss: 0.0019, Val Loss: 0.0022\n",
            "Epoch [14/200], Loss: 0.0018, Val Loss: 0.0019\n",
            "Epoch [15/200], Loss: 0.0018, Val Loss: 0.0019\n",
            "Epoch [16/200], Loss: 0.0018, Val Loss: 0.0018\n",
            "Epoch [17/200], Loss: 0.0017, Val Loss: 0.0019\n",
            "Epoch [18/200], Loss: 0.0017, Val Loss: 0.0018\n",
            "Epoch [19/200], Loss: 0.0016, Val Loss: 0.0015\n",
            "Epoch [20/200], Loss: 0.0015, Val Loss: 0.0017\n",
            "Epoch [21/200], Loss: 0.0014, Val Loss: 0.0017\n",
            "Epoch [22/200], Loss: 0.0013, Val Loss: 0.0012\n",
            "Epoch [23/200], Loss: 0.0013, Val Loss: 0.0014\n",
            "Epoch [24/200], Loss: 0.0012, Val Loss: 0.0014\n",
            "Epoch [25/200], Loss: 0.0012, Val Loss: 0.0013\n",
            "Epoch [26/200], Loss: 0.0011, Val Loss: 0.0012\n",
            "Epoch [27/200], Loss: 0.0012, Val Loss: 0.0012\n",
            "Epoch [28/200], Loss: 0.0011, Val Loss: 0.0012\n",
            "Epoch [29/200], Loss: 0.0011, Val Loss: 0.0010\n",
            "Epoch [30/200], Loss: 0.0011, Val Loss: 0.0011\n",
            "Epoch [31/200], Loss: 0.0010, Val Loss: 0.0012\n",
            "Epoch [32/200], Loss: 0.0010, Val Loss: 0.0011\n",
            "Epoch [33/200], Loss: 0.0010, Val Loss: 0.0010\n",
            "Epoch [34/200], Loss: 0.0009, Val Loss: 0.0010\n",
            "Epoch [35/200], Loss: 0.0009, Val Loss: 0.0009\n",
            "Epoch [36/200], Loss: 0.0009, Val Loss: 0.0008\n",
            "Epoch [37/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [38/200], Loss: 0.0008, Val Loss: 0.0009\n",
            "Epoch [39/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [40/200], Loss: 0.0006, Val Loss: 0.0007\n",
            "Epoch [41/200], Loss: 0.0006, Val Loss: 0.0007\n",
            "Epoch [42/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [43/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [44/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [45/200], Loss: 0.0005, Val Loss: 0.0007\n",
            "Epoch [46/200], Loss: 0.0005, Val Loss: 0.0003\n",
            "Epoch [47/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [48/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [49/200], Loss: 0.0004, Val Loss: 0.0006\n",
            "Epoch [50/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [51/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [52/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [53/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [54/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [55/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [56/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [57/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [58/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [59/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [60/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [61/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [62/200], Loss: 0.0003, Val Loss: 0.0005\n",
            "Epoch [63/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [64/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [65/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [66/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [67/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [68/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [69/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [70/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [71/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [72/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [73/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [74/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [75/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [76/200], Loss: 0.0002, Val Loss: 0.0004\n",
            "Epoch [77/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [78/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [79/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [80/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [81/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [82/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=32, BS=32, Dropout=0.0, EncDim=8 -> MAE=0.0064, Error%=23648877.4408\n",
            "Running: LR=0.001, HS=32, BS=32, Dropout=0.1, EncDim=8\n",
            "67 / 81 completed\n",
            "Epoch [1/200], Loss: 0.2037, Val Loss: 0.0907\n",
            "Epoch [2/200], Loss: 0.1388, Val Loss: 0.0816\n",
            "Epoch [3/200], Loss: 0.1332, Val Loss: 0.0784\n",
            "Epoch [4/200], Loss: 0.1286, Val Loss: 0.0794\n",
            "Epoch [5/200], Loss: 0.1266, Val Loss: 0.0767\n",
            "Epoch [6/200], Loss: 0.1244, Val Loss: 0.0763\n",
            "Epoch [7/200], Loss: 0.1237, Val Loss: 0.0744\n",
            "Epoch [8/200], Loss: 0.1222, Val Loss: 0.0749\n",
            "Epoch [9/200], Loss: 0.1207, Val Loss: 0.0767\n",
            "Epoch [10/200], Loss: 0.1187, Val Loss: 0.0764\n",
            "Epoch [11/200], Loss: 0.1173, Val Loss: 0.0762\n",
            "Epoch [12/200], Loss: 0.1160, Val Loss: 0.0743\n",
            "Epoch [13/200], Loss: 0.1147, Val Loss: 0.0756\n",
            "Epoch [14/200], Loss: 0.1140, Val Loss: 0.0751\n",
            "Epoch [15/200], Loss: 0.1128, Val Loss: 0.0744\n",
            "Epoch [16/200], Loss: 0.1120, Val Loss: 0.0723\n",
            "Epoch [17/200], Loss: 0.1115, Val Loss: 0.0716\n",
            "Epoch [18/200], Loss: 0.1106, Val Loss: 0.0680\n",
            "Epoch [19/200], Loss: 0.1092, Val Loss: 0.0677\n",
            "Epoch [20/200], Loss: 0.1087, Val Loss: 0.0653\n",
            "Epoch [21/200], Loss: 0.1084, Val Loss: 0.0635\n",
            "Epoch [22/200], Loss: 0.1074, Val Loss: 0.0610\n",
            "Epoch [23/200], Loss: 0.1063, Val Loss: 0.0622\n",
            "Epoch [24/200], Loss: 0.1059, Val Loss: 0.0604\n",
            "Epoch [25/200], Loss: 0.1057, Val Loss: 0.0610\n",
            "Epoch [26/200], Loss: 0.1047, Val Loss: 0.0610\n",
            "Epoch [27/200], Loss: 0.1047, Val Loss: 0.0593\n",
            "Epoch [28/200], Loss: 0.1033, Val Loss: 0.0596\n",
            "Epoch [29/200], Loss: 0.1036, Val Loss: 0.0594\n",
            "Epoch [30/200], Loss: 0.1031, Val Loss: 0.0583\n",
            "Epoch [31/200], Loss: 0.1027, Val Loss: 0.0579\n",
            "Epoch [32/200], Loss: 0.1035, Val Loss: 0.0582\n",
            "Epoch [33/200], Loss: 0.1019, Val Loss: 0.0595\n",
            "Epoch [34/200], Loss: 0.1015, Val Loss: 0.0554\n",
            "Epoch [35/200], Loss: 0.1006, Val Loss: 0.0533\n",
            "Epoch [36/200], Loss: 0.0994, Val Loss: 0.0538\n",
            "Epoch [37/200], Loss: 0.0990, Val Loss: 0.0540\n",
            "Epoch [38/200], Loss: 0.0992, Val Loss: 0.0533\n",
            "Epoch [39/200], Loss: 0.0990, Val Loss: 0.0512\n",
            "Epoch [40/200], Loss: 0.0982, Val Loss: 0.0537\n",
            "Epoch [41/200], Loss: 0.0981, Val Loss: 0.0525\n",
            "Epoch [42/200], Loss: 0.0976, Val Loss: 0.0526\n",
            "Epoch [43/200], Loss: 0.0984, Val Loss: 0.0563\n",
            "Epoch [44/200], Loss: 0.0977, Val Loss: 0.0516\n",
            "Epoch [45/200], Loss: 0.0978, Val Loss: 0.0503\n",
            "Epoch [46/200], Loss: 0.0976, Val Loss: 0.0544\n",
            "Epoch [47/200], Loss: 0.0968, Val Loss: 0.0560\n",
            "Epoch [48/200], Loss: 0.0967, Val Loss: 0.0517\n",
            "Epoch [49/200], Loss: 0.0975, Val Loss: 0.0531\n",
            "Epoch [50/200], Loss: 0.0972, Val Loss: 0.0576\n",
            "Epoch [51/200], Loss: 0.0966, Val Loss: 0.0575\n",
            "Epoch [52/200], Loss: 0.0969, Val Loss: 0.0551\n",
            "Epoch [53/200], Loss: 0.0978, Val Loss: 0.0521\n",
            "Epoch [54/200], Loss: 0.0969, Val Loss: 0.0553\n",
            "Epoch [55/200], Loss: 0.0965, Val Loss: 0.0522\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2006, Val Loss: 0.0938\n",
            "Epoch [2/200], Loss: 0.1403, Val Loss: 0.0831\n",
            "Epoch [3/200], Loss: 0.1334, Val Loss: 0.0806\n",
            "Epoch [4/200], Loss: 0.1294, Val Loss: 0.0772\n",
            "Epoch [5/200], Loss: 0.1267, Val Loss: 0.0767\n",
            "Epoch [6/200], Loss: 0.1253, Val Loss: 0.0755\n",
            "Epoch [7/200], Loss: 0.1244, Val Loss: 0.0755\n",
            "Epoch [8/200], Loss: 0.1225, Val Loss: 0.0761\n",
            "Epoch [9/200], Loss: 0.1221, Val Loss: 0.0749\n",
            "Epoch [10/200], Loss: 0.1207, Val Loss: 0.0728\n",
            "Epoch [11/200], Loss: 0.1187, Val Loss: 0.0770\n",
            "Epoch [12/200], Loss: 0.1191, Val Loss: 0.0740\n",
            "Epoch [13/200], Loss: 0.1178, Val Loss: 0.0736\n",
            "Epoch [14/200], Loss: 0.1166, Val Loss: 0.0745\n",
            "Epoch [15/200], Loss: 0.1155, Val Loss: 0.0737\n",
            "Epoch [16/200], Loss: 0.1146, Val Loss: 0.0727\n",
            "Epoch [17/200], Loss: 0.1141, Val Loss: 0.0736\n",
            "Epoch [18/200], Loss: 0.1129, Val Loss: 0.0724\n",
            "Epoch [19/200], Loss: 0.1124, Val Loss: 0.0706\n",
            "Epoch [20/200], Loss: 0.1116, Val Loss: 0.0709\n",
            "Epoch [21/200], Loss: 0.1109, Val Loss: 0.0734\n",
            "Epoch [22/200], Loss: 0.1100, Val Loss: 0.0715\n",
            "Epoch [23/200], Loss: 0.1096, Val Loss: 0.0699\n",
            "Epoch [24/200], Loss: 0.1094, Val Loss: 0.0695\n",
            "Epoch [25/200], Loss: 0.1089, Val Loss: 0.0702\n",
            "Epoch [26/200], Loss: 0.1090, Val Loss: 0.0698\n",
            "Epoch [27/200], Loss: 0.1080, Val Loss: 0.0701\n",
            "Epoch [28/200], Loss: 0.1080, Val Loss: 0.0663\n",
            "Epoch [29/200], Loss: 0.1076, Val Loss: 0.0668\n",
            "Epoch [30/200], Loss: 0.1063, Val Loss: 0.0654\n",
            "Epoch [31/200], Loss: 0.1064, Val Loss: 0.0623\n",
            "Epoch [32/200], Loss: 0.1052, Val Loss: 0.0618\n",
            "Epoch [33/200], Loss: 0.1036, Val Loss: 0.0578\n",
            "Epoch [34/200], Loss: 0.1026, Val Loss: 0.0615\n",
            "Epoch [35/200], Loss: 0.1019, Val Loss: 0.0604\n",
            "Epoch [36/200], Loss: 0.1014, Val Loss: 0.0608\n",
            "Epoch [37/200], Loss: 0.1013, Val Loss: 0.0590\n",
            "Epoch [38/200], Loss: 0.1002, Val Loss: 0.0607\n",
            "Epoch [39/200], Loss: 0.1006, Val Loss: 0.0602\n",
            "Epoch [40/200], Loss: 0.1002, Val Loss: 0.0588\n",
            "Epoch [41/200], Loss: 0.0993, Val Loss: 0.0583\n",
            "Epoch [42/200], Loss: 0.0991, Val Loss: 0.0571\n",
            "Epoch [43/200], Loss: 0.0991, Val Loss: 0.0581\n",
            "Epoch [44/200], Loss: 0.0983, Val Loss: 0.0584\n",
            "Epoch [45/200], Loss: 0.0985, Val Loss: 0.0583\n",
            "Epoch [46/200], Loss: 0.0983, Val Loss: 0.0595\n",
            "Epoch [47/200], Loss: 0.0981, Val Loss: 0.0577\n",
            "Epoch [48/200], Loss: 0.0974, Val Loss: 0.0591\n",
            "Epoch [49/200], Loss: 0.0981, Val Loss: 0.0613\n",
            "Epoch [50/200], Loss: 0.0979, Val Loss: 0.0570\n",
            "Epoch [51/200], Loss: 0.0976, Val Loss: 0.0589\n",
            "Epoch [52/200], Loss: 0.0979, Val Loss: 0.0581\n",
            "Epoch [53/200], Loss: 0.0970, Val Loss: 0.0600\n",
            "Epoch [54/200], Loss: 0.0971, Val Loss: 0.0590\n",
            "Epoch [55/200], Loss: 0.0980, Val Loss: 0.0567\n",
            "Epoch [56/200], Loss: 0.0974, Val Loss: 0.0575\n",
            "Epoch [57/200], Loss: 0.0966, Val Loss: 0.0587\n",
            "Epoch [58/200], Loss: 0.0970, Val Loss: 0.0597\n",
            "Epoch [59/200], Loss: 0.0969, Val Loss: 0.0568\n",
            "Epoch [60/200], Loss: 0.0967, Val Loss: 0.0574\n",
            "Epoch [61/200], Loss: 0.0968, Val Loss: 0.0577\n",
            "Epoch [62/200], Loss: 0.0967, Val Loss: 0.0578\n",
            "Epoch [63/200], Loss: 0.0974, Val Loss: 0.0595\n",
            "Epoch [64/200], Loss: 0.0973, Val Loss: 0.0567\n",
            "Epoch [65/200], Loss: 0.0966, Val Loss: 0.0606\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1873, Val Loss: 0.0778\n",
            "Epoch [2/200], Loss: 0.1340, Val Loss: 0.0766\n",
            "Epoch [3/200], Loss: 0.1286, Val Loss: 0.0732\n",
            "Epoch [4/200], Loss: 0.1246, Val Loss: 0.0715\n",
            "Epoch [5/200], Loss: 0.1221, Val Loss: 0.0725\n",
            "Epoch [6/200], Loss: 0.1207, Val Loss: 0.0734\n",
            "Epoch [7/200], Loss: 0.1188, Val Loss: 0.0718\n",
            "Epoch [8/200], Loss: 0.1177, Val Loss: 0.0702\n",
            "Epoch [9/200], Loss: 0.1174, Val Loss: 0.0679\n",
            "Epoch [10/200], Loss: 0.1152, Val Loss: 0.0633\n",
            "Epoch [11/200], Loss: 0.1138, Val Loss: 0.0628\n",
            "Epoch [12/200], Loss: 0.1128, Val Loss: 0.0598\n",
            "Epoch [13/200], Loss: 0.1123, Val Loss: 0.0586\n",
            "Epoch [14/200], Loss: 0.1114, Val Loss: 0.0599\n",
            "Epoch [15/200], Loss: 0.1098, Val Loss: 0.0600\n",
            "Epoch [16/200], Loss: 0.1102, Val Loss: 0.0596\n",
            "Epoch [17/200], Loss: 0.1086, Val Loss: 0.0571\n",
            "Epoch [18/200], Loss: 0.1070, Val Loss: 0.0548\n",
            "Epoch [19/200], Loss: 0.1052, Val Loss: 0.0539\n",
            "Epoch [20/200], Loss: 0.1034, Val Loss: 0.0534\n",
            "Epoch [21/200], Loss: 0.1023, Val Loss: 0.0571\n",
            "Epoch [22/200], Loss: 0.1001, Val Loss: 0.0499\n",
            "Epoch [23/200], Loss: 0.0996, Val Loss: 0.0526\n",
            "Epoch [24/200], Loss: 0.0988, Val Loss: 0.0512\n",
            "Epoch [25/200], Loss: 0.0984, Val Loss: 0.0504\n",
            "Epoch [26/200], Loss: 0.0968, Val Loss: 0.0519\n",
            "Epoch [27/200], Loss: 0.0967, Val Loss: 0.0479\n",
            "Epoch [28/200], Loss: 0.0964, Val Loss: 0.0532\n",
            "Epoch [29/200], Loss: 0.0962, Val Loss: 0.0505\n",
            "Epoch [30/200], Loss: 0.0968, Val Loss: 0.0508\n",
            "Epoch [31/200], Loss: 0.0961, Val Loss: 0.0531\n",
            "Epoch [32/200], Loss: 0.0964, Val Loss: 0.0511\n",
            "Epoch [33/200], Loss: 0.0964, Val Loss: 0.0503\n",
            "Epoch [34/200], Loss: 0.0959, Val Loss: 0.0517\n",
            "Epoch [35/200], Loss: 0.0963, Val Loss: 0.0520\n",
            "Epoch [36/200], Loss: 0.0964, Val Loss: 0.0477\n",
            "Epoch [37/200], Loss: 0.0959, Val Loss: 0.0507\n",
            "Epoch [38/200], Loss: 0.0956, Val Loss: 0.0490\n",
            "Epoch [39/200], Loss: 0.0958, Val Loss: 0.0516\n",
            "Epoch [40/200], Loss: 0.0946, Val Loss: 0.0479\n",
            "Epoch [41/200], Loss: 0.0961, Val Loss: 0.0515\n",
            "Epoch [42/200], Loss: 0.0958, Val Loss: 0.0501\n",
            "Epoch [43/200], Loss: 0.0957, Val Loss: 0.0495\n",
            "Epoch [44/200], Loss: 0.0948, Val Loss: 0.0543\n",
            "Epoch [45/200], Loss: 0.0959, Val Loss: 0.0533\n",
            "Epoch [46/200], Loss: 0.0951, Val Loss: 0.0518\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2112, Val Loss: 0.0966\n",
            "Epoch [2/200], Loss: 0.1431, Val Loss: 0.0835\n",
            "Epoch [3/200], Loss: 0.1334, Val Loss: 0.0799\n",
            "Epoch [4/200], Loss: 0.1293, Val Loss: 0.0796\n",
            "Epoch [5/200], Loss: 0.1265, Val Loss: 0.0783\n",
            "Epoch [6/200], Loss: 0.1245, Val Loss: 0.0777\n",
            "Epoch [7/200], Loss: 0.1226, Val Loss: 0.0785\n",
            "Epoch [8/200], Loss: 0.1212, Val Loss: 0.0770\n",
            "Epoch [9/200], Loss: 0.1196, Val Loss: 0.0758\n",
            "Epoch [10/200], Loss: 0.1187, Val Loss: 0.0745\n",
            "Epoch [11/200], Loss: 0.1175, Val Loss: 0.0733\n",
            "Epoch [12/200], Loss: 0.1156, Val Loss: 0.0714\n",
            "Epoch [13/200], Loss: 0.1153, Val Loss: 0.0735\n",
            "Epoch [14/200], Loss: 0.1148, Val Loss: 0.0731\n",
            "Epoch [15/200], Loss: 0.1132, Val Loss: 0.0727\n",
            "Epoch [16/200], Loss: 0.1125, Val Loss: 0.0711\n",
            "Epoch [17/200], Loss: 0.1125, Val Loss: 0.0728\n",
            "Epoch [18/200], Loss: 0.1118, Val Loss: 0.0704\n",
            "Epoch [19/200], Loss: 0.1116, Val Loss: 0.0722\n",
            "Epoch [20/200], Loss: 0.1099, Val Loss: 0.0702\n",
            "Epoch [21/200], Loss: 0.1090, Val Loss: 0.0726\n",
            "Epoch [22/200], Loss: 0.1095, Val Loss: 0.0704\n",
            "Epoch [23/200], Loss: 0.1072, Val Loss: 0.0690\n",
            "Epoch [24/200], Loss: 0.1073, Val Loss: 0.0712\n",
            "Epoch [25/200], Loss: 0.1063, Val Loss: 0.0698\n",
            "Epoch [26/200], Loss: 0.1061, Val Loss: 0.0684\n",
            "Epoch [27/200], Loss: 0.1051, Val Loss: 0.0687\n",
            "Epoch [28/200], Loss: 0.1046, Val Loss: 0.0694\n",
            "Epoch [29/200], Loss: 0.1040, Val Loss: 0.0684\n",
            "Epoch [30/200], Loss: 0.1034, Val Loss: 0.0681\n",
            "Epoch [31/200], Loss: 0.1040, Val Loss: 0.0653\n",
            "Epoch [32/200], Loss: 0.1023, Val Loss: 0.0620\n",
            "Epoch [33/200], Loss: 0.1001, Val Loss: 0.0595\n",
            "Epoch [34/200], Loss: 0.0982, Val Loss: 0.0588\n",
            "Epoch [35/200], Loss: 0.0986, Val Loss: 0.0562\n",
            "Epoch [36/200], Loss: 0.0977, Val Loss: 0.0564\n",
            "Epoch [37/200], Loss: 0.0977, Val Loss: 0.0574\n",
            "Epoch [38/200], Loss: 0.0967, Val Loss: 0.0570\n",
            "Epoch [39/200], Loss: 0.0965, Val Loss: 0.0554\n",
            "Epoch [40/200], Loss: 0.0956, Val Loss: 0.0553\n",
            "Epoch [41/200], Loss: 0.0952, Val Loss: 0.0531\n",
            "Epoch [42/200], Loss: 0.0953, Val Loss: 0.0559\n",
            "Epoch [43/200], Loss: 0.0946, Val Loss: 0.0553\n",
            "Epoch [44/200], Loss: 0.0946, Val Loss: 0.0541\n",
            "Epoch [45/200], Loss: 0.0942, Val Loss: 0.0559\n",
            "Epoch [46/200], Loss: 0.0938, Val Loss: 0.0549\n",
            "Epoch [47/200], Loss: 0.0938, Val Loss: 0.0562\n",
            "Epoch [48/200], Loss: 0.0935, Val Loss: 0.0549\n",
            "Epoch [49/200], Loss: 0.0934, Val Loss: 0.0542\n",
            "Epoch [50/200], Loss: 0.0935, Val Loss: 0.0522\n",
            "Epoch [51/200], Loss: 0.0931, Val Loss: 0.0552\n",
            "Epoch [52/200], Loss: 0.0929, Val Loss: 0.0526\n",
            "Epoch [53/200], Loss: 0.0936, Val Loss: 0.0539\n",
            "Epoch [54/200], Loss: 0.0933, Val Loss: 0.0542\n",
            "Epoch [55/200], Loss: 0.0924, Val Loss: 0.0538\n",
            "Epoch [56/200], Loss: 0.0921, Val Loss: 0.0527\n",
            "Epoch [57/200], Loss: 0.0909, Val Loss: 0.0492\n",
            "Epoch [58/200], Loss: 0.0901, Val Loss: 0.0480\n",
            "Epoch [59/200], Loss: 0.0890, Val Loss: 0.0486\n",
            "Epoch [60/200], Loss: 0.0889, Val Loss: 0.0471\n",
            "Epoch [61/200], Loss: 0.0888, Val Loss: 0.0456\n",
            "Epoch [62/200], Loss: 0.0882, Val Loss: 0.0441\n",
            "Epoch [63/200], Loss: 0.0872, Val Loss: 0.0441\n",
            "Epoch [64/200], Loss: 0.0865, Val Loss: 0.0441\n",
            "Epoch [65/200], Loss: 0.0869, Val Loss: 0.0430\n",
            "Epoch [66/200], Loss: 0.0868, Val Loss: 0.0435\n",
            "Epoch [67/200], Loss: 0.0863, Val Loss: 0.0432\n",
            "Epoch [68/200], Loss: 0.0862, Val Loss: 0.0440\n",
            "Epoch [69/200], Loss: 0.0858, Val Loss: 0.0443\n",
            "Epoch [70/200], Loss: 0.0852, Val Loss: 0.0434\n",
            "Epoch [71/200], Loss: 0.0849, Val Loss: 0.0426\n",
            "Epoch [72/200], Loss: 0.0855, Val Loss: 0.0438\n",
            "Epoch [73/200], Loss: 0.0857, Val Loss: 0.0409\n",
            "Epoch [74/200], Loss: 0.0847, Val Loss: 0.0434\n",
            "Epoch [75/200], Loss: 0.0849, Val Loss: 0.0428\n",
            "Epoch [76/200], Loss: 0.0848, Val Loss: 0.0420\n",
            "Epoch [77/200], Loss: 0.0840, Val Loss: 0.0423\n",
            "Epoch [78/200], Loss: 0.0857, Val Loss: 0.0428\n",
            "Epoch [79/200], Loss: 0.0843, Val Loss: 0.0427\n",
            "Epoch [80/200], Loss: 0.0838, Val Loss: 0.0443\n",
            "Epoch [81/200], Loss: 0.0839, Val Loss: 0.0414\n",
            "Epoch [82/200], Loss: 0.0835, Val Loss: 0.0420\n",
            "Epoch [83/200], Loss: 0.0829, Val Loss: 0.0419\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2059, Val Loss: 0.0868\n",
            "Epoch [2/200], Loss: 0.1405, Val Loss: 0.0805\n",
            "Epoch [3/200], Loss: 0.1321, Val Loss: 0.0823\n",
            "Epoch [4/200], Loss: 0.1289, Val Loss: 0.0774\n",
            "Epoch [5/200], Loss: 0.1261, Val Loss: 0.0780\n",
            "Epoch [6/200], Loss: 0.1235, Val Loss: 0.0773\n",
            "Epoch [7/200], Loss: 0.1219, Val Loss: 0.0762\n",
            "Epoch [8/200], Loss: 0.1204, Val Loss: 0.0786\n",
            "Epoch [9/200], Loss: 0.1190, Val Loss: 0.0749\n",
            "Epoch [10/200], Loss: 0.1167, Val Loss: 0.0752\n",
            "Epoch [11/200], Loss: 0.1159, Val Loss: 0.0747\n",
            "Epoch [12/200], Loss: 0.1146, Val Loss: 0.0768\n",
            "Epoch [13/200], Loss: 0.1135, Val Loss: 0.0745\n",
            "Epoch [14/200], Loss: 0.1128, Val Loss: 0.0753\n",
            "Epoch [15/200], Loss: 0.1124, Val Loss: 0.0737\n",
            "Epoch [16/200], Loss: 0.1114, Val Loss: 0.0747\n",
            "Epoch [17/200], Loss: 0.1107, Val Loss: 0.0744\n",
            "Epoch [18/200], Loss: 0.1095, Val Loss: 0.0717\n",
            "Epoch [19/200], Loss: 0.1089, Val Loss: 0.0714\n",
            "Epoch [20/200], Loss: 0.1083, Val Loss: 0.0747\n",
            "Epoch [21/200], Loss: 0.1072, Val Loss: 0.0700\n",
            "Epoch [22/200], Loss: 0.1069, Val Loss: 0.0715\n",
            "Epoch [23/200], Loss: 0.1068, Val Loss: 0.0733\n",
            "Epoch [24/200], Loss: 0.1073, Val Loss: 0.0742\n",
            "Epoch [25/200], Loss: 0.1065, Val Loss: 0.0732\n",
            "Epoch [26/200], Loss: 0.1051, Val Loss: 0.0726\n",
            "Epoch [27/200], Loss: 0.1060, Val Loss: 0.0741\n",
            "Epoch [28/200], Loss: 0.1058, Val Loss: 0.0741\n",
            "Epoch [29/200], Loss: 0.1051, Val Loss: 0.0746\n",
            "Epoch [30/200], Loss: 0.1047, Val Loss: 0.0741\n",
            "Epoch [31/200], Loss: 0.1047, Val Loss: 0.0749\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=32, BS=32, Dropout=0.1, EncDim=8 -> MAE=0.1415, Error%=413915373.4726\n",
            "Running: LR=0.001, HS=32, BS=32, Dropout=0.2, EncDim=8\n",
            "68 / 81 completed\n",
            "Epoch [1/200], Loss: 0.2721, Val Loss: 0.1458\n",
            "Epoch [2/200], Loss: 0.2113, Val Loss: 0.1414\n",
            "Epoch [3/200], Loss: 0.2022, Val Loss: 0.1342\n",
            "Epoch [4/200], Loss: 0.1968, Val Loss: 0.1298\n",
            "Epoch [5/200], Loss: 0.1935, Val Loss: 0.1290\n",
            "Epoch [6/200], Loss: 0.1887, Val Loss: 0.1221\n",
            "Epoch [7/200], Loss: 0.1861, Val Loss: 0.1163\n",
            "Epoch [8/200], Loss: 0.1836, Val Loss: 0.1172\n",
            "Epoch [9/200], Loss: 0.1795, Val Loss: 0.1127\n",
            "Epoch [10/200], Loss: 0.1783, Val Loss: 0.1124\n",
            "Epoch [11/200], Loss: 0.1759, Val Loss: 0.1131\n",
            "Epoch [12/200], Loss: 0.1744, Val Loss: 0.1100\n",
            "Epoch [13/200], Loss: 0.1723, Val Loss: 0.1092\n",
            "Epoch [14/200], Loss: 0.1713, Val Loss: 0.1102\n",
            "Epoch [15/200], Loss: 0.1688, Val Loss: 0.1073\n",
            "Epoch [16/200], Loss: 0.1684, Val Loss: 0.1065\n",
            "Epoch [17/200], Loss: 0.1678, Val Loss: 0.1064\n",
            "Epoch [18/200], Loss: 0.1658, Val Loss: 0.1064\n",
            "Epoch [19/200], Loss: 0.1656, Val Loss: 0.1054\n",
            "Epoch [20/200], Loss: 0.1653, Val Loss: 0.1038\n",
            "Epoch [21/200], Loss: 0.1639, Val Loss: 0.1051\n",
            "Epoch [22/200], Loss: 0.1629, Val Loss: 0.1055\n",
            "Epoch [23/200], Loss: 0.1629, Val Loss: 0.1030\n",
            "Epoch [24/200], Loss: 0.1634, Val Loss: 0.1035\n",
            "Epoch [25/200], Loss: 0.1630, Val Loss: 0.1046\n",
            "Epoch [26/200], Loss: 0.1634, Val Loss: 0.1019\n",
            "Epoch [27/200], Loss: 0.1626, Val Loss: 0.1046\n",
            "Epoch [28/200], Loss: 0.1617, Val Loss: 0.1038\n",
            "Epoch [29/200], Loss: 0.1621, Val Loss: 0.1052\n",
            "Epoch [30/200], Loss: 0.1612, Val Loss: 0.1019\n",
            "Epoch [31/200], Loss: 0.1605, Val Loss: 0.1044\n",
            "Epoch [32/200], Loss: 0.1618, Val Loss: 0.0993\n",
            "Epoch [33/200], Loss: 0.1605, Val Loss: 0.1032\n",
            "Epoch [34/200], Loss: 0.1591, Val Loss: 0.1004\n",
            "Epoch [35/200], Loss: 0.1593, Val Loss: 0.1012\n",
            "Epoch [36/200], Loss: 0.1596, Val Loss: 0.1009\n",
            "Epoch [37/200], Loss: 0.1596, Val Loss: 0.0989\n",
            "Epoch [38/200], Loss: 0.1596, Val Loss: 0.0984\n",
            "Epoch [39/200], Loss: 0.1583, Val Loss: 0.0984\n",
            "Epoch [40/200], Loss: 0.1588, Val Loss: 0.0961\n",
            "Epoch [41/200], Loss: 0.1589, Val Loss: 0.1014\n",
            "Epoch [42/200], Loss: 0.1591, Val Loss: 0.0965\n",
            "Epoch [43/200], Loss: 0.1587, Val Loss: 0.0957\n",
            "Epoch [44/200], Loss: 0.1585, Val Loss: 0.0977\n",
            "Epoch [45/200], Loss: 0.1566, Val Loss: 0.0973\n",
            "Epoch [46/200], Loss: 0.1582, Val Loss: 0.0966\n",
            "Epoch [47/200], Loss: 0.1586, Val Loss: 0.0980\n",
            "Epoch [48/200], Loss: 0.1582, Val Loss: 0.0959\n",
            "Epoch [49/200], Loss: 0.1581, Val Loss: 0.0975\n",
            "Epoch [50/200], Loss: 0.1581, Val Loss: 0.0955\n",
            "Epoch [51/200], Loss: 0.1583, Val Loss: 0.0995\n",
            "Epoch [52/200], Loss: 0.1580, Val Loss: 0.0956\n",
            "Epoch [53/200], Loss: 0.1582, Val Loss: 0.0972\n",
            "Epoch [54/200], Loss: 0.1574, Val Loss: 0.0975\n",
            "Epoch [55/200], Loss: 0.1579, Val Loss: 0.0934\n",
            "Epoch [56/200], Loss: 0.1563, Val Loss: 0.0938\n",
            "Epoch [57/200], Loss: 0.1570, Val Loss: 0.0949\n",
            "Epoch [58/200], Loss: 0.1571, Val Loss: 0.0956\n",
            "Epoch [59/200], Loss: 0.1568, Val Loss: 0.0954\n",
            "Epoch [60/200], Loss: 0.1577, Val Loss: 0.0981\n",
            "Epoch [61/200], Loss: 0.1570, Val Loss: 0.0944\n",
            "Epoch [62/200], Loss: 0.1559, Val Loss: 0.0972\n",
            "Epoch [63/200], Loss: 0.1562, Val Loss: 0.0952\n",
            "Epoch [64/200], Loss: 0.1571, Val Loss: 0.0946\n",
            "Epoch [65/200], Loss: 0.1565, Val Loss: 0.0961\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2738, Val Loss: 0.1422\n",
            "Epoch [2/200], Loss: 0.2088, Val Loss: 0.1200\n",
            "Epoch [3/200], Loss: 0.1956, Val Loss: 0.1167\n",
            "Epoch [4/200], Loss: 0.1901, Val Loss: 0.1163\n",
            "Epoch [5/200], Loss: 0.1878, Val Loss: 0.1096\n",
            "Epoch [6/200], Loss: 0.1854, Val Loss: 0.1085\n",
            "Epoch [7/200], Loss: 0.1840, Val Loss: 0.1079\n",
            "Epoch [8/200], Loss: 0.1828, Val Loss: 0.1067\n",
            "Epoch [9/200], Loss: 0.1815, Val Loss: 0.1081\n",
            "Epoch [10/200], Loss: 0.1795, Val Loss: 0.1045\n",
            "Epoch [11/200], Loss: 0.1794, Val Loss: 0.1117\n",
            "Epoch [12/200], Loss: 0.1780, Val Loss: 0.1120\n",
            "Epoch [13/200], Loss: 0.1767, Val Loss: 0.1044\n",
            "Epoch [14/200], Loss: 0.1775, Val Loss: 0.1082\n",
            "Epoch [15/200], Loss: 0.1768, Val Loss: 0.1082\n",
            "Epoch [16/200], Loss: 0.1768, Val Loss: 0.1049\n",
            "Epoch [17/200], Loss: 0.1750, Val Loss: 0.1068\n",
            "Epoch [18/200], Loss: 0.1748, Val Loss: 0.1006\n",
            "Epoch [19/200], Loss: 0.1736, Val Loss: 0.1019\n",
            "Epoch [20/200], Loss: 0.1728, Val Loss: 0.1010\n",
            "Epoch [21/200], Loss: 0.1731, Val Loss: 0.1002\n",
            "Epoch [22/200], Loss: 0.1719, Val Loss: 0.1026\n",
            "Epoch [23/200], Loss: 0.1719, Val Loss: 0.1001\n",
            "Epoch [24/200], Loss: 0.1714, Val Loss: 0.0987\n",
            "Epoch [25/200], Loss: 0.1696, Val Loss: 0.1006\n",
            "Epoch [26/200], Loss: 0.1706, Val Loss: 0.1024\n",
            "Epoch [27/200], Loss: 0.1703, Val Loss: 0.0978\n",
            "Epoch [28/200], Loss: 0.1684, Val Loss: 0.0979\n",
            "Epoch [29/200], Loss: 0.1680, Val Loss: 0.0994\n",
            "Epoch [30/200], Loss: 0.1671, Val Loss: 0.0975\n",
            "Epoch [31/200], Loss: 0.1661, Val Loss: 0.0998\n",
            "Epoch [32/200], Loss: 0.1656, Val Loss: 0.0965\n",
            "Epoch [33/200], Loss: 0.1662, Val Loss: 0.0967\n",
            "Epoch [34/200], Loss: 0.1646, Val Loss: 0.0969\n",
            "Epoch [35/200], Loss: 0.1643, Val Loss: 0.0979\n",
            "Epoch [36/200], Loss: 0.1643, Val Loss: 0.0976\n",
            "Epoch [37/200], Loss: 0.1644, Val Loss: 0.0979\n",
            "Epoch [38/200], Loss: 0.1642, Val Loss: 0.0973\n",
            "Epoch [39/200], Loss: 0.1631, Val Loss: 0.0968\n",
            "Epoch [40/200], Loss: 0.1632, Val Loss: 0.0967\n",
            "Epoch [41/200], Loss: 0.1627, Val Loss: 0.0972\n",
            "Epoch [42/200], Loss: 0.1629, Val Loss: 0.0958\n",
            "Epoch [43/200], Loss: 0.1626, Val Loss: 0.0971\n",
            "Epoch [44/200], Loss: 0.1628, Val Loss: 0.0948\n",
            "Epoch [45/200], Loss: 0.1629, Val Loss: 0.0961\n",
            "Epoch [46/200], Loss: 0.1623, Val Loss: 0.0964\n",
            "Epoch [47/200], Loss: 0.1623, Val Loss: 0.0957\n",
            "Epoch [48/200], Loss: 0.1621, Val Loss: 0.0949\n",
            "Epoch [49/200], Loss: 0.1623, Val Loss: 0.0964\n",
            "Epoch [50/200], Loss: 0.1605, Val Loss: 0.0967\n",
            "Epoch [51/200], Loss: 0.1615, Val Loss: 0.0952\n",
            "Epoch [52/200], Loss: 0.1606, Val Loss: 0.0935\n",
            "Epoch [53/200], Loss: 0.1628, Val Loss: 0.0939\n",
            "Epoch [54/200], Loss: 0.1604, Val Loss: 0.0987\n",
            "Epoch [55/200], Loss: 0.1623, Val Loss: 0.0938\n",
            "Epoch [56/200], Loss: 0.1607, Val Loss: 0.0917\n",
            "Epoch [57/200], Loss: 0.1600, Val Loss: 0.0956\n",
            "Epoch [58/200], Loss: 0.1624, Val Loss: 0.0950\n",
            "Epoch [59/200], Loss: 0.1611, Val Loss: 0.0962\n",
            "Epoch [60/200], Loss: 0.1612, Val Loss: 0.0942\n",
            "Epoch [61/200], Loss: 0.1606, Val Loss: 0.1014\n",
            "Epoch [62/200], Loss: 0.1605, Val Loss: 0.0956\n",
            "Epoch [63/200], Loss: 0.1605, Val Loss: 0.0950\n",
            "Epoch [64/200], Loss: 0.1618, Val Loss: 0.0947\n",
            "Epoch [65/200], Loss: 0.1605, Val Loss: 0.0954\n",
            "Epoch [66/200], Loss: 0.1586, Val Loss: 0.0928\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2643, Val Loss: 0.1384\n",
            "Epoch [2/200], Loss: 0.2031, Val Loss: 0.1226\n",
            "Epoch [3/200], Loss: 0.1935, Val Loss: 0.1150\n",
            "Epoch [4/200], Loss: 0.1892, Val Loss: 0.1176\n",
            "Epoch [5/200], Loss: 0.1854, Val Loss: 0.1126\n",
            "Epoch [6/200], Loss: 0.1844, Val Loss: 0.1121\n",
            "Epoch [7/200], Loss: 0.1817, Val Loss: 0.1138\n",
            "Epoch [8/200], Loss: 0.1807, Val Loss: 0.1139\n",
            "Epoch [9/200], Loss: 0.1785, Val Loss: 0.1097\n",
            "Epoch [10/200], Loss: 0.1779, Val Loss: 0.1117\n",
            "Epoch [11/200], Loss: 0.1763, Val Loss: 0.1139\n",
            "Epoch [12/200], Loss: 0.1746, Val Loss: 0.1105\n",
            "Epoch [13/200], Loss: 0.1744, Val Loss: 0.1088\n",
            "Epoch [14/200], Loss: 0.1727, Val Loss: 0.1072\n",
            "Epoch [15/200], Loss: 0.1721, Val Loss: 0.1138\n",
            "Epoch [16/200], Loss: 0.1722, Val Loss: 0.1142\n",
            "Epoch [17/200], Loss: 0.1706, Val Loss: 0.1082\n",
            "Epoch [18/200], Loss: 0.1714, Val Loss: 0.1144\n",
            "Epoch [19/200], Loss: 0.1693, Val Loss: 0.1057\n",
            "Epoch [20/200], Loss: 0.1700, Val Loss: 0.1114\n",
            "Epoch [21/200], Loss: 0.1695, Val Loss: 0.1048\n",
            "Epoch [22/200], Loss: 0.1690, Val Loss: 0.1057\n",
            "Epoch [23/200], Loss: 0.1682, Val Loss: 0.1085\n",
            "Epoch [24/200], Loss: 0.1672, Val Loss: 0.1123\n",
            "Epoch [25/200], Loss: 0.1675, Val Loss: 0.1035\n",
            "Epoch [26/200], Loss: 0.1676, Val Loss: 0.1053\n",
            "Epoch [27/200], Loss: 0.1674, Val Loss: 0.1034\n",
            "Epoch [28/200], Loss: 0.1681, Val Loss: 0.1020\n",
            "Epoch [29/200], Loss: 0.1662, Val Loss: 0.1020\n",
            "Epoch [30/200], Loss: 0.1663, Val Loss: 0.1018\n",
            "Epoch [31/200], Loss: 0.1663, Val Loss: 0.1070\n",
            "Epoch [32/200], Loss: 0.1661, Val Loss: 0.1049\n",
            "Epoch [33/200], Loss: 0.1657, Val Loss: 0.1029\n",
            "Epoch [34/200], Loss: 0.1661, Val Loss: 0.1082\n",
            "Epoch [35/200], Loss: 0.1650, Val Loss: 0.1001\n",
            "Epoch [36/200], Loss: 0.1659, Val Loss: 0.1081\n",
            "Epoch [37/200], Loss: 0.1659, Val Loss: 0.1059\n",
            "Epoch [38/200], Loss: 0.1654, Val Loss: 0.1008\n",
            "Epoch [39/200], Loss: 0.1656, Val Loss: 0.1026\n",
            "Epoch [40/200], Loss: 0.1648, Val Loss: 0.1026\n",
            "Epoch [41/200], Loss: 0.1650, Val Loss: 0.1042\n",
            "Epoch [42/200], Loss: 0.1647, Val Loss: 0.1076\n",
            "Epoch [43/200], Loss: 0.1652, Val Loss: 0.1045\n",
            "Epoch [44/200], Loss: 0.1658, Val Loss: 0.1028\n",
            "Epoch [45/200], Loss: 0.1657, Val Loss: 0.1037\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2737, Val Loss: 0.1526\n",
            "Epoch [2/200], Loss: 0.2143, Val Loss: 0.1511\n",
            "Epoch [3/200], Loss: 0.2076, Val Loss: 0.1463\n",
            "Epoch [4/200], Loss: 0.2030, Val Loss: 0.1424\n",
            "Epoch [5/200], Loss: 0.1994, Val Loss: 0.1381\n",
            "Epoch [6/200], Loss: 0.1947, Val Loss: 0.1279\n",
            "Epoch [7/200], Loss: 0.1891, Val Loss: 0.1243\n",
            "Epoch [8/200], Loss: 0.1865, Val Loss: 0.1255\n",
            "Epoch [9/200], Loss: 0.1853, Val Loss: 0.1269\n",
            "Epoch [10/200], Loss: 0.1856, Val Loss: 0.1227\n",
            "Epoch [11/200], Loss: 0.1839, Val Loss: 0.1199\n",
            "Epoch [12/200], Loss: 0.1833, Val Loss: 0.1206\n",
            "Epoch [13/200], Loss: 0.1811, Val Loss: 0.1173\n",
            "Epoch [14/200], Loss: 0.1818, Val Loss: 0.1229\n",
            "Epoch [15/200], Loss: 0.1813, Val Loss: 0.1271\n",
            "Epoch [16/200], Loss: 0.1814, Val Loss: 0.1211\n",
            "Epoch [17/200], Loss: 0.1804, Val Loss: 0.1226\n",
            "Epoch [18/200], Loss: 0.1795, Val Loss: 0.1184\n",
            "Epoch [19/200], Loss: 0.1788, Val Loss: 0.1243\n",
            "Epoch [20/200], Loss: 0.1792, Val Loss: 0.1217\n",
            "Epoch [21/200], Loss: 0.1777, Val Loss: 0.1187\n",
            "Epoch [22/200], Loss: 0.1780, Val Loss: 0.1198\n",
            "Epoch [23/200], Loss: 0.1782, Val Loss: 0.1182\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2692, Val Loss: 0.1518\n",
            "Epoch [2/200], Loss: 0.2119, Val Loss: 0.1374\n",
            "Epoch [3/200], Loss: 0.2037, Val Loss: 0.1378\n",
            "Epoch [4/200], Loss: 0.1971, Val Loss: 0.1305\n",
            "Epoch [5/200], Loss: 0.1906, Val Loss: 0.1216\n",
            "Epoch [6/200], Loss: 0.1863, Val Loss: 0.1146\n",
            "Epoch [7/200], Loss: 0.1833, Val Loss: 0.1117\n",
            "Epoch [8/200], Loss: 0.1809, Val Loss: 0.1166\n",
            "Epoch [9/200], Loss: 0.1799, Val Loss: 0.1092\n",
            "Epoch [10/200], Loss: 0.1790, Val Loss: 0.1122\n",
            "Epoch [11/200], Loss: 0.1786, Val Loss: 0.1094\n",
            "Epoch [12/200], Loss: 0.1769, Val Loss: 0.1133\n",
            "Epoch [13/200], Loss: 0.1753, Val Loss: 0.1130\n",
            "Epoch [14/200], Loss: 0.1753, Val Loss: 0.1119\n",
            "Epoch [15/200], Loss: 0.1750, Val Loss: 0.1115\n",
            "Epoch [16/200], Loss: 0.1741, Val Loss: 0.1145\n",
            "Epoch [17/200], Loss: 0.1725, Val Loss: 0.1140\n",
            "Epoch [18/200], Loss: 0.1727, Val Loss: 0.1171\n",
            "Epoch [19/200], Loss: 0.1715, Val Loss: 0.1189\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=32, BS=32, Dropout=0.2, EncDim=8 -> MAE=0.2061, Error%=560801308.6828\n",
            "Running: LR=0.001, HS=32, BS=64, Dropout=0.0, EncDim=8\n",
            "69 / 81 completed\n",
            "Epoch [1/200], Loss: 0.1357, Val Loss: 0.0364\n",
            "Epoch [2/200], Loss: 0.0221, Val Loss: 0.0158\n",
            "Epoch [3/200], Loss: 0.0111, Val Loss: 0.0096\n",
            "Epoch [4/200], Loss: 0.0087, Val Loss: 0.0086\n",
            "Epoch [5/200], Loss: 0.0081, Val Loss: 0.0077\n",
            "Epoch [6/200], Loss: 0.0068, Val Loss: 0.0060\n",
            "Epoch [7/200], Loss: 0.0050, Val Loss: 0.0049\n",
            "Epoch [8/200], Loss: 0.0046, Val Loss: 0.0047\n",
            "Epoch [9/200], Loss: 0.0045, Val Loss: 0.0046\n",
            "Epoch [10/200], Loss: 0.0044, Val Loss: 0.0045\n",
            "Epoch [11/200], Loss: 0.0044, Val Loss: 0.0044\n",
            "Epoch [12/200], Loss: 0.0043, Val Loss: 0.0046\n",
            "Epoch [13/200], Loss: 0.0043, Val Loss: 0.0045\n",
            "Epoch [14/200], Loss: 0.0042, Val Loss: 0.0044\n",
            "Epoch [15/200], Loss: 0.0042, Val Loss: 0.0042\n",
            "Epoch [16/200], Loss: 0.0042, Val Loss: 0.0044\n",
            "Epoch [17/200], Loss: 0.0041, Val Loss: 0.0044\n",
            "Epoch [18/200], Loss: 0.0041, Val Loss: 0.0042\n",
            "Epoch [19/200], Loss: 0.0041, Val Loss: 0.0042\n",
            "Epoch [20/200], Loss: 0.0040, Val Loss: 0.0042\n",
            "Epoch [21/200], Loss: 0.0040, Val Loss: 0.0042\n",
            "Epoch [22/200], Loss: 0.0040, Val Loss: 0.0040\n",
            "Epoch [23/200], Loss: 0.0040, Val Loss: 0.0040\n",
            "Epoch [24/200], Loss: 0.0040, Val Loss: 0.0040\n",
            "Epoch [25/200], Loss: 0.0039, Val Loss: 0.0037\n",
            "Epoch [26/200], Loss: 0.0033, Val Loss: 0.0030\n",
            "Epoch [27/200], Loss: 0.0026, Val Loss: 0.0024\n",
            "Epoch [28/200], Loss: 0.0023, Val Loss: 0.0023\n",
            "Epoch [29/200], Loss: 0.0022, Val Loss: 0.0021\n",
            "Epoch [30/200], Loss: 0.0021, Val Loss: 0.0023\n",
            "Epoch [31/200], Loss: 0.0020, Val Loss: 0.0020\n",
            "Epoch [32/200], Loss: 0.0020, Val Loss: 0.0020\n",
            "Epoch [33/200], Loss: 0.0020, Val Loss: 0.0020\n",
            "Epoch [34/200], Loss: 0.0020, Val Loss: 0.0022\n",
            "Epoch [35/200], Loss: 0.0019, Val Loss: 0.0020\n",
            "Epoch [36/200], Loss: 0.0019, Val Loss: 0.0019\n",
            "Epoch [37/200], Loss: 0.0019, Val Loss: 0.0020\n",
            "Epoch [38/200], Loss: 0.0019, Val Loss: 0.0019\n",
            "Epoch [39/200], Loss: 0.0019, Val Loss: 0.0018\n",
            "Epoch [40/200], Loss: 0.0019, Val Loss: 0.0020\n",
            "Epoch [41/200], Loss: 0.0019, Val Loss: 0.0020\n",
            "Epoch [42/200], Loss: 0.0018, Val Loss: 0.0020\n",
            "Epoch [43/200], Loss: 0.0018, Val Loss: 0.0019\n",
            "Epoch [44/200], Loss: 0.0018, Val Loss: 0.0020\n",
            "Epoch [45/200], Loss: 0.0018, Val Loss: 0.0021\n",
            "Epoch [46/200], Loss: 0.0018, Val Loss: 0.0018\n",
            "Epoch [47/200], Loss: 0.0018, Val Loss: 0.0019\n",
            "Epoch [48/200], Loss: 0.0018, Val Loss: 0.0019\n",
            "Epoch [49/200], Loss: 0.0018, Val Loss: 0.0018\n",
            "Epoch [50/200], Loss: 0.0017, Val Loss: 0.0017\n",
            "Epoch [51/200], Loss: 0.0017, Val Loss: 0.0018\n",
            "Epoch [52/200], Loss: 0.0017, Val Loss: 0.0017\n",
            "Epoch [53/200], Loss: 0.0017, Val Loss: 0.0017\n",
            "Epoch [54/200], Loss: 0.0017, Val Loss: 0.0019\n",
            "Epoch [55/200], Loss: 0.0017, Val Loss: 0.0018\n",
            "Epoch [56/200], Loss: 0.0017, Val Loss: 0.0018\n",
            "Epoch [57/200], Loss: 0.0017, Val Loss: 0.0018\n",
            "Epoch [58/200], Loss: 0.0017, Val Loss: 0.0018\n",
            "Epoch [59/200], Loss: 0.0017, Val Loss: 0.0017\n",
            "Epoch [60/200], Loss: 0.0017, Val Loss: 0.0018\n",
            "Epoch [61/200], Loss: 0.0017, Val Loss: 0.0018\n",
            "Epoch [62/200], Loss: 0.0017, Val Loss: 0.0018\n",
            "Epoch [63/200], Loss: 0.0017, Val Loss: 0.0016\n",
            "Epoch [64/200], Loss: 0.0017, Val Loss: 0.0018\n",
            "Epoch [65/200], Loss: 0.0017, Val Loss: 0.0017\n",
            "Epoch [66/200], Loss: 0.0016, Val Loss: 0.0018\n",
            "Epoch [67/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [68/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [69/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [70/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [71/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [72/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [73/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [74/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [75/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [76/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [77/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [78/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [79/200], Loss: 0.0016, Val Loss: 0.0018\n",
            "Epoch [80/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [81/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [82/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [83/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [84/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [85/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [86/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [87/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [88/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [89/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [90/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [91/200], Loss: 0.0016, Val Loss: 0.0015\n",
            "Epoch [92/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [93/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [94/200], Loss: 0.0016, Val Loss: 0.0017\n",
            "Epoch [95/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [96/200], Loss: 0.0016, Val Loss: 0.0015\n",
            "Epoch [97/200], Loss: 0.0015, Val Loss: 0.0019\n",
            "Epoch [98/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [99/200], Loss: 0.0015, Val Loss: 0.0015\n",
            "Epoch [100/200], Loss: 0.0015, Val Loss: 0.0015\n",
            "Epoch [101/200], Loss: 0.0015, Val Loss: 0.0015\n",
            "Epoch [102/200], Loss: 0.0015, Val Loss: 0.0016\n",
            "Epoch [103/200], Loss: 0.0015, Val Loss: 0.0015\n",
            "Epoch [104/200], Loss: 0.0015, Val Loss: 0.0017\n",
            "Epoch [105/200], Loss: 0.0015, Val Loss: 0.0016\n",
            "Epoch [106/200], Loss: 0.0015, Val Loss: 0.0015\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1188, Val Loss: 0.0279\n",
            "Epoch [2/200], Loss: 0.0251, Val Loss: 0.0207\n",
            "Epoch [3/200], Loss: 0.0182, Val Loss: 0.0171\n",
            "Epoch [4/200], Loss: 0.0166, Val Loss: 0.0161\n",
            "Epoch [5/200], Loss: 0.0158, Val Loss: 0.0151\n",
            "Epoch [6/200], Loss: 0.0148, Val Loss: 0.0143\n",
            "Epoch [7/200], Loss: 0.0140, Val Loss: 0.0139\n",
            "Epoch [8/200], Loss: 0.0136, Val Loss: 0.0140\n",
            "Epoch [9/200], Loss: 0.0131, Val Loss: 0.0122\n",
            "Epoch [10/200], Loss: 0.0077, Val Loss: 0.0061\n",
            "Epoch [11/200], Loss: 0.0052, Val Loss: 0.0052\n",
            "Epoch [12/200], Loss: 0.0048, Val Loss: 0.0050\n",
            "Epoch [13/200], Loss: 0.0045, Val Loss: 0.0044\n",
            "Epoch [14/200], Loss: 0.0042, Val Loss: 0.0042\n",
            "Epoch [15/200], Loss: 0.0028, Val Loss: 0.0019\n",
            "Epoch [16/200], Loss: 0.0019, Val Loss: 0.0016\n",
            "Epoch [17/200], Loss: 0.0017, Val Loss: 0.0016\n",
            "Epoch [18/200], Loss: 0.0016, Val Loss: 0.0015\n",
            "Epoch [19/200], Loss: 0.0015, Val Loss: 0.0013\n",
            "Epoch [20/200], Loss: 0.0014, Val Loss: 0.0014\n",
            "Epoch [21/200], Loss: 0.0014, Val Loss: 0.0015\n",
            "Epoch [22/200], Loss: 0.0013, Val Loss: 0.0012\n",
            "Epoch [23/200], Loss: 0.0012, Val Loss: 0.0012\n",
            "Epoch [24/200], Loss: 0.0012, Val Loss: 0.0012\n",
            "Epoch [25/200], Loss: 0.0011, Val Loss: 0.0012\n",
            "Epoch [26/200], Loss: 0.0011, Val Loss: 0.0010\n",
            "Epoch [27/200], Loss: 0.0011, Val Loss: 0.0009\n",
            "Epoch [28/200], Loss: 0.0010, Val Loss: 0.0009\n",
            "Epoch [29/200], Loss: 0.0009, Val Loss: 0.0009\n",
            "Epoch [30/200], Loss: 0.0009, Val Loss: 0.0010\n",
            "Epoch [31/200], Loss: 0.0008, Val Loss: 0.0007\n",
            "Epoch [32/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [33/200], Loss: 0.0008, Val Loss: 0.0006\n",
            "Epoch [34/200], Loss: 0.0008, Val Loss: 0.0006\n",
            "Epoch [35/200], Loss: 0.0007, Val Loss: 0.0011\n",
            "Epoch [36/200], Loss: 0.0007, Val Loss: 0.0006\n",
            "Epoch [37/200], Loss: 0.0007, Val Loss: 0.0005\n",
            "Epoch [38/200], Loss: 0.0007, Val Loss: 0.0005\n",
            "Epoch [39/200], Loss: 0.0007, Val Loss: 0.0005\n",
            "Epoch [40/200], Loss: 0.0006, Val Loss: 0.0007\n",
            "Epoch [41/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [42/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [43/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [44/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [45/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [46/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [47/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [48/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [49/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [50/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [51/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [52/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [53/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [54/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [55/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [56/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [57/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [58/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [59/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [60/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [61/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [62/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [63/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [64/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [65/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [66/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [67/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [68/200], Loss: 0.0004, Val Loss: 0.0006\n",
            "Epoch [69/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [70/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [71/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [72/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [73/200], Loss: 0.0004, Val Loss: 0.0006\n",
            "Epoch [74/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [75/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [76/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [77/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [78/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [79/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [80/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [81/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [82/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [83/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [84/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [85/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [86/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [87/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [88/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [89/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [90/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [91/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [92/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [93/200], Loss: 0.0004, Val Loss: 0.0006\n",
            "Epoch [94/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1189, Val Loss: 0.0428\n",
            "Epoch [2/200], Loss: 0.0268, Val Loss: 0.0216\n",
            "Epoch [3/200], Loss: 0.0187, Val Loss: 0.0154\n",
            "Epoch [4/200], Loss: 0.0138, Val Loss: 0.0126\n",
            "Epoch [5/200], Loss: 0.0116, Val Loss: 0.0119\n",
            "Epoch [6/200], Loss: 0.0085, Val Loss: 0.0057\n",
            "Epoch [7/200], Loss: 0.0050, Val Loss: 0.0043\n",
            "Epoch [8/200], Loss: 0.0037, Val Loss: 0.0032\n",
            "Epoch [9/200], Loss: 0.0029, Val Loss: 0.0029\n",
            "Epoch [10/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [11/200], Loss: 0.0025, Val Loss: 0.0024\n",
            "Epoch [12/200], Loss: 0.0024, Val Loss: 0.0024\n",
            "Epoch [13/200], Loss: 0.0022, Val Loss: 0.0023\n",
            "Epoch [14/200], Loss: 0.0020, Val Loss: 0.0021\n",
            "Epoch [15/200], Loss: 0.0019, Val Loss: 0.0020\n",
            "Epoch [16/200], Loss: 0.0018, Val Loss: 0.0017\n",
            "Epoch [17/200], Loss: 0.0017, Val Loss: 0.0016\n",
            "Epoch [18/200], Loss: 0.0016, Val Loss: 0.0018\n",
            "Epoch [19/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [20/200], Loss: 0.0015, Val Loss: 0.0015\n",
            "Epoch [21/200], Loss: 0.0015, Val Loss: 0.0015\n",
            "Epoch [22/200], Loss: 0.0014, Val Loss: 0.0015\n",
            "Epoch [23/200], Loss: 0.0013, Val Loss: 0.0014\n",
            "Epoch [24/200], Loss: 0.0012, Val Loss: 0.0013\n",
            "Epoch [25/200], Loss: 0.0012, Val Loss: 0.0014\n",
            "Epoch [26/200], Loss: 0.0011, Val Loss: 0.0013\n",
            "Epoch [27/200], Loss: 0.0010, Val Loss: 0.0010\n",
            "Epoch [28/200], Loss: 0.0010, Val Loss: 0.0010\n",
            "Epoch [29/200], Loss: 0.0010, Val Loss: 0.0010\n",
            "Epoch [30/200], Loss: 0.0009, Val Loss: 0.0009\n",
            "Epoch [31/200], Loss: 0.0009, Val Loss: 0.0008\n",
            "Epoch [32/200], Loss: 0.0008, Val Loss: 0.0009\n",
            "Epoch [33/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [34/200], Loss: 0.0008, Val Loss: 0.0010\n",
            "Epoch [35/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [36/200], Loss: 0.0007, Val Loss: 0.0009\n",
            "Epoch [37/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [38/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [39/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [40/200], Loss: 0.0006, Val Loss: 0.0007\n",
            "Epoch [41/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [42/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [43/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [44/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [45/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [46/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [47/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [48/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [49/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [50/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [51/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [52/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [53/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [54/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [55/200], Loss: 0.0004, Val Loss: 0.0007\n",
            "Epoch [56/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [57/200], Loss: 0.0004, Val Loss: 0.0006\n",
            "Epoch [58/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [59/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [60/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [61/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [62/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [63/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [64/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [65/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [66/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [67/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [68/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [69/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [70/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [71/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [72/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [73/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [74/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [75/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [76/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [77/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [78/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [79/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [80/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [81/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [82/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [83/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [84/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [85/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [86/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [87/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [88/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [89/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [90/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [91/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [92/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [93/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [94/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [95/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [96/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [97/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [98/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [99/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [100/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [101/200], Loss: 0.0001, Val Loss: 0.0003\n",
            "Epoch [102/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [103/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1181, Val Loss: 0.0340\n",
            "Epoch [2/200], Loss: 0.0238, Val Loss: 0.0211\n",
            "Epoch [3/200], Loss: 0.0207, Val Loss: 0.0198\n",
            "Epoch [4/200], Loss: 0.0179, Val Loss: 0.0137\n",
            "Epoch [5/200], Loss: 0.0133, Val Loss: 0.0127\n",
            "Epoch [6/200], Loss: 0.0106, Val Loss: 0.0085\n",
            "Epoch [7/200], Loss: 0.0083, Val Loss: 0.0079\n",
            "Epoch [8/200], Loss: 0.0079, Val Loss: 0.0076\n",
            "Epoch [9/200], Loss: 0.0078, Val Loss: 0.0078\n",
            "Epoch [10/200], Loss: 0.0077, Val Loss: 0.0079\n",
            "Epoch [11/200], Loss: 0.0065, Val Loss: 0.0048\n",
            "Epoch [12/200], Loss: 0.0044, Val Loss: 0.0045\n",
            "Epoch [13/200], Loss: 0.0043, Val Loss: 0.0044\n",
            "Epoch [14/200], Loss: 0.0041, Val Loss: 0.0042\n",
            "Epoch [15/200], Loss: 0.0040, Val Loss: 0.0040\n",
            "Epoch [16/200], Loss: 0.0039, Val Loss: 0.0041\n",
            "Epoch [17/200], Loss: 0.0039, Val Loss: 0.0041\n",
            "Epoch [18/200], Loss: 0.0039, Val Loss: 0.0038\n",
            "Epoch [19/200], Loss: 0.0037, Val Loss: 0.0037\n",
            "Epoch [20/200], Loss: 0.0037, Val Loss: 0.0037\n",
            "Epoch [21/200], Loss: 0.0038, Val Loss: 0.0038\n",
            "Epoch [22/200], Loss: 0.0036, Val Loss: 0.0038\n",
            "Epoch [23/200], Loss: 0.0036, Val Loss: 0.0038\n",
            "Epoch [24/200], Loss: 0.0036, Val Loss: 0.0036\n",
            "Epoch [25/200], Loss: 0.0036, Val Loss: 0.0037\n",
            "Epoch [26/200], Loss: 0.0036, Val Loss: 0.0036\n",
            "Epoch [27/200], Loss: 0.0036, Val Loss: 0.0036\n",
            "Epoch [28/200], Loss: 0.0036, Val Loss: 0.0036\n",
            "Epoch [29/200], Loss: 0.0035, Val Loss: 0.0036\n",
            "Epoch [30/200], Loss: 0.0036, Val Loss: 0.0035\n",
            "Epoch [31/200], Loss: 0.0035, Val Loss: 0.0035\n",
            "Epoch [32/200], Loss: 0.0035, Val Loss: 0.0035\n",
            "Epoch [33/200], Loss: 0.0035, Val Loss: 0.0036\n",
            "Epoch [34/200], Loss: 0.0035, Val Loss: 0.0035\n",
            "Epoch [35/200], Loss: 0.0035, Val Loss: 0.0035\n",
            "Epoch [36/200], Loss: 0.0035, Val Loss: 0.0036\n",
            "Epoch [37/200], Loss: 0.0034, Val Loss: 0.0036\n",
            "Epoch [38/200], Loss: 0.0034, Val Loss: 0.0038\n",
            "Epoch [39/200], Loss: 0.0034, Val Loss: 0.0035\n",
            "Epoch [40/200], Loss: 0.0034, Val Loss: 0.0034\n",
            "Epoch [41/200], Loss: 0.0033, Val Loss: 0.0035\n",
            "Epoch [42/200], Loss: 0.0033, Val Loss: 0.0035\n",
            "Epoch [43/200], Loss: 0.0033, Val Loss: 0.0035\n",
            "Epoch [44/200], Loss: 0.0033, Val Loss: 0.0034\n",
            "Epoch [45/200], Loss: 0.0033, Val Loss: 0.0035\n",
            "Epoch [46/200], Loss: 0.0033, Val Loss: 0.0033\n",
            "Epoch [47/200], Loss: 0.0032, Val Loss: 0.0033\n",
            "Epoch [48/200], Loss: 0.0032, Val Loss: 0.0033\n",
            "Epoch [49/200], Loss: 0.0031, Val Loss: 0.0032\n",
            "Epoch [50/200], Loss: 0.0031, Val Loss: 0.0035\n",
            "Epoch [51/200], Loss: 0.0031, Val Loss: 0.0032\n",
            "Epoch [52/200], Loss: 0.0030, Val Loss: 0.0032\n",
            "Epoch [53/200], Loss: 0.0030, Val Loss: 0.0031\n",
            "Epoch [54/200], Loss: 0.0030, Val Loss: 0.0031\n",
            "Epoch [55/200], Loss: 0.0030, Val Loss: 0.0034\n",
            "Epoch [56/200], Loss: 0.0030, Val Loss: 0.0031\n",
            "Epoch [57/200], Loss: 0.0030, Val Loss: 0.0032\n",
            "Epoch [58/200], Loss: 0.0029, Val Loss: 0.0032\n",
            "Epoch [59/200], Loss: 0.0030, Val Loss: 0.0030\n",
            "Epoch [60/200], Loss: 0.0029, Val Loss: 0.0029\n",
            "Epoch [61/200], Loss: 0.0029, Val Loss: 0.0029\n",
            "Epoch [62/200], Loss: 0.0029, Val Loss: 0.0030\n",
            "Epoch [63/200], Loss: 0.0029, Val Loss: 0.0030\n",
            "Epoch [64/200], Loss: 0.0028, Val Loss: 0.0030\n",
            "Epoch [65/200], Loss: 0.0028, Val Loss: 0.0030\n",
            "Epoch [66/200], Loss: 0.0028, Val Loss: 0.0029\n",
            "Epoch [67/200], Loss: 0.0028, Val Loss: 0.0028\n",
            "Epoch [68/200], Loss: 0.0028, Val Loss: 0.0030\n",
            "Epoch [69/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Epoch [70/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Epoch [71/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Epoch [72/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Epoch [73/200], Loss: 0.0027, Val Loss: 0.0030\n",
            "Epoch [74/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Epoch [75/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Epoch [76/200], Loss: 0.0027, Val Loss: 0.0029\n",
            "Epoch [77/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [78/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Epoch [79/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Epoch [80/200], Loss: 0.0027, Val Loss: 0.0029\n",
            "Epoch [81/200], Loss: 0.0027, Val Loss: 0.0029\n",
            "Epoch [82/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Epoch [83/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [84/200], Loss: 0.0027, Val Loss: 0.0027\n",
            "Epoch [85/200], Loss: 0.0027, Val Loss: 0.0029\n",
            "Epoch [86/200], Loss: 0.0027, Val Loss: 0.0031\n",
            "Epoch [87/200], Loss: 0.0027, Val Loss: 0.0028\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1313, Val Loss: 0.0289\n",
            "Epoch [2/200], Loss: 0.0243, Val Loss: 0.0205\n",
            "Epoch [3/200], Loss: 0.0174, Val Loss: 0.0142\n",
            "Epoch [4/200], Loss: 0.0110, Val Loss: 0.0087\n",
            "Epoch [5/200], Loss: 0.0076, Val Loss: 0.0071\n",
            "Epoch [6/200], Loss: 0.0062, Val Loss: 0.0059\n",
            "Epoch [7/200], Loss: 0.0050, Val Loss: 0.0043\n",
            "Epoch [8/200], Loss: 0.0038, Val Loss: 0.0038\n",
            "Epoch [9/200], Loss: 0.0032, Val Loss: 0.0031\n",
            "Epoch [10/200], Loss: 0.0028, Val Loss: 0.0030\n",
            "Epoch [11/200], Loss: 0.0026, Val Loss: 0.0025\n",
            "Epoch [12/200], Loss: 0.0022, Val Loss: 0.0020\n",
            "Epoch [13/200], Loss: 0.0020, Val Loss: 0.0021\n",
            "Epoch [14/200], Loss: 0.0016, Val Loss: 0.0015\n",
            "Epoch [15/200], Loss: 0.0014, Val Loss: 0.0014\n",
            "Epoch [16/200], Loss: 0.0012, Val Loss: 0.0012\n",
            "Epoch [17/200], Loss: 0.0011, Val Loss: 0.0011\n",
            "Epoch [18/200], Loss: 0.0010, Val Loss: 0.0009\n",
            "Epoch [19/200], Loss: 0.0009, Val Loss: 0.0008\n",
            "Epoch [20/200], Loss: 0.0008, Val Loss: 0.0007\n",
            "Epoch [21/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [22/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [23/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [24/200], Loss: 0.0006, Val Loss: 0.0008\n",
            "Epoch [25/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [26/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [27/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [28/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [29/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [30/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [31/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [32/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [33/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [34/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [35/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [36/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [37/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [38/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [39/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [40/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [41/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [42/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [43/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [44/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [45/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [46/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [47/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [48/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [49/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [50/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [51/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [52/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [53/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [54/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [55/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [56/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [57/200], Loss: 0.0002, Val Loss: 0.0015\n",
            "Epoch [58/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [59/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [60/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [61/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [62/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [63/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [64/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [65/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [66/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [67/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [68/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [69/200], Loss: 0.0001, Val Loss: 0.0006\n",
            "Epoch [70/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [71/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [72/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [73/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [74/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [75/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [76/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [77/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [78/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [79/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [80/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [81/200], Loss: 0.0001, Val Loss: 0.0004\n",
            "Epoch [82/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [83/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [84/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [85/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [86/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [87/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [88/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [89/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [90/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [91/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [92/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [93/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [94/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [95/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [96/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [97/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [98/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [99/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [100/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [101/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [102/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [103/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [104/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [105/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [106/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [107/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [108/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [109/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [110/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [111/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [112/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [113/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [114/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [115/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [116/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [117/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [118/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [119/200], Loss: 0.0000, Val Loss: 0.0000\n",
            "Epoch [120/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [121/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [122/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [123/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [124/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [125/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [126/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [127/200], Loss: 0.0000, Val Loss: 0.0000\n",
            "Epoch [128/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=32, BS=64, Dropout=0.0, EncDim=8 -> MAE=0.0104, Error%=52866778.0096\n",
            "Running: LR=0.001, HS=32, BS=64, Dropout=0.1, EncDim=8\n",
            "70 / 81 completed\n",
            "Epoch [1/200], Loss: 0.2378, Val Loss: 0.0950\n",
            "Epoch [2/200], Loss: 0.1485, Val Loss: 0.0879\n",
            "Epoch [3/200], Loss: 0.1395, Val Loss: 0.0850\n",
            "Epoch [4/200], Loss: 0.1349, Val Loss: 0.0838\n",
            "Epoch [5/200], Loss: 0.1314, Val Loss: 0.0801\n",
            "Epoch [6/200], Loss: 0.1290, Val Loss: 0.0798\n",
            "Epoch [7/200], Loss: 0.1278, Val Loss: 0.0804\n",
            "Epoch [8/200], Loss: 0.1262, Val Loss: 0.0794\n",
            "Epoch [9/200], Loss: 0.1248, Val Loss: 0.0803\n",
            "Epoch [10/200], Loss: 0.1242, Val Loss: 0.0788\n",
            "Epoch [11/200], Loss: 0.1232, Val Loss: 0.0784\n",
            "Epoch [12/200], Loss: 0.1223, Val Loss: 0.0801\n",
            "Epoch [13/200], Loss: 0.1215, Val Loss: 0.0784\n",
            "Epoch [14/200], Loss: 0.1209, Val Loss: 0.0779\n",
            "Epoch [15/200], Loss: 0.1202, Val Loss: 0.0761\n",
            "Epoch [16/200], Loss: 0.1193, Val Loss: 0.0744\n",
            "Epoch [17/200], Loss: 0.1179, Val Loss: 0.0721\n",
            "Epoch [18/200], Loss: 0.1164, Val Loss: 0.0719\n",
            "Epoch [19/200], Loss: 0.1150, Val Loss: 0.0674\n",
            "Epoch [20/200], Loss: 0.1147, Val Loss: 0.0682\n",
            "Epoch [21/200], Loss: 0.1136, Val Loss: 0.0675\n",
            "Epoch [22/200], Loss: 0.1130, Val Loss: 0.0666\n",
            "Epoch [23/200], Loss: 0.1120, Val Loss: 0.0667\n",
            "Epoch [24/200], Loss: 0.1115, Val Loss: 0.0673\n",
            "Epoch [25/200], Loss: 0.1117, Val Loss: 0.0661\n",
            "Epoch [26/200], Loss: 0.1107, Val Loss: 0.0652\n",
            "Epoch [27/200], Loss: 0.1103, Val Loss: 0.0658\n",
            "Epoch [28/200], Loss: 0.1099, Val Loss: 0.0641\n",
            "Epoch [29/200], Loss: 0.1098, Val Loss: 0.0653\n",
            "Epoch [30/200], Loss: 0.1094, Val Loss: 0.0646\n",
            "Epoch [31/200], Loss: 0.1094, Val Loss: 0.0653\n",
            "Epoch [32/200], Loss: 0.1091, Val Loss: 0.0649\n",
            "Epoch [33/200], Loss: 0.1083, Val Loss: 0.0653\n",
            "Epoch [34/200], Loss: 0.1084, Val Loss: 0.0650\n",
            "Epoch [35/200], Loss: 0.1079, Val Loss: 0.0654\n",
            "Epoch [36/200], Loss: 0.1072, Val Loss: 0.0653\n",
            "Epoch [37/200], Loss: 0.1074, Val Loss: 0.0652\n",
            "Epoch [38/200], Loss: 0.1061, Val Loss: 0.0636\n",
            "Epoch [39/200], Loss: 0.1053, Val Loss: 0.0632\n",
            "Epoch [40/200], Loss: 0.1055, Val Loss: 0.0628\n",
            "Epoch [41/200], Loss: 0.1051, Val Loss: 0.0640\n",
            "Epoch [42/200], Loss: 0.1044, Val Loss: 0.0641\n",
            "Epoch [43/200], Loss: 0.1038, Val Loss: 0.0645\n",
            "Epoch [44/200], Loss: 0.1038, Val Loss: 0.0635\n",
            "Epoch [45/200], Loss: 0.1029, Val Loss: 0.0635\n",
            "Epoch [46/200], Loss: 0.1032, Val Loss: 0.0656\n",
            "Epoch [47/200], Loss: 0.1020, Val Loss: 0.0631\n",
            "Epoch [48/200], Loss: 0.1021, Val Loss: 0.0617\n",
            "Epoch [49/200], Loss: 0.1025, Val Loss: 0.0637\n",
            "Epoch [50/200], Loss: 0.1021, Val Loss: 0.0639\n",
            "Epoch [51/200], Loss: 0.1010, Val Loss: 0.0648\n",
            "Epoch [52/200], Loss: 0.1014, Val Loss: 0.0641\n",
            "Epoch [53/200], Loss: 0.1011, Val Loss: 0.0622\n",
            "Epoch [54/200], Loss: 0.0999, Val Loss: 0.0613\n",
            "Epoch [55/200], Loss: 0.1003, Val Loss: 0.0620\n",
            "Epoch [56/200], Loss: 0.0991, Val Loss: 0.0608\n",
            "Epoch [57/200], Loss: 0.1008, Val Loss: 0.0621\n",
            "Epoch [58/200], Loss: 0.0993, Val Loss: 0.0618\n",
            "Epoch [59/200], Loss: 0.0987, Val Loss: 0.0605\n",
            "Epoch [60/200], Loss: 0.0992, Val Loss: 0.0597\n",
            "Epoch [61/200], Loss: 0.0984, Val Loss: 0.0607\n",
            "Epoch [62/200], Loss: 0.0981, Val Loss: 0.0609\n",
            "Epoch [63/200], Loss: 0.0989, Val Loss: 0.0599\n",
            "Epoch [64/200], Loss: 0.0989, Val Loss: 0.0603\n",
            "Epoch [65/200], Loss: 0.0976, Val Loss: 0.0604\n",
            "Epoch [66/200], Loss: 0.0978, Val Loss: 0.0590\n",
            "Epoch [67/200], Loss: 0.0976, Val Loss: 0.0586\n",
            "Epoch [68/200], Loss: 0.0976, Val Loss: 0.0577\n",
            "Epoch [69/200], Loss: 0.0977, Val Loss: 0.0607\n",
            "Epoch [70/200], Loss: 0.0968, Val Loss: 0.0573\n",
            "Epoch [71/200], Loss: 0.0966, Val Loss: 0.0602\n",
            "Epoch [72/200], Loss: 0.0968, Val Loss: 0.0596\n",
            "Epoch [73/200], Loss: 0.0964, Val Loss: 0.0584\n",
            "Epoch [74/200], Loss: 0.0963, Val Loss: 0.0571\n",
            "Epoch [75/200], Loss: 0.0975, Val Loss: 0.0587\n",
            "Epoch [76/200], Loss: 0.0962, Val Loss: 0.0586\n",
            "Epoch [77/200], Loss: 0.0950, Val Loss: 0.0544\n",
            "Epoch [78/200], Loss: 0.0943, Val Loss: 0.0529\n",
            "Epoch [79/200], Loss: 0.0946, Val Loss: 0.0556\n",
            "Epoch [80/200], Loss: 0.0931, Val Loss: 0.0569\n",
            "Epoch [81/200], Loss: 0.0932, Val Loss: 0.0549\n",
            "Epoch [82/200], Loss: 0.0935, Val Loss: 0.0536\n",
            "Epoch [83/200], Loss: 0.0934, Val Loss: 0.0543\n",
            "Epoch [84/200], Loss: 0.0937, Val Loss: 0.0552\n",
            "Epoch [85/200], Loss: 0.0932, Val Loss: 0.0554\n",
            "Epoch [86/200], Loss: 0.0927, Val Loss: 0.0552\n",
            "Epoch [87/200], Loss: 0.0920, Val Loss: 0.0556\n",
            "Epoch [88/200], Loss: 0.0921, Val Loss: 0.0553\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2211, Val Loss: 0.0880\n",
            "Epoch [2/200], Loss: 0.1421, Val Loss: 0.0851\n",
            "Epoch [3/200], Loss: 0.1354, Val Loss: 0.0838\n",
            "Epoch [4/200], Loss: 0.1308, Val Loss: 0.0782\n",
            "Epoch [5/200], Loss: 0.1289, Val Loss: 0.0787\n",
            "Epoch [6/200], Loss: 0.1263, Val Loss: 0.0766\n",
            "Epoch [7/200], Loss: 0.1253, Val Loss: 0.0768\n",
            "Epoch [8/200], Loss: 0.1240, Val Loss: 0.0778\n",
            "Epoch [9/200], Loss: 0.1233, Val Loss: 0.0756\n",
            "Epoch [10/200], Loss: 0.1225, Val Loss: 0.0771\n",
            "Epoch [11/200], Loss: 0.1220, Val Loss: 0.0765\n",
            "Epoch [12/200], Loss: 0.1207, Val Loss: 0.0765\n",
            "Epoch [13/200], Loss: 0.1202, Val Loss: 0.0739\n",
            "Epoch [14/200], Loss: 0.1198, Val Loss: 0.0743\n",
            "Epoch [15/200], Loss: 0.1186, Val Loss: 0.0748\n",
            "Epoch [16/200], Loss: 0.1181, Val Loss: 0.0781\n",
            "Epoch [17/200], Loss: 0.1173, Val Loss: 0.0752\n",
            "Epoch [18/200], Loss: 0.1167, Val Loss: 0.0779\n",
            "Epoch [19/200], Loss: 0.1157, Val Loss: 0.0780\n",
            "Epoch [20/200], Loss: 0.1157, Val Loss: 0.0759\n",
            "Epoch [21/200], Loss: 0.1153, Val Loss: 0.0756\n",
            "Epoch [22/200], Loss: 0.1138, Val Loss: 0.0763\n",
            "Epoch [23/200], Loss: 0.1127, Val Loss: 0.0772\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2207, Val Loss: 0.0892\n",
            "Epoch [2/200], Loss: 0.1444, Val Loss: 0.0828\n",
            "Epoch [3/200], Loss: 0.1356, Val Loss: 0.0772\n",
            "Epoch [4/200], Loss: 0.1307, Val Loss: 0.0758\n",
            "Epoch [5/200], Loss: 0.1273, Val Loss: 0.0734\n",
            "Epoch [6/200], Loss: 0.1247, Val Loss: 0.0743\n",
            "Epoch [7/200], Loss: 0.1224, Val Loss: 0.0728\n",
            "Epoch [8/200], Loss: 0.1202, Val Loss: 0.0733\n",
            "Epoch [9/200], Loss: 0.1186, Val Loss: 0.0720\n",
            "Epoch [10/200], Loss: 0.1177, Val Loss: 0.0714\n",
            "Epoch [11/200], Loss: 0.1162, Val Loss: 0.0715\n",
            "Epoch [12/200], Loss: 0.1149, Val Loss: 0.0724\n",
            "Epoch [13/200], Loss: 0.1140, Val Loss: 0.0711\n",
            "Epoch [14/200], Loss: 0.1131, Val Loss: 0.0708\n",
            "Epoch [15/200], Loss: 0.1126, Val Loss: 0.0710\n",
            "Epoch [16/200], Loss: 0.1120, Val Loss: 0.0704\n",
            "Epoch [17/200], Loss: 0.1111, Val Loss: 0.0705\n",
            "Epoch [18/200], Loss: 0.1102, Val Loss: 0.0696\n",
            "Epoch [19/200], Loss: 0.1103, Val Loss: 0.0701\n",
            "Epoch [20/200], Loss: 0.1087, Val Loss: 0.0703\n",
            "Epoch [21/200], Loss: 0.1084, Val Loss: 0.0683\n",
            "Epoch [22/200], Loss: 0.1085, Val Loss: 0.0700\n",
            "Epoch [23/200], Loss: 0.1076, Val Loss: 0.0709\n",
            "Epoch [24/200], Loss: 0.1067, Val Loss: 0.0694\n",
            "Epoch [25/200], Loss: 0.1073, Val Loss: 0.0691\n",
            "Epoch [26/200], Loss: 0.1064, Val Loss: 0.0691\n",
            "Epoch [27/200], Loss: 0.1065, Val Loss: 0.0683\n",
            "Epoch [28/200], Loss: 0.1055, Val Loss: 0.0695\n",
            "Epoch [29/200], Loss: 0.1046, Val Loss: 0.0685\n",
            "Epoch [30/200], Loss: 0.1041, Val Loss: 0.0683\n",
            "Epoch [31/200], Loss: 0.1043, Val Loss: 0.0696\n",
            "Epoch [32/200], Loss: 0.1027, Val Loss: 0.0670\n",
            "Epoch [33/200], Loss: 0.1033, Val Loss: 0.0672\n",
            "Epoch [34/200], Loss: 0.1028, Val Loss: 0.0699\n",
            "Epoch [35/200], Loss: 0.1028, Val Loss: 0.0683\n",
            "Epoch [36/200], Loss: 0.1022, Val Loss: 0.0675\n",
            "Epoch [37/200], Loss: 0.1027, Val Loss: 0.0693\n",
            "Epoch [38/200], Loss: 0.1020, Val Loss: 0.0674\n",
            "Epoch [39/200], Loss: 0.1018, Val Loss: 0.0638\n",
            "Epoch [40/200], Loss: 0.1007, Val Loss: 0.0629\n",
            "Epoch [41/200], Loss: 0.1005, Val Loss: 0.0628\n",
            "Epoch [42/200], Loss: 0.0994, Val Loss: 0.0638\n",
            "Epoch [43/200], Loss: 0.0994, Val Loss: 0.0591\n",
            "Epoch [44/200], Loss: 0.0995, Val Loss: 0.0585\n",
            "Epoch [45/200], Loss: 0.0980, Val Loss: 0.0558\n",
            "Epoch [46/200], Loss: 0.0971, Val Loss: 0.0553\n",
            "Epoch [47/200], Loss: 0.0964, Val Loss: 0.0540\n",
            "Epoch [48/200], Loss: 0.0972, Val Loss: 0.0539\n",
            "Epoch [49/200], Loss: 0.0966, Val Loss: 0.0526\n",
            "Epoch [50/200], Loss: 0.0963, Val Loss: 0.0523\n",
            "Epoch [51/200], Loss: 0.0954, Val Loss: 0.0511\n",
            "Epoch [52/200], Loss: 0.0949, Val Loss: 0.0513\n",
            "Epoch [53/200], Loss: 0.0940, Val Loss: 0.0510\n",
            "Epoch [54/200], Loss: 0.0937, Val Loss: 0.0520\n",
            "Epoch [55/200], Loss: 0.0936, Val Loss: 0.0496\n",
            "Epoch [56/200], Loss: 0.0934, Val Loss: 0.0523\n",
            "Epoch [57/200], Loss: 0.0930, Val Loss: 0.0484\n",
            "Epoch [58/200], Loss: 0.0929, Val Loss: 0.0486\n",
            "Epoch [59/200], Loss: 0.0923, Val Loss: 0.0510\n",
            "Epoch [60/200], Loss: 0.0917, Val Loss: 0.0510\n",
            "Epoch [61/200], Loss: 0.0917, Val Loss: 0.0521\n",
            "Epoch [62/200], Loss: 0.0915, Val Loss: 0.0510\n",
            "Epoch [63/200], Loss: 0.0914, Val Loss: 0.0502\n",
            "Epoch [64/200], Loss: 0.0909, Val Loss: 0.0490\n",
            "Epoch [65/200], Loss: 0.0905, Val Loss: 0.0492\n",
            "Epoch [66/200], Loss: 0.0910, Val Loss: 0.0493\n",
            "Epoch [67/200], Loss: 0.0915, Val Loss: 0.0491\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2349, Val Loss: 0.0978\n",
            "Epoch [2/200], Loss: 0.1484, Val Loss: 0.0835\n",
            "Epoch [3/200], Loss: 0.1374, Val Loss: 0.0808\n",
            "Epoch [4/200], Loss: 0.1336, Val Loss: 0.0800\n",
            "Epoch [5/200], Loss: 0.1311, Val Loss: 0.0806\n",
            "Epoch [6/200], Loss: 0.1287, Val Loss: 0.0797\n",
            "Epoch [7/200], Loss: 0.1275, Val Loss: 0.0814\n",
            "Epoch [8/200], Loss: 0.1253, Val Loss: 0.0791\n",
            "Epoch [9/200], Loss: 0.1248, Val Loss: 0.0787\n",
            "Epoch [10/200], Loss: 0.1245, Val Loss: 0.0768\n",
            "Epoch [11/200], Loss: 0.1227, Val Loss: 0.0766\n",
            "Epoch [12/200], Loss: 0.1224, Val Loss: 0.0754\n",
            "Epoch [13/200], Loss: 0.1211, Val Loss: 0.0753\n",
            "Epoch [14/200], Loss: 0.1205, Val Loss: 0.0756\n",
            "Epoch [15/200], Loss: 0.1197, Val Loss: 0.0763\n",
            "Epoch [16/200], Loss: 0.1188, Val Loss: 0.0749\n",
            "Epoch [17/200], Loss: 0.1182, Val Loss: 0.0741\n",
            "Epoch [18/200], Loss: 0.1180, Val Loss: 0.0747\n",
            "Epoch [19/200], Loss: 0.1173, Val Loss: 0.0737\n",
            "Epoch [20/200], Loss: 0.1169, Val Loss: 0.0747\n",
            "Epoch [21/200], Loss: 0.1156, Val Loss: 0.0702\n",
            "Epoch [22/200], Loss: 0.1142, Val Loss: 0.0665\n",
            "Epoch [23/200], Loss: 0.1138, Val Loss: 0.0661\n",
            "Epoch [24/200], Loss: 0.1132, Val Loss: 0.0655\n",
            "Epoch [25/200], Loss: 0.1117, Val Loss: 0.0668\n",
            "Epoch [26/200], Loss: 0.1112, Val Loss: 0.0659\n",
            "Epoch [27/200], Loss: 0.1104, Val Loss: 0.0630\n",
            "Epoch [28/200], Loss: 0.1096, Val Loss: 0.0641\n",
            "Epoch [29/200], Loss: 0.1083, Val Loss: 0.0629\n",
            "Epoch [30/200], Loss: 0.1079, Val Loss: 0.0635\n",
            "Epoch [31/200], Loss: 0.1071, Val Loss: 0.0633\n",
            "Epoch [32/200], Loss: 0.1067, Val Loss: 0.0618\n",
            "Epoch [33/200], Loss: 0.1053, Val Loss: 0.0614\n",
            "Epoch [34/200], Loss: 0.1062, Val Loss: 0.0625\n",
            "Epoch [35/200], Loss: 0.1054, Val Loss: 0.0603\n",
            "Epoch [36/200], Loss: 0.1043, Val Loss: 0.0624\n",
            "Epoch [37/200], Loss: 0.1038, Val Loss: 0.0609\n",
            "Epoch [38/200], Loss: 0.1041, Val Loss: 0.0608\n",
            "Epoch [39/200], Loss: 0.1033, Val Loss: 0.0617\n",
            "Epoch [40/200], Loss: 0.1031, Val Loss: 0.0599\n",
            "Epoch [41/200], Loss: 0.1026, Val Loss: 0.0596\n",
            "Epoch [42/200], Loss: 0.1019, Val Loss: 0.0585\n",
            "Epoch [43/200], Loss: 0.1008, Val Loss: 0.0593\n",
            "Epoch [44/200], Loss: 0.0992, Val Loss: 0.0568\n",
            "Epoch [45/200], Loss: 0.0992, Val Loss: 0.0558\n",
            "Epoch [46/200], Loss: 0.0978, Val Loss: 0.0547\n",
            "Epoch [47/200], Loss: 0.0976, Val Loss: 0.0536\n",
            "Epoch [48/200], Loss: 0.0965, Val Loss: 0.0524\n",
            "Epoch [49/200], Loss: 0.0953, Val Loss: 0.0512\n",
            "Epoch [50/200], Loss: 0.0944, Val Loss: 0.0520\n",
            "Epoch [51/200], Loss: 0.0927, Val Loss: 0.0523\n",
            "Epoch [52/200], Loss: 0.0922, Val Loss: 0.0519\n",
            "Epoch [53/200], Loss: 0.0921, Val Loss: 0.0510\n",
            "Epoch [54/200], Loss: 0.0917, Val Loss: 0.0490\n",
            "Epoch [55/200], Loss: 0.0909, Val Loss: 0.0496\n",
            "Epoch [56/200], Loss: 0.0906, Val Loss: 0.0519\n",
            "Epoch [57/200], Loss: 0.0894, Val Loss: 0.0530\n",
            "Epoch [58/200], Loss: 0.0889, Val Loss: 0.0506\n",
            "Epoch [59/200], Loss: 0.0881, Val Loss: 0.0477\n",
            "Epoch [60/200], Loss: 0.0884, Val Loss: 0.0505\n",
            "Epoch [61/200], Loss: 0.0875, Val Loss: 0.0471\n",
            "Epoch [62/200], Loss: 0.0870, Val Loss: 0.0485\n",
            "Epoch [63/200], Loss: 0.0883, Val Loss: 0.0505\n",
            "Epoch [64/200], Loss: 0.0867, Val Loss: 0.0505\n",
            "Epoch [65/200], Loss: 0.0859, Val Loss: 0.0517\n",
            "Epoch [66/200], Loss: 0.0863, Val Loss: 0.0495\n",
            "Epoch [67/200], Loss: 0.0860, Val Loss: 0.0487\n",
            "Epoch [68/200], Loss: 0.0860, Val Loss: 0.0484\n",
            "Epoch [69/200], Loss: 0.0857, Val Loss: 0.0471\n",
            "Epoch [70/200], Loss: 0.0858, Val Loss: 0.0493\n",
            "Epoch [71/200], Loss: 0.0848, Val Loss: 0.0497\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2549, Val Loss: 0.1372\n",
            "Epoch [2/200], Loss: 0.1676, Val Loss: 0.0999\n",
            "Epoch [3/200], Loss: 0.1380, Val Loss: 0.0835\n",
            "Epoch [4/200], Loss: 0.1301, Val Loss: 0.0806\n",
            "Epoch [5/200], Loss: 0.1275, Val Loss: 0.0778\n",
            "Epoch [6/200], Loss: 0.1250, Val Loss: 0.0779\n",
            "Epoch [7/200], Loss: 0.1228, Val Loss: 0.0791\n",
            "Epoch [8/200], Loss: 0.1216, Val Loss: 0.0774\n",
            "Epoch [9/200], Loss: 0.1192, Val Loss: 0.0769\n",
            "Epoch [10/200], Loss: 0.1188, Val Loss: 0.0794\n",
            "Epoch [11/200], Loss: 0.1175, Val Loss: 0.0757\n",
            "Epoch [12/200], Loss: 0.1165, Val Loss: 0.0749\n",
            "Epoch [13/200], Loss: 0.1164, Val Loss: 0.0750\n",
            "Epoch [14/200], Loss: 0.1150, Val Loss: 0.0756\n",
            "Epoch [15/200], Loss: 0.1140, Val Loss: 0.0737\n",
            "Epoch [16/200], Loss: 0.1128, Val Loss: 0.0746\n",
            "Epoch [17/200], Loss: 0.1120, Val Loss: 0.0757\n",
            "Epoch [18/200], Loss: 0.1112, Val Loss: 0.0750\n",
            "Epoch [19/200], Loss: 0.1098, Val Loss: 0.0729\n",
            "Epoch [20/200], Loss: 0.1093, Val Loss: 0.0741\n",
            "Epoch [21/200], Loss: 0.1082, Val Loss: 0.0727\n",
            "Epoch [22/200], Loss: 0.1071, Val Loss: 0.0714\n",
            "Epoch [23/200], Loss: 0.1061, Val Loss: 0.0726\n",
            "Epoch [24/200], Loss: 0.1051, Val Loss: 0.0734\n",
            "Epoch [25/200], Loss: 0.1046, Val Loss: 0.0720\n",
            "Epoch [26/200], Loss: 0.1025, Val Loss: 0.0750\n",
            "Epoch [27/200], Loss: 0.1031, Val Loss: 0.0720\n",
            "Epoch [28/200], Loss: 0.1019, Val Loss: 0.0739\n",
            "Epoch [29/200], Loss: 0.1025, Val Loss: 0.0738\n",
            "Epoch [30/200], Loss: 0.1014, Val Loss: 0.0788\n",
            "Epoch [31/200], Loss: 0.1018, Val Loss: 0.0753\n",
            "Epoch [32/200], Loss: 0.1013, Val Loss: 0.0727\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=32, BS=64, Dropout=0.1, EncDim=8 -> MAE=0.1491, Error%=438138820.1671\n",
            "Running: LR=0.001, HS=32, BS=64, Dropout=0.2, EncDim=8\n",
            "71 / 81 completed\n",
            "Epoch [1/200], Loss: 0.3166, Val Loss: 0.1948\n",
            "Epoch [2/200], Loss: 0.2310, Val Loss: 0.1442\n",
            "Epoch [3/200], Loss: 0.2099, Val Loss: 0.1354\n",
            "Epoch [4/200], Loss: 0.2000, Val Loss: 0.1266\n",
            "Epoch [5/200], Loss: 0.1912, Val Loss: 0.1240\n",
            "Epoch [6/200], Loss: 0.1864, Val Loss: 0.1175\n",
            "Epoch [7/200], Loss: 0.1818, Val Loss: 0.1151\n",
            "Epoch [8/200], Loss: 0.1779, Val Loss: 0.1124\n",
            "Epoch [9/200], Loss: 0.1749, Val Loss: 0.1082\n",
            "Epoch [10/200], Loss: 0.1726, Val Loss: 0.1083\n",
            "Epoch [11/200], Loss: 0.1720, Val Loss: 0.1050\n",
            "Epoch [12/200], Loss: 0.1698, Val Loss: 0.1041\n",
            "Epoch [13/200], Loss: 0.1690, Val Loss: 0.1053\n",
            "Epoch [14/200], Loss: 0.1676, Val Loss: 0.1006\n",
            "Epoch [15/200], Loss: 0.1657, Val Loss: 0.1007\n",
            "Epoch [16/200], Loss: 0.1658, Val Loss: 0.1024\n",
            "Epoch [17/200], Loss: 0.1657, Val Loss: 0.0991\n",
            "Epoch [18/200], Loss: 0.1632, Val Loss: 0.0994\n",
            "Epoch [19/200], Loss: 0.1626, Val Loss: 0.0982\n",
            "Epoch [20/200], Loss: 0.1621, Val Loss: 0.1014\n",
            "Epoch [21/200], Loss: 0.1607, Val Loss: 0.0958\n",
            "Epoch [22/200], Loss: 0.1610, Val Loss: 0.0987\n",
            "Epoch [23/200], Loss: 0.1610, Val Loss: 0.0959\n",
            "Epoch [24/200], Loss: 0.1593, Val Loss: 0.0949\n",
            "Epoch [25/200], Loss: 0.1589, Val Loss: 0.0992\n",
            "Epoch [26/200], Loss: 0.1585, Val Loss: 0.0959\n",
            "Epoch [27/200], Loss: 0.1587, Val Loss: 0.0943\n",
            "Epoch [28/200], Loss: 0.1583, Val Loss: 0.0959\n",
            "Epoch [29/200], Loss: 0.1583, Val Loss: 0.0924\n",
            "Epoch [30/200], Loss: 0.1573, Val Loss: 0.0951\n",
            "Epoch [31/200], Loss: 0.1564, Val Loss: 0.0947\n",
            "Epoch [32/200], Loss: 0.1573, Val Loss: 0.0934\n",
            "Epoch [33/200], Loss: 0.1561, Val Loss: 0.0938\n",
            "Epoch [34/200], Loss: 0.1565, Val Loss: 0.0941\n",
            "Epoch [35/200], Loss: 0.1568, Val Loss: 0.1006\n",
            "Epoch [36/200], Loss: 0.1563, Val Loss: 0.0916\n",
            "Epoch [37/200], Loss: 0.1561, Val Loss: 0.0938\n",
            "Epoch [38/200], Loss: 0.1560, Val Loss: 0.0939\n",
            "Epoch [39/200], Loss: 0.1553, Val Loss: 0.0912\n",
            "Epoch [40/200], Loss: 0.1562, Val Loss: 0.0930\n",
            "Epoch [41/200], Loss: 0.1548, Val Loss: 0.0925\n",
            "Epoch [42/200], Loss: 0.1555, Val Loss: 0.0912\n",
            "Epoch [43/200], Loss: 0.1552, Val Loss: 0.0919\n",
            "Epoch [44/200], Loss: 0.1566, Val Loss: 0.0912\n",
            "Epoch [45/200], Loss: 0.1545, Val Loss: 0.0915\n",
            "Epoch [46/200], Loss: 0.1548, Val Loss: 0.0923\n",
            "Epoch [47/200], Loss: 0.1537, Val Loss: 0.0913\n",
            "Epoch [48/200], Loss: 0.1548, Val Loss: 0.0945\n",
            "Epoch [49/200], Loss: 0.1544, Val Loss: 0.0917\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2928, Val Loss: 0.1526\n",
            "Epoch [2/200], Loss: 0.2180, Val Loss: 0.1404\n",
            "Epoch [3/200], Loss: 0.2058, Val Loss: 0.1326\n",
            "Epoch [4/200], Loss: 0.1993, Val Loss: 0.1306\n",
            "Epoch [5/200], Loss: 0.1962, Val Loss: 0.1226\n",
            "Epoch [6/200], Loss: 0.1899, Val Loss: 0.1178\n",
            "Epoch [7/200], Loss: 0.1864, Val Loss: 0.1141\n",
            "Epoch [8/200], Loss: 0.1846, Val Loss: 0.1148\n",
            "Epoch [9/200], Loss: 0.1829, Val Loss: 0.1138\n",
            "Epoch [10/200], Loss: 0.1810, Val Loss: 0.1131\n",
            "Epoch [11/200], Loss: 0.1798, Val Loss: 0.1115\n",
            "Epoch [12/200], Loss: 0.1802, Val Loss: 0.1111\n",
            "Epoch [13/200], Loss: 0.1778, Val Loss: 0.1094\n",
            "Epoch [14/200], Loss: 0.1789, Val Loss: 0.1111\n",
            "Epoch [15/200], Loss: 0.1780, Val Loss: 0.1115\n",
            "Epoch [16/200], Loss: 0.1773, Val Loss: 0.1121\n",
            "Epoch [17/200], Loss: 0.1777, Val Loss: 0.1138\n",
            "Epoch [18/200], Loss: 0.1758, Val Loss: 0.1099\n",
            "Epoch [19/200], Loss: 0.1759, Val Loss: 0.1049\n",
            "Epoch [20/200], Loss: 0.1760, Val Loss: 0.1126\n",
            "Epoch [21/200], Loss: 0.1752, Val Loss: 0.1067\n",
            "Epoch [22/200], Loss: 0.1737, Val Loss: 0.1094\n",
            "Epoch [23/200], Loss: 0.1749, Val Loss: 0.1097\n",
            "Epoch [24/200], Loss: 0.1742, Val Loss: 0.1135\n",
            "Epoch [25/200], Loss: 0.1731, Val Loss: 0.1080\n",
            "Epoch [26/200], Loss: 0.1743, Val Loss: 0.1106\n",
            "Epoch [27/200], Loss: 0.1713, Val Loss: 0.1073\n",
            "Epoch [28/200], Loss: 0.1720, Val Loss: 0.1059\n",
            "Epoch [29/200], Loss: 0.1721, Val Loss: 0.1082\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2935, Val Loss: 0.1558\n",
            "Epoch [2/200], Loss: 0.2235, Val Loss: 0.1446\n",
            "Epoch [3/200], Loss: 0.2136, Val Loss: 0.1432\n",
            "Epoch [4/200], Loss: 0.2076, Val Loss: 0.1382\n",
            "Epoch [5/200], Loss: 0.1998, Val Loss: 0.1358\n",
            "Epoch [6/200], Loss: 0.1946, Val Loss: 0.1261\n",
            "Epoch [7/200], Loss: 0.1881, Val Loss: 0.1218\n",
            "Epoch [8/200], Loss: 0.1845, Val Loss: 0.1176\n",
            "Epoch [9/200], Loss: 0.1819, Val Loss: 0.1178\n",
            "Epoch [10/200], Loss: 0.1796, Val Loss: 0.1173\n",
            "Epoch [11/200], Loss: 0.1801, Val Loss: 0.1080\n",
            "Epoch [12/200], Loss: 0.1786, Val Loss: 0.1092\n",
            "Epoch [13/200], Loss: 0.1778, Val Loss: 0.1120\n",
            "Epoch [14/200], Loss: 0.1760, Val Loss: 0.1167\n",
            "Epoch [15/200], Loss: 0.1760, Val Loss: 0.1084\n",
            "Epoch [16/200], Loss: 0.1755, Val Loss: 0.1086\n",
            "Epoch [17/200], Loss: 0.1749, Val Loss: 0.1066\n",
            "Epoch [18/200], Loss: 0.1738, Val Loss: 0.1091\n",
            "Epoch [19/200], Loss: 0.1734, Val Loss: 0.1107\n",
            "Epoch [20/200], Loss: 0.1729, Val Loss: 0.1150\n",
            "Epoch [21/200], Loss: 0.1725, Val Loss: 0.1090\n",
            "Epoch [22/200], Loss: 0.1718, Val Loss: 0.1117\n",
            "Epoch [23/200], Loss: 0.1726, Val Loss: 0.1064\n",
            "Epoch [24/200], Loss: 0.1719, Val Loss: 0.1061\n",
            "Epoch [25/200], Loss: 0.1699, Val Loss: 0.1044\n",
            "Epoch [26/200], Loss: 0.1703, Val Loss: 0.1103\n",
            "Epoch [27/200], Loss: 0.1709, Val Loss: 0.1093\n",
            "Epoch [28/200], Loss: 0.1698, Val Loss: 0.1114\n",
            "Epoch [29/200], Loss: 0.1695, Val Loss: 0.1034\n",
            "Epoch [30/200], Loss: 0.1688, Val Loss: 0.1118\n",
            "Epoch [31/200], Loss: 0.1696, Val Loss: 0.1047\n",
            "Epoch [32/200], Loss: 0.1702, Val Loss: 0.1074\n",
            "Epoch [33/200], Loss: 0.1674, Val Loss: 0.1056\n",
            "Epoch [34/200], Loss: 0.1687, Val Loss: 0.1057\n",
            "Epoch [35/200], Loss: 0.1684, Val Loss: 0.1057\n",
            "Epoch [36/200], Loss: 0.1670, Val Loss: 0.1105\n",
            "Epoch [37/200], Loss: 0.1676, Val Loss: 0.1055\n",
            "Epoch [38/200], Loss: 0.1667, Val Loss: 0.1052\n",
            "Epoch [39/200], Loss: 0.1671, Val Loss: 0.1048\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2870, Val Loss: 0.1463\n",
            "Epoch [2/200], Loss: 0.2149, Val Loss: 0.1320\n",
            "Epoch [3/200], Loss: 0.2022, Val Loss: 0.1205\n",
            "Epoch [4/200], Loss: 0.1942, Val Loss: 0.1198\n",
            "Epoch [5/200], Loss: 0.1897, Val Loss: 0.1114\n",
            "Epoch [6/200], Loss: 0.1847, Val Loss: 0.1109\n",
            "Epoch [7/200], Loss: 0.1838, Val Loss: 0.1090\n",
            "Epoch [8/200], Loss: 0.1824, Val Loss: 0.1091\n",
            "Epoch [9/200], Loss: 0.1797, Val Loss: 0.1043\n",
            "Epoch [10/200], Loss: 0.1799, Val Loss: 0.1036\n",
            "Epoch [11/200], Loss: 0.1789, Val Loss: 0.1083\n",
            "Epoch [12/200], Loss: 0.1779, Val Loss: 0.1052\n",
            "Epoch [13/200], Loss: 0.1780, Val Loss: 0.1045\n",
            "Epoch [14/200], Loss: 0.1763, Val Loss: 0.0991\n",
            "Epoch [15/200], Loss: 0.1763, Val Loss: 0.1001\n",
            "Epoch [16/200], Loss: 0.1748, Val Loss: 0.0994\n",
            "Epoch [17/200], Loss: 0.1749, Val Loss: 0.1014\n",
            "Epoch [18/200], Loss: 0.1736, Val Loss: 0.1028\n",
            "Epoch [19/200], Loss: 0.1730, Val Loss: 0.1050\n",
            "Epoch [20/200], Loss: 0.1726, Val Loss: 0.0981\n",
            "Epoch [21/200], Loss: 0.1710, Val Loss: 0.1000\n",
            "Epoch [22/200], Loss: 0.1692, Val Loss: 0.1006\n",
            "Epoch [23/200], Loss: 0.1691, Val Loss: 0.1001\n",
            "Epoch [24/200], Loss: 0.1682, Val Loss: 0.1024\n",
            "Epoch [25/200], Loss: 0.1665, Val Loss: 0.0992\n",
            "Epoch [26/200], Loss: 0.1665, Val Loss: 0.1025\n",
            "Epoch [27/200], Loss: 0.1645, Val Loss: 0.0981\n",
            "Epoch [28/200], Loss: 0.1635, Val Loss: 0.1025\n",
            "Epoch [29/200], Loss: 0.1636, Val Loss: 0.1009\n",
            "Epoch [30/200], Loss: 0.1618, Val Loss: 0.0996\n",
            "Epoch [31/200], Loss: 0.1611, Val Loss: 0.0991\n",
            "Epoch [32/200], Loss: 0.1611, Val Loss: 0.0998\n",
            "Epoch [33/200], Loss: 0.1609, Val Loss: 0.0982\n",
            "Epoch [34/200], Loss: 0.1594, Val Loss: 0.0974\n",
            "Epoch [35/200], Loss: 0.1586, Val Loss: 0.0990\n",
            "Epoch [36/200], Loss: 0.1587, Val Loss: 0.1022\n",
            "Epoch [37/200], Loss: 0.1582, Val Loss: 0.0996\n",
            "Epoch [38/200], Loss: 0.1574, Val Loss: 0.1006\n",
            "Epoch [39/200], Loss: 0.1573, Val Loss: 0.1002\n",
            "Epoch [40/200], Loss: 0.1570, Val Loss: 0.1010\n",
            "Epoch [41/200], Loss: 0.1575, Val Loss: 0.0983\n",
            "Epoch [42/200], Loss: 0.1562, Val Loss: 0.1013\n",
            "Epoch [43/200], Loss: 0.1556, Val Loss: 0.0986\n",
            "Epoch [44/200], Loss: 0.1560, Val Loss: 0.0978\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2871, Val Loss: 0.1447\n",
            "Epoch [2/200], Loss: 0.2136, Val Loss: 0.1231\n",
            "Epoch [3/200], Loss: 0.1981, Val Loss: 0.1082\n",
            "Epoch [4/200], Loss: 0.1916, Val Loss: 0.1068\n",
            "Epoch [5/200], Loss: 0.1899, Val Loss: 0.1043\n",
            "Epoch [6/200], Loss: 0.1861, Val Loss: 0.1045\n",
            "Epoch [7/200], Loss: 0.1848, Val Loss: 0.1005\n",
            "Epoch [8/200], Loss: 0.1839, Val Loss: 0.1038\n",
            "Epoch [9/200], Loss: 0.1826, Val Loss: 0.1013\n",
            "Epoch [10/200], Loss: 0.1817, Val Loss: 0.1027\n",
            "Epoch [11/200], Loss: 0.1821, Val Loss: 0.1022\n",
            "Epoch [12/200], Loss: 0.1808, Val Loss: 0.0983\n",
            "Epoch [13/200], Loss: 0.1808, Val Loss: 0.1039\n",
            "Epoch [14/200], Loss: 0.1793, Val Loss: 0.1004\n",
            "Epoch [15/200], Loss: 0.1798, Val Loss: 0.1016\n",
            "Epoch [16/200], Loss: 0.1781, Val Loss: 0.1028\n",
            "Epoch [17/200], Loss: 0.1777, Val Loss: 0.1007\n",
            "Epoch [18/200], Loss: 0.1772, Val Loss: 0.1027\n",
            "Epoch [19/200], Loss: 0.1758, Val Loss: 0.1016\n",
            "Epoch [20/200], Loss: 0.1753, Val Loss: 0.1006\n",
            "Epoch [21/200], Loss: 0.1739, Val Loss: 0.0972\n",
            "Epoch [22/200], Loss: 0.1741, Val Loss: 0.1031\n",
            "Epoch [23/200], Loss: 0.1726, Val Loss: 0.1001\n",
            "Epoch [24/200], Loss: 0.1728, Val Loss: 0.1031\n",
            "Epoch [25/200], Loss: 0.1719, Val Loss: 0.1013\n",
            "Epoch [26/200], Loss: 0.1712, Val Loss: 0.1039\n",
            "Epoch [27/200], Loss: 0.1707, Val Loss: 0.1039\n",
            "Epoch [28/200], Loss: 0.1702, Val Loss: 0.1012\n",
            "Epoch [29/200], Loss: 0.1685, Val Loss: 0.1014\n",
            "Epoch [30/200], Loss: 0.1683, Val Loss: 0.0987\n",
            "Epoch [31/200], Loss: 0.1677, Val Loss: 0.1014\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=32, BS=64, Dropout=0.2, EncDim=8 -> MAE=0.1999, Error%=566649579.5093\n",
            "Running: LR=0.001, HS=64, BS=16, Dropout=0.0, EncDim=8\n",
            "72 / 81 completed\n",
            "Epoch [1/200], Loss: 0.0351, Val Loss: 0.0041\n",
            "Epoch [2/200], Loss: 0.0026, Val Loss: 0.0038\n",
            "Epoch [3/200], Loss: 0.0016, Val Loss: 0.0015\n",
            "Epoch [4/200], Loss: 0.0013, Val Loss: 0.0011\n",
            "Epoch [5/200], Loss: 0.0011, Val Loss: 0.0009\n",
            "Epoch [6/200], Loss: 0.0010, Val Loss: 0.0011\n",
            "Epoch [7/200], Loss: 0.0008, Val Loss: 0.0010\n",
            "Epoch [8/200], Loss: 0.0008, Val Loss: 0.0005\n",
            "Epoch [9/200], Loss: 0.0007, Val Loss: 0.0006\n",
            "Epoch [10/200], Loss: 0.0006, Val Loss: 0.0004\n",
            "Epoch [11/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [12/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [13/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [14/200], Loss: 0.0003, Val Loss: 0.0008\n",
            "Epoch [15/200], Loss: 0.0004, Val Loss: 0.0001\n",
            "Epoch [16/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [17/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [18/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [19/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [20/200], Loss: 0.0004, Val Loss: 0.0002\n",
            "Epoch [21/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [22/200], Loss: 0.0002, Val Loss: 0.0004\n",
            "Epoch [23/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [24/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [25/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [26/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [27/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [28/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [29/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [30/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [31/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [32/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [33/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [34/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [35/200], Loss: 0.0002, Val Loss: 0.0009\n",
            "Epoch [36/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [37/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [38/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [39/200], Loss: 0.0004, Val Loss: 0.0002\n",
            "Epoch [40/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0329, Val Loss: 0.0060\n",
            "Epoch [2/200], Loss: 0.0034, Val Loss: 0.0024\n",
            "Epoch [3/200], Loss: 0.0020, Val Loss: 0.0020\n",
            "Epoch [4/200], Loss: 0.0016, Val Loss: 0.0010\n",
            "Epoch [5/200], Loss: 0.0012, Val Loss: 0.0014\n",
            "Epoch [6/200], Loss: 0.0009, Val Loss: 0.0007\n",
            "Epoch [7/200], Loss: 0.0008, Val Loss: 0.0015\n",
            "Epoch [8/200], Loss: 0.0007, Val Loss: 0.0004\n",
            "Epoch [9/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [10/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [11/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [12/200], Loss: 0.0004, Val Loss: 0.0002\n",
            "Epoch [13/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [14/200], Loss: 0.0005, Val Loss: 0.0001\n",
            "Epoch [15/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [16/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [17/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [18/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [19/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [20/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [21/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [22/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [23/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [24/200], Loss: 0.0002, Val Loss: 0.0005\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0332, Val Loss: 0.0081\n",
            "Epoch [2/200], Loss: 0.0053, Val Loss: 0.0044\n",
            "Epoch [3/200], Loss: 0.0027, Val Loss: 0.0022\n",
            "Epoch [4/200], Loss: 0.0019, Val Loss: 0.0016\n",
            "Epoch [5/200], Loss: 0.0015, Val Loss: 0.0009\n",
            "Epoch [6/200], Loss: 0.0012, Val Loss: 0.0007\n",
            "Epoch [7/200], Loss: 0.0010, Val Loss: 0.0005\n",
            "Epoch [8/200], Loss: 0.0008, Val Loss: 0.0007\n",
            "Epoch [9/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [10/200], Loss: 0.0007, Val Loss: 0.0005\n",
            "Epoch [11/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [12/200], Loss: 0.0007, Val Loss: 0.0004\n",
            "Epoch [13/200], Loss: 0.0006, Val Loss: 0.0004\n",
            "Epoch [14/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [15/200], Loss: 0.0006, Val Loss: 0.0009\n",
            "Epoch [16/200], Loss: 0.0006, Val Loss: 0.0008\n",
            "Epoch [17/200], Loss: 0.0006, Val Loss: 0.0004\n",
            "Epoch [18/200], Loss: 0.0006, Val Loss: 0.0003\n",
            "Epoch [19/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [20/200], Loss: 0.0005, Val Loss: 0.0002\n",
            "Epoch [21/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [22/200], Loss: 0.0005, Val Loss: 0.0003\n",
            "Epoch [23/200], Loss: 0.0006, Val Loss: 0.0002\n",
            "Epoch [24/200], Loss: 0.0004, Val Loss: 0.0002\n",
            "Epoch [25/200], Loss: 0.0005, Val Loss: 0.0002\n",
            "Epoch [26/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [27/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [28/200], Loss: 0.0004, Val Loss: 0.0010\n",
            "Epoch [29/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [30/200], Loss: 0.0003, Val Loss: 0.0018\n",
            "Epoch [31/200], Loss: 0.0004, Val Loss: 0.0002\n",
            "Epoch [32/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [33/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [34/200], Loss: 0.0003, Val Loss: 0.0019\n",
            "Epoch [35/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [36/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [37/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [38/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [39/200], Loss: 0.0003, Val Loss: 0.0005\n",
            "Epoch [40/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [41/200], Loss: 0.0003, Val Loss: 0.0005\n",
            "Epoch [42/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [43/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [44/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [45/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [46/200], Loss: 0.0002, Val Loss: 0.0004\n",
            "Epoch [47/200], Loss: 0.0003, Val Loss: 0.0000\n",
            "Epoch [48/200], Loss: 0.0004, Val Loss: 0.0001\n",
            "Epoch [49/200], Loss: 0.0002, Val Loss: 0.0006\n",
            "Epoch [50/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [51/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [52/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [53/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [54/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [55/200], Loss: 0.0003, Val Loss: 0.0011\n",
            "Epoch [56/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [57/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0331, Val Loss: 0.0067\n",
            "Epoch [2/200], Loss: 0.0040, Val Loss: 0.0022\n",
            "Epoch [3/200], Loss: 0.0014, Val Loss: 0.0009\n",
            "Epoch [4/200], Loss: 0.0011, Val Loss: 0.0008\n",
            "Epoch [5/200], Loss: 0.0010, Val Loss: 0.0007\n",
            "Epoch [6/200], Loss: 0.0009, Val Loss: 0.0006\n",
            "Epoch [7/200], Loss: 0.0008, Val Loss: 0.0004\n",
            "Epoch [8/200], Loss: 0.0007, Val Loss: 0.0004\n",
            "Epoch [9/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [10/200], Loss: 0.0005, Val Loss: 0.0003\n",
            "Epoch [11/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [12/200], Loss: 0.0004, Val Loss: 0.0015\n",
            "Epoch [13/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [14/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [15/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [16/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [17/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [18/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [19/200], Loss: 0.0003, Val Loss: 0.0007\n",
            "Epoch [20/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [21/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [22/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [23/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [24/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [25/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [26/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [27/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [28/200], Loss: 0.0001, Val Loss: 0.0004\n",
            "Epoch [29/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [30/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [31/200], Loss: 0.0004, Val Loss: 0.0002\n",
            "Epoch [32/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [33/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [34/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [35/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [36/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [37/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [38/200], Loss: 0.0004, Val Loss: 0.0001\n",
            "Epoch [39/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [40/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [41/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [42/200], Loss: 0.0005, Val Loss: 0.0001\n",
            "Epoch [43/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [44/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [45/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [46/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [47/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0307, Val Loss: 0.0038\n",
            "Epoch [2/200], Loss: 0.0033, Val Loss: 0.0027\n",
            "Epoch [3/200], Loss: 0.0021, Val Loss: 0.0014\n",
            "Epoch [4/200], Loss: 0.0013, Val Loss: 0.0011\n",
            "Epoch [5/200], Loss: 0.0010, Val Loss: 0.0007\n",
            "Epoch [6/200], Loss: 0.0008, Val Loss: 0.0007\n",
            "Epoch [7/200], Loss: 0.0007, Val Loss: 0.0004\n",
            "Epoch [8/200], Loss: 0.0007, Val Loss: 0.0005\n",
            "Epoch [9/200], Loss: 0.0006, Val Loss: 0.0003\n",
            "Epoch [10/200], Loss: 0.0006, Val Loss: 0.0004\n",
            "Epoch [11/200], Loss: 0.0004, Val Loss: 0.0002\n",
            "Epoch [12/200], Loss: 0.0005, Val Loss: 0.0002\n",
            "Epoch [13/200], Loss: 0.0004, Val Loss: 0.0002\n",
            "Epoch [14/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [15/200], Loss: 0.0004, Val Loss: 0.0002\n",
            "Epoch [16/200], Loss: 0.0004, Val Loss: 0.0002\n",
            "Epoch [17/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [18/200], Loss: 0.0004, Val Loss: 0.0002\n",
            "Epoch [19/200], Loss: 0.0005, Val Loss: 0.0002\n",
            "Epoch [20/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [21/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [22/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [23/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [24/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [25/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [26/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [27/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [28/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [29/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [30/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [31/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [32/200], Loss: 0.0003, Val Loss: 0.0006\n",
            "Epoch [33/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [34/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [35/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [36/200], Loss: 0.0002, Val Loss: 0.0009\n",
            "Epoch [37/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [38/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [39/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [40/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [41/200], Loss: 0.0002, Val Loss: 0.0020\n",
            "Epoch [42/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [43/200], Loss: 0.0001, Val Loss: 0.0003\n",
            "Epoch [44/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [45/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [46/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [47/200], Loss: 0.0002, Val Loss: 0.0009\n",
            "Epoch [48/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [49/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=64, BS=16, Dropout=0.0, EncDim=8 -> MAE=0.0077, Error%=18637895.4799\n",
            "Running: LR=0.001, HS=64, BS=16, Dropout=0.1, EncDim=8\n",
            "73 / 81 completed\n",
            "Epoch [1/200], Loss: 0.1179, Val Loss: 0.0491\n",
            "Epoch [2/200], Loss: 0.0843, Val Loss: 0.0413\n",
            "Epoch [3/200], Loss: 0.0716, Val Loss: 0.0292\n",
            "Epoch [4/200], Loss: 0.0643, Val Loss: 0.0275\n",
            "Epoch [5/200], Loss: 0.0601, Val Loss: 0.0255\n",
            "Epoch [6/200], Loss: 0.0574, Val Loss: 0.0241\n",
            "Epoch [7/200], Loss: 0.0547, Val Loss: 0.0245\n",
            "Epoch [8/200], Loss: 0.0532, Val Loss: 0.0240\n",
            "Epoch [9/200], Loss: 0.0520, Val Loss: 0.0235\n",
            "Epoch [10/200], Loss: 0.0514, Val Loss: 0.0213\n",
            "Epoch [11/200], Loss: 0.0503, Val Loss: 0.0221\n",
            "Epoch [12/200], Loss: 0.0493, Val Loss: 0.0210\n",
            "Epoch [13/200], Loss: 0.0491, Val Loss: 0.0199\n",
            "Epoch [14/200], Loss: 0.0483, Val Loss: 0.0219\n",
            "Epoch [15/200], Loss: 0.0486, Val Loss: 0.0212\n",
            "Epoch [16/200], Loss: 0.0478, Val Loss: 0.0203\n",
            "Epoch [17/200], Loss: 0.0474, Val Loss: 0.0194\n",
            "Epoch [18/200], Loss: 0.0475, Val Loss: 0.0201\n",
            "Epoch [19/200], Loss: 0.0473, Val Loss: 0.0199\n",
            "Epoch [20/200], Loss: 0.0470, Val Loss: 0.0220\n",
            "Epoch [21/200], Loss: 0.0458, Val Loss: 0.0179\n",
            "Epoch [22/200], Loss: 0.0460, Val Loss: 0.0189\n",
            "Epoch [23/200], Loss: 0.0449, Val Loss: 0.0166\n",
            "Epoch [24/200], Loss: 0.0455, Val Loss: 0.0168\n",
            "Epoch [25/200], Loss: 0.0445, Val Loss: 0.0167\n",
            "Epoch [26/200], Loss: 0.0436, Val Loss: 0.0146\n",
            "Epoch [27/200], Loss: 0.0428, Val Loss: 0.0133\n",
            "Epoch [28/200], Loss: 0.0421, Val Loss: 0.0150\n",
            "Epoch [29/200], Loss: 0.0424, Val Loss: 0.0134\n",
            "Epoch [30/200], Loss: 0.0418, Val Loss: 0.0145\n",
            "Epoch [31/200], Loss: 0.0416, Val Loss: 0.0142\n",
            "Epoch [32/200], Loss: 0.0418, Val Loss: 0.0140\n",
            "Epoch [33/200], Loss: 0.0412, Val Loss: 0.0125\n",
            "Epoch [34/200], Loss: 0.0419, Val Loss: 0.0135\n",
            "Epoch [35/200], Loss: 0.0406, Val Loss: 0.0144\n",
            "Epoch [36/200], Loss: 0.0412, Val Loss: 0.0159\n",
            "Epoch [37/200], Loss: 0.0413, Val Loss: 0.0145\n",
            "Epoch [38/200], Loss: 0.0406, Val Loss: 0.0130\n",
            "Epoch [39/200], Loss: 0.0406, Val Loss: 0.0132\n",
            "Epoch [40/200], Loss: 0.0410, Val Loss: 0.0134\n",
            "Epoch [41/200], Loss: 0.0409, Val Loss: 0.0158\n",
            "Epoch [42/200], Loss: 0.0405, Val Loss: 0.0146\n",
            "Epoch [43/200], Loss: 0.0407, Val Loss: 0.0143\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1214, Val Loss: 0.0577\n",
            "Epoch [2/200], Loss: 0.0855, Val Loss: 0.0446\n",
            "Epoch [3/200], Loss: 0.0760, Val Loss: 0.0382\n",
            "Epoch [4/200], Loss: 0.0704, Val Loss: 0.0360\n",
            "Epoch [5/200], Loss: 0.0663, Val Loss: 0.0269\n",
            "Epoch [6/200], Loss: 0.0630, Val Loss: 0.0275\n",
            "Epoch [7/200], Loss: 0.0609, Val Loss: 0.0255\n",
            "Epoch [8/200], Loss: 0.0584, Val Loss: 0.0225\n",
            "Epoch [9/200], Loss: 0.0567, Val Loss: 0.0225\n",
            "Epoch [10/200], Loss: 0.0546, Val Loss: 0.0222\n",
            "Epoch [11/200], Loss: 0.0533, Val Loss: 0.0215\n",
            "Epoch [12/200], Loss: 0.0515, Val Loss: 0.0208\n",
            "Epoch [13/200], Loss: 0.0506, Val Loss: 0.0206\n",
            "Epoch [14/200], Loss: 0.0494, Val Loss: 0.0212\n",
            "Epoch [15/200], Loss: 0.0480, Val Loss: 0.0209\n",
            "Epoch [16/200], Loss: 0.0472, Val Loss: 0.0197\n",
            "Epoch [17/200], Loss: 0.0472, Val Loss: 0.0214\n",
            "Epoch [18/200], Loss: 0.0462, Val Loss: 0.0206\n",
            "Epoch [19/200], Loss: 0.0454, Val Loss: 0.0198\n",
            "Epoch [20/200], Loss: 0.0457, Val Loss: 0.0203\n",
            "Epoch [21/200], Loss: 0.0453, Val Loss: 0.0193\n",
            "Epoch [22/200], Loss: 0.0448, Val Loss: 0.0192\n",
            "Epoch [23/200], Loss: 0.0444, Val Loss: 0.0185\n",
            "Epoch [24/200], Loss: 0.0438, Val Loss: 0.0198\n",
            "Epoch [25/200], Loss: 0.0442, Val Loss: 0.0182\n",
            "Epoch [26/200], Loss: 0.0437, Val Loss: 0.0185\n",
            "Epoch [27/200], Loss: 0.0431, Val Loss: 0.0207\n",
            "Epoch [28/200], Loss: 0.0429, Val Loss: 0.0195\n",
            "Epoch [29/200], Loss: 0.0432, Val Loss: 0.0180\n",
            "Epoch [30/200], Loss: 0.0425, Val Loss: 0.0185\n",
            "Epoch [31/200], Loss: 0.0432, Val Loss: 0.0189\n",
            "Epoch [32/200], Loss: 0.0425, Val Loss: 0.0196\n",
            "Epoch [33/200], Loss: 0.0426, Val Loss: 0.0182\n",
            "Epoch [34/200], Loss: 0.0420, Val Loss: 0.0185\n",
            "Epoch [35/200], Loss: 0.0421, Val Loss: 0.0196\n",
            "Epoch [36/200], Loss: 0.0419, Val Loss: 0.0173\n",
            "Epoch [37/200], Loss: 0.0422, Val Loss: 0.0182\n",
            "Epoch [38/200], Loss: 0.0419, Val Loss: 0.0175\n",
            "Epoch [39/200], Loss: 0.0420, Val Loss: 0.0168\n",
            "Epoch [40/200], Loss: 0.0417, Val Loss: 0.0185\n",
            "Epoch [41/200], Loss: 0.0416, Val Loss: 0.0183\n",
            "Epoch [42/200], Loss: 0.0415, Val Loss: 0.0187\n",
            "Epoch [43/200], Loss: 0.0411, Val Loss: 0.0176\n",
            "Epoch [44/200], Loss: 0.0410, Val Loss: 0.0194\n",
            "Epoch [45/200], Loss: 0.0407, Val Loss: 0.0170\n",
            "Epoch [46/200], Loss: 0.0409, Val Loss: 0.0184\n",
            "Epoch [47/200], Loss: 0.0410, Val Loss: 0.0175\n",
            "Epoch [48/200], Loss: 0.0409, Val Loss: 0.0173\n",
            "Epoch [49/200], Loss: 0.0413, Val Loss: 0.0178\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1233, Val Loss: 0.0500\n",
            "Epoch [2/200], Loss: 0.0848, Val Loss: 0.0491\n",
            "Epoch [3/200], Loss: 0.0726, Val Loss: 0.0345\n",
            "Epoch [4/200], Loss: 0.0643, Val Loss: 0.0279\n",
            "Epoch [5/200], Loss: 0.0596, Val Loss: 0.0259\n",
            "Epoch [6/200], Loss: 0.0575, Val Loss: 0.0252\n",
            "Epoch [7/200], Loss: 0.0546, Val Loss: 0.0240\n",
            "Epoch [8/200], Loss: 0.0520, Val Loss: 0.0242\n",
            "Epoch [9/200], Loss: 0.0507, Val Loss: 0.0222\n",
            "Epoch [10/200], Loss: 0.0494, Val Loss: 0.0224\n",
            "Epoch [11/200], Loss: 0.0481, Val Loss: 0.0201\n",
            "Epoch [12/200], Loss: 0.0477, Val Loss: 0.0224\n",
            "Epoch [13/200], Loss: 0.0468, Val Loss: 0.0193\n",
            "Epoch [14/200], Loss: 0.0458, Val Loss: 0.0183\n",
            "Epoch [15/200], Loss: 0.0453, Val Loss: 0.0173\n",
            "Epoch [16/200], Loss: 0.0443, Val Loss: 0.0205\n",
            "Epoch [17/200], Loss: 0.0440, Val Loss: 0.0163\n",
            "Epoch [18/200], Loss: 0.0434, Val Loss: 0.0174\n",
            "Epoch [19/200], Loss: 0.0430, Val Loss: 0.0163\n",
            "Epoch [20/200], Loss: 0.0433, Val Loss: 0.0163\n",
            "Epoch [21/200], Loss: 0.0431, Val Loss: 0.0157\n",
            "Epoch [22/200], Loss: 0.0432, Val Loss: 0.0158\n",
            "Epoch [23/200], Loss: 0.0432, Val Loss: 0.0153\n",
            "Epoch [24/200], Loss: 0.0423, Val Loss: 0.0144\n",
            "Epoch [25/200], Loss: 0.0421, Val Loss: 0.0158\n",
            "Epoch [26/200], Loss: 0.0417, Val Loss: 0.0145\n",
            "Epoch [27/200], Loss: 0.0413, Val Loss: 0.0134\n",
            "Epoch [28/200], Loss: 0.0414, Val Loss: 0.0138\n",
            "Epoch [29/200], Loss: 0.0415, Val Loss: 0.0135\n",
            "Epoch [30/200], Loss: 0.0406, Val Loss: 0.0134\n",
            "Epoch [31/200], Loss: 0.0407, Val Loss: 0.0163\n",
            "Epoch [32/200], Loss: 0.0407, Val Loss: 0.0132\n",
            "Epoch [33/200], Loss: 0.0411, Val Loss: 0.0128\n",
            "Epoch [34/200], Loss: 0.0404, Val Loss: 0.0114\n",
            "Epoch [35/200], Loss: 0.0399, Val Loss: 0.0128\n",
            "Epoch [36/200], Loss: 0.0397, Val Loss: 0.0117\n",
            "Epoch [37/200], Loss: 0.0399, Val Loss: 0.0144\n",
            "Epoch [38/200], Loss: 0.0397, Val Loss: 0.0127\n",
            "Epoch [39/200], Loss: 0.0403, Val Loss: 0.0145\n",
            "Epoch [40/200], Loss: 0.0395, Val Loss: 0.0143\n",
            "Epoch [41/200], Loss: 0.0400, Val Loss: 0.0131\n",
            "Epoch [42/200], Loss: 0.0399, Val Loss: 0.0151\n",
            "Epoch [43/200], Loss: 0.0394, Val Loss: 0.0125\n",
            "Epoch [44/200], Loss: 0.0400, Val Loss: 0.0138\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1151, Val Loss: 0.0499\n",
            "Epoch [2/200], Loss: 0.0770, Val Loss: 0.0320\n",
            "Epoch [3/200], Loss: 0.0665, Val Loss: 0.0288\n",
            "Epoch [4/200], Loss: 0.0627, Val Loss: 0.0257\n",
            "Epoch [5/200], Loss: 0.0604, Val Loss: 0.0254\n",
            "Epoch [6/200], Loss: 0.0578, Val Loss: 0.0255\n",
            "Epoch [7/200], Loss: 0.0561, Val Loss: 0.0249\n",
            "Epoch [8/200], Loss: 0.0547, Val Loss: 0.0226\n",
            "Epoch [9/200], Loss: 0.0534, Val Loss: 0.0241\n",
            "Epoch [10/200], Loss: 0.0526, Val Loss: 0.0236\n",
            "Epoch [11/200], Loss: 0.0515, Val Loss: 0.0227\n",
            "Epoch [12/200], Loss: 0.0509, Val Loss: 0.0222\n",
            "Epoch [13/200], Loss: 0.0497, Val Loss: 0.0203\n",
            "Epoch [14/200], Loss: 0.0488, Val Loss: 0.0218\n",
            "Epoch [15/200], Loss: 0.0483, Val Loss: 0.0194\n",
            "Epoch [16/200], Loss: 0.0474, Val Loss: 0.0179\n",
            "Epoch [17/200], Loss: 0.0457, Val Loss: 0.0152\n",
            "Epoch [18/200], Loss: 0.0438, Val Loss: 0.0146\n",
            "Epoch [19/200], Loss: 0.0433, Val Loss: 0.0161\n",
            "Epoch [20/200], Loss: 0.0426, Val Loss: 0.0152\n",
            "Epoch [21/200], Loss: 0.0424, Val Loss: 0.0147\n",
            "Epoch [22/200], Loss: 0.0416, Val Loss: 0.0141\n",
            "Epoch [23/200], Loss: 0.0414, Val Loss: 0.0144\n",
            "Epoch [24/200], Loss: 0.0409, Val Loss: 0.0142\n",
            "Epoch [25/200], Loss: 0.0404, Val Loss: 0.0132\n",
            "Epoch [26/200], Loss: 0.0400, Val Loss: 0.0146\n",
            "Epoch [27/200], Loss: 0.0399, Val Loss: 0.0151\n",
            "Epoch [28/200], Loss: 0.0395, Val Loss: 0.0140\n",
            "Epoch [29/200], Loss: 0.0388, Val Loss: 0.0139\n",
            "Epoch [30/200], Loss: 0.0388, Val Loss: 0.0146\n",
            "Epoch [31/200], Loss: 0.0385, Val Loss: 0.0130\n",
            "Epoch [32/200], Loss: 0.0384, Val Loss: 0.0143\n",
            "Epoch [33/200], Loss: 0.0382, Val Loss: 0.0136\n",
            "Epoch [34/200], Loss: 0.0384, Val Loss: 0.0173\n",
            "Epoch [35/200], Loss: 0.0387, Val Loss: 0.0137\n",
            "Epoch [36/200], Loss: 0.0381, Val Loss: 0.0125\n",
            "Epoch [37/200], Loss: 0.0381, Val Loss: 0.0125\n",
            "Epoch [38/200], Loss: 0.0382, Val Loss: 0.0125\n",
            "Epoch [39/200], Loss: 0.0377, Val Loss: 0.0118\n",
            "Epoch [40/200], Loss: 0.0373, Val Loss: 0.0124\n",
            "Epoch [41/200], Loss: 0.0376, Val Loss: 0.0115\n",
            "Epoch [42/200], Loss: 0.0380, Val Loss: 0.0136\n",
            "Epoch [43/200], Loss: 0.0383, Val Loss: 0.0136\n",
            "Epoch [44/200], Loss: 0.0376, Val Loss: 0.0138\n",
            "Epoch [45/200], Loss: 0.0370, Val Loss: 0.0132\n",
            "Epoch [46/200], Loss: 0.0374, Val Loss: 0.0115\n",
            "Epoch [47/200], Loss: 0.0369, Val Loss: 0.0117\n",
            "Epoch [48/200], Loss: 0.0377, Val Loss: 0.0132\n",
            "Epoch [49/200], Loss: 0.0366, Val Loss: 0.0132\n",
            "Epoch [50/200], Loss: 0.0369, Val Loss: 0.0128\n",
            "Epoch [51/200], Loss: 0.0368, Val Loss: 0.0135\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1120, Val Loss: 0.0341\n",
            "Epoch [2/200], Loss: 0.0739, Val Loss: 0.0323\n",
            "Epoch [3/200], Loss: 0.0690, Val Loss: 0.0320\n",
            "Epoch [4/200], Loss: 0.0653, Val Loss: 0.0292\n",
            "Epoch [5/200], Loss: 0.0619, Val Loss: 0.0244\n",
            "Epoch [6/200], Loss: 0.0578, Val Loss: 0.0242\n",
            "Epoch [7/200], Loss: 0.0562, Val Loss: 0.0248\n",
            "Epoch [8/200], Loss: 0.0551, Val Loss: 0.0229\n",
            "Epoch [9/200], Loss: 0.0537, Val Loss: 0.0224\n",
            "Epoch [10/200], Loss: 0.0529, Val Loss: 0.0221\n",
            "Epoch [11/200], Loss: 0.0519, Val Loss: 0.0231\n",
            "Epoch [12/200], Loss: 0.0517, Val Loss: 0.0240\n",
            "Epoch [13/200], Loss: 0.0518, Val Loss: 0.0225\n",
            "Epoch [14/200], Loss: 0.0502, Val Loss: 0.0218\n",
            "Epoch [15/200], Loss: 0.0501, Val Loss: 0.0197\n",
            "Epoch [16/200], Loss: 0.0494, Val Loss: 0.0210\n",
            "Epoch [17/200], Loss: 0.0491, Val Loss: 0.0210\n",
            "Epoch [18/200], Loss: 0.0483, Val Loss: 0.0216\n",
            "Epoch [19/200], Loss: 0.0478, Val Loss: 0.0206\n",
            "Epoch [20/200], Loss: 0.0474, Val Loss: 0.0216\n",
            "Epoch [21/200], Loss: 0.0475, Val Loss: 0.0207\n",
            "Epoch [22/200], Loss: 0.0470, Val Loss: 0.0223\n",
            "Epoch [23/200], Loss: 0.0466, Val Loss: 0.0197\n",
            "Epoch [24/200], Loss: 0.0466, Val Loss: 0.0210\n",
            "Epoch [25/200], Loss: 0.0463, Val Loss: 0.0214\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=64, BS=16, Dropout=0.1, EncDim=8 -> MAE=0.0650, Error%=155639739.5617\n",
            "Running: LR=0.001, HS=64, BS=16, Dropout=0.2, EncDim=8\n",
            "74 / 81 completed\n",
            "Epoch [1/200], Loss: 0.1696, Val Loss: 0.0832\n",
            "Epoch [2/200], Loss: 0.1306, Val Loss: 0.0766\n",
            "Epoch [3/200], Loss: 0.1247, Val Loss: 0.0776\n",
            "Epoch [4/200], Loss: 0.1217, Val Loss: 0.0755\n",
            "Epoch [5/200], Loss: 0.1175, Val Loss: 0.0660\n",
            "Epoch [6/200], Loss: 0.1112, Val Loss: 0.0623\n",
            "Epoch [7/200], Loss: 0.1069, Val Loss: 0.0587\n",
            "Epoch [8/200], Loss: 0.1050, Val Loss: 0.0566\n",
            "Epoch [9/200], Loss: 0.1037, Val Loss: 0.0584\n",
            "Epoch [10/200], Loss: 0.1023, Val Loss: 0.0556\n",
            "Epoch [11/200], Loss: 0.1011, Val Loss: 0.0571\n",
            "Epoch [12/200], Loss: 0.1001, Val Loss: 0.0555\n",
            "Epoch [13/200], Loss: 0.0993, Val Loss: 0.0537\n",
            "Epoch [14/200], Loss: 0.0983, Val Loss: 0.0556\n",
            "Epoch [15/200], Loss: 0.0967, Val Loss: 0.0573\n",
            "Epoch [16/200], Loss: 0.0962, Val Loss: 0.0522\n",
            "Epoch [17/200], Loss: 0.0956, Val Loss: 0.0553\n",
            "Epoch [18/200], Loss: 0.0948, Val Loss: 0.0540\n",
            "Epoch [19/200], Loss: 0.0943, Val Loss: 0.0536\n",
            "Epoch [20/200], Loss: 0.0938, Val Loss: 0.0527\n",
            "Epoch [21/200], Loss: 0.0937, Val Loss: 0.0531\n",
            "Epoch [22/200], Loss: 0.0933, Val Loss: 0.0522\n",
            "Epoch [23/200], Loss: 0.0932, Val Loss: 0.0521\n",
            "Epoch [24/200], Loss: 0.0929, Val Loss: 0.0529\n",
            "Epoch [25/200], Loss: 0.0921, Val Loss: 0.0514\n",
            "Epoch [26/200], Loss: 0.0918, Val Loss: 0.0518\n",
            "Epoch [27/200], Loss: 0.0924, Val Loss: 0.0531\n",
            "Epoch [28/200], Loss: 0.0925, Val Loss: 0.0525\n",
            "Epoch [29/200], Loss: 0.0917, Val Loss: 0.0532\n",
            "Epoch [30/200], Loss: 0.0926, Val Loss: 0.0523\n",
            "Epoch [31/200], Loss: 0.0918, Val Loss: 0.0480\n",
            "Epoch [32/200], Loss: 0.0923, Val Loss: 0.0538\n",
            "Epoch [33/200], Loss: 0.0924, Val Loss: 0.0517\n",
            "Epoch [34/200], Loss: 0.0921, Val Loss: 0.0537\n",
            "Epoch [35/200], Loss: 0.0928, Val Loss: 0.0512\n",
            "Epoch [36/200], Loss: 0.0922, Val Loss: 0.0513\n",
            "Epoch [37/200], Loss: 0.0920, Val Loss: 0.0500\n",
            "Epoch [38/200], Loss: 0.0921, Val Loss: 0.0536\n",
            "Epoch [39/200], Loss: 0.0915, Val Loss: 0.0533\n",
            "Epoch [40/200], Loss: 0.0915, Val Loss: 0.0519\n",
            "Epoch [41/200], Loss: 0.0927, Val Loss: 0.0504\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1660, Val Loss: 0.0789\n",
            "Epoch [2/200], Loss: 0.1300, Val Loss: 0.0764\n",
            "Epoch [3/200], Loss: 0.1226, Val Loss: 0.0663\n",
            "Epoch [4/200], Loss: 0.1171, Val Loss: 0.0631\n",
            "Epoch [5/200], Loss: 0.1143, Val Loss: 0.0623\n",
            "Epoch [6/200], Loss: 0.1110, Val Loss: 0.0580\n",
            "Epoch [7/200], Loss: 0.1093, Val Loss: 0.0594\n",
            "Epoch [8/200], Loss: 0.1062, Val Loss: 0.0570\n",
            "Epoch [9/200], Loss: 0.1032, Val Loss: 0.0529\n",
            "Epoch [10/200], Loss: 0.1009, Val Loss: 0.0519\n",
            "Epoch [11/200], Loss: 0.0994, Val Loss: 0.0511\n",
            "Epoch [12/200], Loss: 0.0979, Val Loss: 0.0501\n",
            "Epoch [13/200], Loss: 0.0963, Val Loss: 0.0491\n",
            "Epoch [14/200], Loss: 0.0954, Val Loss: 0.0489\n",
            "Epoch [15/200], Loss: 0.0941, Val Loss: 0.0483\n",
            "Epoch [16/200], Loss: 0.0939, Val Loss: 0.0463\n",
            "Epoch [17/200], Loss: 0.0928, Val Loss: 0.0473\n",
            "Epoch [18/200], Loss: 0.0915, Val Loss: 0.0426\n",
            "Epoch [19/200], Loss: 0.0917, Val Loss: 0.0443\n",
            "Epoch [20/200], Loss: 0.0901, Val Loss: 0.0459\n",
            "Epoch [21/200], Loss: 0.0901, Val Loss: 0.0426\n",
            "Epoch [22/200], Loss: 0.0888, Val Loss: 0.0446\n",
            "Epoch [23/200], Loss: 0.0882, Val Loss: 0.0424\n",
            "Epoch [24/200], Loss: 0.0877, Val Loss: 0.0421\n",
            "Epoch [25/200], Loss: 0.0872, Val Loss: 0.0430\n",
            "Epoch [26/200], Loss: 0.0867, Val Loss: 0.0409\n",
            "Epoch [27/200], Loss: 0.0852, Val Loss: 0.0394\n",
            "Epoch [28/200], Loss: 0.0856, Val Loss: 0.0419\n",
            "Epoch [29/200], Loss: 0.0856, Val Loss: 0.0390\n",
            "Epoch [30/200], Loss: 0.0846, Val Loss: 0.0424\n",
            "Epoch [31/200], Loss: 0.0842, Val Loss: 0.0394\n",
            "Epoch [32/200], Loss: 0.0845, Val Loss: 0.0399\n",
            "Epoch [33/200], Loss: 0.0841, Val Loss: 0.0393\n",
            "Epoch [34/200], Loss: 0.0837, Val Loss: 0.0391\n",
            "Epoch [35/200], Loss: 0.0840, Val Loss: 0.0371\n",
            "Epoch [36/200], Loss: 0.0840, Val Loss: 0.0388\n",
            "Epoch [37/200], Loss: 0.0840, Val Loss: 0.0431\n",
            "Epoch [38/200], Loss: 0.0832, Val Loss: 0.0392\n",
            "Epoch [39/200], Loss: 0.0824, Val Loss: 0.0368\n",
            "Epoch [40/200], Loss: 0.0835, Val Loss: 0.0384\n",
            "Epoch [41/200], Loss: 0.0825, Val Loss: 0.0407\n",
            "Epoch [42/200], Loss: 0.0838, Val Loss: 0.0376\n",
            "Epoch [43/200], Loss: 0.0828, Val Loss: 0.0393\n",
            "Epoch [44/200], Loss: 0.0819, Val Loss: 0.0353\n",
            "Epoch [45/200], Loss: 0.0828, Val Loss: 0.0389\n",
            "Epoch [46/200], Loss: 0.0831, Val Loss: 0.0426\n",
            "Epoch [47/200], Loss: 0.0831, Val Loss: 0.0396\n",
            "Epoch [48/200], Loss: 0.0839, Val Loss: 0.0378\n",
            "Epoch [49/200], Loss: 0.0826, Val Loss: 0.0391\n",
            "Epoch [50/200], Loss: 0.0824, Val Loss: 0.0417\n",
            "Epoch [51/200], Loss: 0.0826, Val Loss: 0.0414\n",
            "Epoch [52/200], Loss: 0.0822, Val Loss: 0.0371\n",
            "Epoch [53/200], Loss: 0.0829, Val Loss: 0.0414\n",
            "Epoch [54/200], Loss: 0.0825, Val Loss: 0.0389\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1694, Val Loss: 0.0798\n",
            "Epoch [2/200], Loss: 0.1304, Val Loss: 0.0746\n",
            "Epoch [3/200], Loss: 0.1248, Val Loss: 0.0709\n",
            "Epoch [4/200], Loss: 0.1205, Val Loss: 0.0720\n",
            "Epoch [5/200], Loss: 0.1145, Val Loss: 0.0658\n",
            "Epoch [6/200], Loss: 0.1105, Val Loss: 0.0610\n",
            "Epoch [7/200], Loss: 0.1081, Val Loss: 0.0607\n",
            "Epoch [8/200], Loss: 0.1054, Val Loss: 0.0587\n",
            "Epoch [9/200], Loss: 0.1038, Val Loss: 0.0576\n",
            "Epoch [10/200], Loss: 0.1025, Val Loss: 0.0555\n",
            "Epoch [11/200], Loss: 0.1007, Val Loss: 0.0522\n",
            "Epoch [12/200], Loss: 0.1003, Val Loss: 0.0551\n",
            "Epoch [13/200], Loss: 0.0981, Val Loss: 0.0528\n",
            "Epoch [14/200], Loss: 0.0968, Val Loss: 0.0529\n",
            "Epoch [15/200], Loss: 0.0964, Val Loss: 0.0466\n",
            "Epoch [16/200], Loss: 0.0945, Val Loss: 0.0464\n",
            "Epoch [17/200], Loss: 0.0937, Val Loss: 0.0465\n",
            "Epoch [18/200], Loss: 0.0924, Val Loss: 0.0456\n",
            "Epoch [19/200], Loss: 0.0912, Val Loss: 0.0447\n",
            "Epoch [20/200], Loss: 0.0903, Val Loss: 0.0440\n",
            "Epoch [21/200], Loss: 0.0901, Val Loss: 0.0429\n",
            "Epoch [22/200], Loss: 0.0891, Val Loss: 0.0448\n",
            "Epoch [23/200], Loss: 0.0885, Val Loss: 0.0406\n",
            "Epoch [24/200], Loss: 0.0885, Val Loss: 0.0435\n",
            "Epoch [25/200], Loss: 0.0874, Val Loss: 0.0397\n",
            "Epoch [26/200], Loss: 0.0873, Val Loss: 0.0397\n",
            "Epoch [27/200], Loss: 0.0875, Val Loss: 0.0435\n",
            "Epoch [28/200], Loss: 0.0870, Val Loss: 0.0380\n",
            "Epoch [29/200], Loss: 0.0866, Val Loss: 0.0416\n",
            "Epoch [30/200], Loss: 0.0864, Val Loss: 0.0426\n",
            "Epoch [31/200], Loss: 0.0872, Val Loss: 0.0420\n",
            "Epoch [32/200], Loss: 0.0866, Val Loss: 0.0412\n",
            "Epoch [33/200], Loss: 0.0864, Val Loss: 0.0430\n",
            "Epoch [34/200], Loss: 0.0865, Val Loss: 0.0370\n",
            "Epoch [35/200], Loss: 0.0869, Val Loss: 0.0401\n",
            "Epoch [36/200], Loss: 0.0868, Val Loss: 0.0394\n",
            "Epoch [37/200], Loss: 0.0862, Val Loss: 0.0409\n",
            "Epoch [38/200], Loss: 0.0865, Val Loss: 0.0411\n",
            "Epoch [39/200], Loss: 0.0866, Val Loss: 0.0419\n",
            "Epoch [40/200], Loss: 0.0865, Val Loss: 0.0400\n",
            "Epoch [41/200], Loss: 0.0859, Val Loss: 0.0401\n",
            "Epoch [42/200], Loss: 0.0864, Val Loss: 0.0405\n",
            "Epoch [43/200], Loss: 0.0867, Val Loss: 0.0399\n",
            "Epoch [44/200], Loss: 0.0861, Val Loss: 0.0409\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1676, Val Loss: 0.0802\n",
            "Epoch [2/200], Loss: 0.1310, Val Loss: 0.0778\n",
            "Epoch [3/200], Loss: 0.1254, Val Loss: 0.0731\n",
            "Epoch [4/200], Loss: 0.1220, Val Loss: 0.0755\n",
            "Epoch [5/200], Loss: 0.1166, Val Loss: 0.0635\n",
            "Epoch [6/200], Loss: 0.1108, Val Loss: 0.0604\n",
            "Epoch [7/200], Loss: 0.1082, Val Loss: 0.0621\n",
            "Epoch [8/200], Loss: 0.1051, Val Loss: 0.0550\n",
            "Epoch [9/200], Loss: 0.1018, Val Loss: 0.0523\n",
            "Epoch [10/200], Loss: 0.0991, Val Loss: 0.0512\n",
            "Epoch [11/200], Loss: 0.0970, Val Loss: 0.0469\n",
            "Epoch [12/200], Loss: 0.0950, Val Loss: 0.0486\n",
            "Epoch [13/200], Loss: 0.0934, Val Loss: 0.0496\n",
            "Epoch [14/200], Loss: 0.0929, Val Loss: 0.0500\n",
            "Epoch [15/200], Loss: 0.0929, Val Loss: 0.0481\n",
            "Epoch [16/200], Loss: 0.0919, Val Loss: 0.0482\n",
            "Epoch [17/200], Loss: 0.0911, Val Loss: 0.0457\n",
            "Epoch [18/200], Loss: 0.0902, Val Loss: 0.0458\n",
            "Epoch [19/200], Loss: 0.0879, Val Loss: 0.0430\n",
            "Epoch [20/200], Loss: 0.0880, Val Loss: 0.0492\n",
            "Epoch [21/200], Loss: 0.0878, Val Loss: 0.0430\n",
            "Epoch [22/200], Loss: 0.0880, Val Loss: 0.0413\n",
            "Epoch [23/200], Loss: 0.0875, Val Loss: 0.0417\n",
            "Epoch [24/200], Loss: 0.0870, Val Loss: 0.0444\n",
            "Epoch [25/200], Loss: 0.0870, Val Loss: 0.0480\n",
            "Epoch [26/200], Loss: 0.0864, Val Loss: 0.0400\n",
            "Epoch [27/200], Loss: 0.0865, Val Loss: 0.0395\n",
            "Epoch [28/200], Loss: 0.0863, Val Loss: 0.0411\n",
            "Epoch [29/200], Loss: 0.0857, Val Loss: 0.0434\n",
            "Epoch [30/200], Loss: 0.0858, Val Loss: 0.0397\n",
            "Epoch [31/200], Loss: 0.0855, Val Loss: 0.0392\n",
            "Epoch [32/200], Loss: 0.0860, Val Loss: 0.0380\n",
            "Epoch [33/200], Loss: 0.0852, Val Loss: 0.0384\n",
            "Epoch [34/200], Loss: 0.0854, Val Loss: 0.0381\n",
            "Epoch [35/200], Loss: 0.0847, Val Loss: 0.0414\n",
            "Epoch [36/200], Loss: 0.0850, Val Loss: 0.0431\n",
            "Epoch [37/200], Loss: 0.0849, Val Loss: 0.0389\n",
            "Epoch [38/200], Loss: 0.0857, Val Loss: 0.0427\n",
            "Epoch [39/200], Loss: 0.0852, Val Loss: 0.0407\n",
            "Epoch [40/200], Loss: 0.0842, Val Loss: 0.0411\n",
            "Epoch [41/200], Loss: 0.0844, Val Loss: 0.0418\n",
            "Epoch [42/200], Loss: 0.0846, Val Loss: 0.0419\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1667, Val Loss: 0.0743\n",
            "Epoch [2/200], Loss: 0.1296, Val Loss: 0.0735\n",
            "Epoch [3/200], Loss: 0.1251, Val Loss: 0.0736\n",
            "Epoch [4/200], Loss: 0.1222, Val Loss: 0.0747\n",
            "Epoch [5/200], Loss: 0.1201, Val Loss: 0.0710\n",
            "Epoch [6/200], Loss: 0.1181, Val Loss: 0.0660\n",
            "Epoch [7/200], Loss: 0.1135, Val Loss: 0.0594\n",
            "Epoch [8/200], Loss: 0.1118, Val Loss: 0.0607\n",
            "Epoch [9/200], Loss: 0.1095, Val Loss: 0.0588\n",
            "Epoch [10/200], Loss: 0.1088, Val Loss: 0.0566\n",
            "Epoch [11/200], Loss: 0.1074, Val Loss: 0.0604\n",
            "Epoch [12/200], Loss: 0.1059, Val Loss: 0.0552\n",
            "Epoch [13/200], Loss: 0.1056, Val Loss: 0.0586\n",
            "Epoch [14/200], Loss: 0.1051, Val Loss: 0.0572\n",
            "Epoch [15/200], Loss: 0.1037, Val Loss: 0.0569\n",
            "Epoch [16/200], Loss: 0.1035, Val Loss: 0.0570\n",
            "Epoch [17/200], Loss: 0.1023, Val Loss: 0.0547\n",
            "Epoch [18/200], Loss: 0.1028, Val Loss: 0.0583\n",
            "Epoch [19/200], Loss: 0.1022, Val Loss: 0.0565\n",
            "Epoch [20/200], Loss: 0.1022, Val Loss: 0.0584\n",
            "Epoch [21/200], Loss: 0.1017, Val Loss: 0.0603\n",
            "Epoch [22/200], Loss: 0.1015, Val Loss: 0.0601\n",
            "Epoch [23/200], Loss: 0.1009, Val Loss: 0.0576\n",
            "Epoch [24/200], Loss: 0.1015, Val Loss: 0.0569\n",
            "Epoch [25/200], Loss: 0.1012, Val Loss: 0.0585\n",
            "Epoch [26/200], Loss: 0.1010, Val Loss: 0.0547\n",
            "Epoch [27/200], Loss: 0.1010, Val Loss: 0.0564\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=64, BS=16, Dropout=0.2, EncDim=8 -> MAE=0.1233, Error%=360018951.1408\n",
            "Running: LR=0.001, HS=64, BS=32, Dropout=0.0, EncDim=8\n",
            "75 / 81 completed\n",
            "Epoch [1/200], Loss: 0.0525, Val Loss: 0.0147\n",
            "Epoch [2/200], Loss: 0.0076, Val Loss: 0.0046\n",
            "Epoch [3/200], Loss: 0.0033, Val Loss: 0.0027\n",
            "Epoch [4/200], Loss: 0.0025, Val Loss: 0.0022\n",
            "Epoch [5/200], Loss: 0.0022, Val Loss: 0.0019\n",
            "Epoch [6/200], Loss: 0.0018, Val Loss: 0.0016\n",
            "Epoch [7/200], Loss: 0.0015, Val Loss: 0.0013\n",
            "Epoch [8/200], Loss: 0.0013, Val Loss: 0.0010\n",
            "Epoch [9/200], Loss: 0.0011, Val Loss: 0.0012\n",
            "Epoch [10/200], Loss: 0.0010, Val Loss: 0.0008\n",
            "Epoch [11/200], Loss: 0.0009, Val Loss: 0.0007\n",
            "Epoch [12/200], Loss: 0.0008, Val Loss: 0.0009\n",
            "Epoch [13/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [14/200], Loss: 0.0007, Val Loss: 0.0005\n",
            "Epoch [15/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [16/200], Loss: 0.0006, Val Loss: 0.0007\n",
            "Epoch [17/200], Loss: 0.0006, Val Loss: 0.0004\n",
            "Epoch [18/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [19/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [20/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [21/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [22/200], Loss: 0.0005, Val Loss: 0.0008\n",
            "Epoch [23/200], Loss: 0.0005, Val Loss: 0.0025\n",
            "Epoch [24/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [25/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [26/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [27/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [28/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [29/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [30/200], Loss: 0.0004, Val Loss: 0.0002\n",
            "Epoch [31/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [32/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [33/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [34/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [35/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [36/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [37/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [38/200], Loss: 0.0004, Val Loss: 0.0009\n",
            "Epoch [39/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [40/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [41/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [42/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [43/200], Loss: 0.0002, Val Loss: 0.0006\n",
            "Epoch [44/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [45/200], Loss: 0.0003, Val Loss: 0.0006\n",
            "Epoch [46/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [47/200], Loss: 0.0003, Val Loss: 0.0010\n",
            "Epoch [48/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [49/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [50/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [51/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [52/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [53/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [54/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [55/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [56/200], Loss: 0.0002, Val Loss: 0.0009\n",
            "Epoch [57/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [58/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [59/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [60/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [61/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [62/200], Loss: 0.0002, Val Loss: 0.0005\n",
            "Epoch [63/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [64/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [65/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [66/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [67/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [68/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [69/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [70/200], Loss: 0.0004, Val Loss: 0.0000\n",
            "Epoch [71/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [72/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [73/200], Loss: 0.0001, Val Loss: 0.0008\n",
            "Epoch [74/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [75/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [76/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [77/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [78/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [79/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [80/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [81/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [82/200], Loss: 0.0001, Val Loss: 0.0003\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0494, Val Loss: 0.0139\n",
            "Epoch [2/200], Loss: 0.0086, Val Loss: 0.0060\n",
            "Epoch [3/200], Loss: 0.0047, Val Loss: 0.0029\n",
            "Epoch [4/200], Loss: 0.0024, Val Loss: 0.0019\n",
            "Epoch [5/200], Loss: 0.0018, Val Loss: 0.0034\n",
            "Epoch [6/200], Loss: 0.0015, Val Loss: 0.0013\n",
            "Epoch [7/200], Loss: 0.0011, Val Loss: 0.0011\n",
            "Epoch [8/200], Loss: 0.0009, Val Loss: 0.0007\n",
            "Epoch [9/200], Loss: 0.0008, Val Loss: 0.0007\n",
            "Epoch [10/200], Loss: 0.0007, Val Loss: 0.0006\n",
            "Epoch [11/200], Loss: 0.0006, Val Loss: 0.0011\n",
            "Epoch [12/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [13/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [14/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [15/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [16/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [17/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [18/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [19/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [20/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [21/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [22/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [23/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [24/200], Loss: 0.0003, Val Loss: 0.0006\n",
            "Epoch [25/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [26/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [27/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [28/200], Loss: 0.0002, Val Loss: 0.0004\n",
            "Epoch [29/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [30/200], Loss: 0.0002, Val Loss: 0.0008\n",
            "Epoch [31/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [32/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [33/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [34/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [35/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0447, Val Loss: 0.0119\n",
            "Epoch [2/200], Loss: 0.0065, Val Loss: 0.0039\n",
            "Epoch [3/200], Loss: 0.0030, Val Loss: 0.0025\n",
            "Epoch [4/200], Loss: 0.0023, Val Loss: 0.0020\n",
            "Epoch [5/200], Loss: 0.0018, Val Loss: 0.0015\n",
            "Epoch [6/200], Loss: 0.0014, Val Loss: 0.0012\n",
            "Epoch [7/200], Loss: 0.0011, Val Loss: 0.0009\n",
            "Epoch [8/200], Loss: 0.0009, Val Loss: 0.0012\n",
            "Epoch [9/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [10/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [11/200], Loss: 0.0005, Val Loss: 0.0007\n",
            "Epoch [12/200], Loss: 0.0005, Val Loss: 0.0003\n",
            "Epoch [13/200], Loss: 0.0004, Val Loss: 0.0016\n",
            "Epoch [14/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [15/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [16/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [17/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [18/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [19/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [20/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [21/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [22/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [23/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [24/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [25/200], Loss: 0.0003, Val Loss: 0.0006\n",
            "Epoch [26/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [27/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [28/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [29/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [30/200], Loss: 0.0002, Val Loss: 0.0008\n",
            "Epoch [31/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [32/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [33/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [34/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [35/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [36/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [37/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [38/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [39/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [40/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [41/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [42/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [43/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [44/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [45/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [46/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [47/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [48/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [49/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [50/200], Loss: 0.0001, Val Loss: 0.0007\n",
            "Epoch [51/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [52/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [53/200], Loss: 0.0001, Val Loss: 0.0004\n",
            "Epoch [54/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [55/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [56/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [57/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [58/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [59/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [60/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [61/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [62/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0453, Val Loss: 0.0088\n",
            "Epoch [2/200], Loss: 0.0058, Val Loss: 0.0050\n",
            "Epoch [3/200], Loss: 0.0032, Val Loss: 0.0016\n",
            "Epoch [4/200], Loss: 0.0015, Val Loss: 0.0013\n",
            "Epoch [5/200], Loss: 0.0011, Val Loss: 0.0010\n",
            "Epoch [6/200], Loss: 0.0009, Val Loss: 0.0005\n",
            "Epoch [7/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [8/200], Loss: 0.0006, Val Loss: 0.0003\n",
            "Epoch [9/200], Loss: 0.0005, Val Loss: 0.0003\n",
            "Epoch [10/200], Loss: 0.0004, Val Loss: 0.0012\n",
            "Epoch [11/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [12/200], Loss: 0.0003, Val Loss: 0.0005\n",
            "Epoch [13/200], Loss: 0.0003, Val Loss: 0.0005\n",
            "Epoch [14/200], Loss: 0.0003, Val Loss: 0.0001\n",
            "Epoch [15/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [16/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [17/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [18/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [19/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [20/200], Loss: 0.0002, Val Loss: 0.0006\n",
            "Epoch [21/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [22/200], Loss: 0.0002, Val Loss: 0.0008\n",
            "Epoch [23/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [24/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [25/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [26/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [27/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [28/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0484, Val Loss: 0.0080\n",
            "Epoch [2/200], Loss: 0.0062, Val Loss: 0.0053\n",
            "Epoch [3/200], Loss: 0.0027, Val Loss: 0.0017\n",
            "Epoch [4/200], Loss: 0.0015, Val Loss: 0.0011\n",
            "Epoch [5/200], Loss: 0.0012, Val Loss: 0.0009\n",
            "Epoch [6/200], Loss: 0.0010, Val Loss: 0.0009\n",
            "Epoch [7/200], Loss: 0.0009, Val Loss: 0.0009\n",
            "Epoch [8/200], Loss: 0.0009, Val Loss: 0.0011\n",
            "Epoch [9/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [10/200], Loss: 0.0008, Val Loss: 0.0007\n",
            "Epoch [11/200], Loss: 0.0007, Val Loss: 0.0009\n",
            "Epoch [12/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [13/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [14/200], Loss: 0.0007, Val Loss: 0.0005\n",
            "Epoch [15/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [16/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [17/200], Loss: 0.0006, Val Loss: 0.0007\n",
            "Epoch [18/200], Loss: 0.0005, Val Loss: 0.0003\n",
            "Epoch [19/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [20/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [21/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [22/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [23/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [24/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [25/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [26/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [27/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [28/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [29/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [30/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [31/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [32/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [33/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [34/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [35/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [36/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [37/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [38/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=64, BS=32, Dropout=0.0, EncDim=8 -> MAE=0.0075, Error%=21841230.8116\n",
            "Running: LR=0.001, HS=64, BS=32, Dropout=0.1, EncDim=8\n",
            "76 / 81 completed\n",
            "Epoch [1/200], Loss: 0.1246, Val Loss: 0.0508\n",
            "Epoch [2/200], Loss: 0.0859, Val Loss: 0.0439\n",
            "Epoch [3/200], Loss: 0.0733, Val Loss: 0.0325\n",
            "Epoch [4/200], Loss: 0.0673, Val Loss: 0.0310\n",
            "Epoch [5/200], Loss: 0.0649, Val Loss: 0.0296\n",
            "Epoch [6/200], Loss: 0.0631, Val Loss: 0.0299\n",
            "Epoch [7/200], Loss: 0.0618, Val Loss: 0.0303\n",
            "Epoch [8/200], Loss: 0.0606, Val Loss: 0.0292\n",
            "Epoch [9/200], Loss: 0.0583, Val Loss: 0.0275\n",
            "Epoch [10/200], Loss: 0.0563, Val Loss: 0.0227\n",
            "Epoch [11/200], Loss: 0.0547, Val Loss: 0.0234\n",
            "Epoch [12/200], Loss: 0.0535, Val Loss: 0.0225\n",
            "Epoch [13/200], Loss: 0.0524, Val Loss: 0.0229\n",
            "Epoch [14/200], Loss: 0.0514, Val Loss: 0.0210\n",
            "Epoch [15/200], Loss: 0.0508, Val Loss: 0.0224\n",
            "Epoch [16/200], Loss: 0.0499, Val Loss: 0.0229\n",
            "Epoch [17/200], Loss: 0.0491, Val Loss: 0.0218\n",
            "Epoch [18/200], Loss: 0.0485, Val Loss: 0.0211\n",
            "Epoch [19/200], Loss: 0.0478, Val Loss: 0.0219\n",
            "Epoch [20/200], Loss: 0.0470, Val Loss: 0.0212\n",
            "Epoch [21/200], Loss: 0.0471, Val Loss: 0.0198\n",
            "Epoch [22/200], Loss: 0.0463, Val Loss: 0.0212\n",
            "Epoch [23/200], Loss: 0.0460, Val Loss: 0.0217\n",
            "Epoch [24/200], Loss: 0.0456, Val Loss: 0.0216\n",
            "Epoch [25/200], Loss: 0.0453, Val Loss: 0.0197\n",
            "Epoch [26/200], Loss: 0.0454, Val Loss: 0.0194\n",
            "Epoch [27/200], Loss: 0.0450, Val Loss: 0.0192\n",
            "Epoch [28/200], Loss: 0.0448, Val Loss: 0.0198\n",
            "Epoch [29/200], Loss: 0.0449, Val Loss: 0.0195\n",
            "Epoch [30/200], Loss: 0.0448, Val Loss: 0.0185\n",
            "Epoch [31/200], Loss: 0.0442, Val Loss: 0.0211\n",
            "Epoch [32/200], Loss: 0.0447, Val Loss: 0.0197\n",
            "Epoch [33/200], Loss: 0.0442, Val Loss: 0.0198\n",
            "Epoch [34/200], Loss: 0.0443, Val Loss: 0.0193\n",
            "Epoch [35/200], Loss: 0.0438, Val Loss: 0.0195\n",
            "Epoch [36/200], Loss: 0.0442, Val Loss: 0.0205\n",
            "Epoch [37/200], Loss: 0.0437, Val Loss: 0.0206\n",
            "Epoch [38/200], Loss: 0.0436, Val Loss: 0.0214\n",
            "Epoch [39/200], Loss: 0.0434, Val Loss: 0.0199\n",
            "Epoch [40/200], Loss: 0.0436, Val Loss: 0.0187\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1253, Val Loss: 0.0497\n",
            "Epoch [2/200], Loss: 0.0793, Val Loss: 0.0340\n",
            "Epoch [3/200], Loss: 0.0700, Val Loss: 0.0315\n",
            "Epoch [4/200], Loss: 0.0660, Val Loss: 0.0281\n",
            "Epoch [5/200], Loss: 0.0623, Val Loss: 0.0250\n",
            "Epoch [6/200], Loss: 0.0604, Val Loss: 0.0242\n",
            "Epoch [7/200], Loss: 0.0583, Val Loss: 0.0212\n",
            "Epoch [8/200], Loss: 0.0566, Val Loss: 0.0205\n",
            "Epoch [9/200], Loss: 0.0550, Val Loss: 0.0186\n",
            "Epoch [10/200], Loss: 0.0537, Val Loss: 0.0207\n",
            "Epoch [11/200], Loss: 0.0523, Val Loss: 0.0194\n",
            "Epoch [12/200], Loss: 0.0512, Val Loss: 0.0162\n",
            "Epoch [13/200], Loss: 0.0490, Val Loss: 0.0177\n",
            "Epoch [14/200], Loss: 0.0477, Val Loss: 0.0182\n",
            "Epoch [15/200], Loss: 0.0474, Val Loss: 0.0186\n",
            "Epoch [16/200], Loss: 0.0463, Val Loss: 0.0169\n",
            "Epoch [17/200], Loss: 0.0452, Val Loss: 0.0171\n",
            "Epoch [18/200], Loss: 0.0444, Val Loss: 0.0171\n",
            "Epoch [19/200], Loss: 0.0449, Val Loss: 0.0163\n",
            "Epoch [20/200], Loss: 0.0442, Val Loss: 0.0161\n",
            "Epoch [21/200], Loss: 0.0433, Val Loss: 0.0170\n",
            "Epoch [22/200], Loss: 0.0429, Val Loss: 0.0171\n",
            "Epoch [23/200], Loss: 0.0427, Val Loss: 0.0189\n",
            "Epoch [24/200], Loss: 0.0421, Val Loss: 0.0160\n",
            "Epoch [25/200], Loss: 0.0416, Val Loss: 0.0150\n",
            "Epoch [26/200], Loss: 0.0414, Val Loss: 0.0176\n",
            "Epoch [27/200], Loss: 0.0409, Val Loss: 0.0189\n",
            "Epoch [28/200], Loss: 0.0404, Val Loss: 0.0152\n",
            "Epoch [29/200], Loss: 0.0403, Val Loss: 0.0187\n",
            "Epoch [30/200], Loss: 0.0403, Val Loss: 0.0179\n",
            "Epoch [31/200], Loss: 0.0391, Val Loss: 0.0155\n",
            "Epoch [32/200], Loss: 0.0393, Val Loss: 0.0178\n",
            "Epoch [33/200], Loss: 0.0390, Val Loss: 0.0170\n",
            "Epoch [34/200], Loss: 0.0389, Val Loss: 0.0171\n",
            "Epoch [35/200], Loss: 0.0384, Val Loss: 0.0180\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1253, Val Loss: 0.0384\n",
            "Epoch [2/200], Loss: 0.0786, Val Loss: 0.0344\n",
            "Epoch [3/200], Loss: 0.0728, Val Loss: 0.0300\n",
            "Epoch [4/200], Loss: 0.0689, Val Loss: 0.0291\n",
            "Epoch [5/200], Loss: 0.0654, Val Loss: 0.0255\n",
            "Epoch [6/200], Loss: 0.0622, Val Loss: 0.0253\n",
            "Epoch [7/200], Loss: 0.0600, Val Loss: 0.0252\n",
            "Epoch [8/200], Loss: 0.0580, Val Loss: 0.0241\n",
            "Epoch [9/200], Loss: 0.0569, Val Loss: 0.0237\n",
            "Epoch [10/200], Loss: 0.0557, Val Loss: 0.0246\n",
            "Epoch [11/200], Loss: 0.0551, Val Loss: 0.0235\n",
            "Epoch [12/200], Loss: 0.0546, Val Loss: 0.0234\n",
            "Epoch [13/200], Loss: 0.0538, Val Loss: 0.0228\n",
            "Epoch [14/200], Loss: 0.0528, Val Loss: 0.0220\n",
            "Epoch [15/200], Loss: 0.0519, Val Loss: 0.0223\n",
            "Epoch [16/200], Loss: 0.0513, Val Loss: 0.0216\n",
            "Epoch [17/200], Loss: 0.0507, Val Loss: 0.0220\n",
            "Epoch [18/200], Loss: 0.0500, Val Loss: 0.0202\n",
            "Epoch [19/200], Loss: 0.0496, Val Loss: 0.0186\n",
            "Epoch [20/200], Loss: 0.0483, Val Loss: 0.0186\n",
            "Epoch [21/200], Loss: 0.0476, Val Loss: 0.0183\n",
            "Epoch [22/200], Loss: 0.0470, Val Loss: 0.0195\n",
            "Epoch [23/200], Loss: 0.0465, Val Loss: 0.0208\n",
            "Epoch [24/200], Loss: 0.0459, Val Loss: 0.0171\n",
            "Epoch [25/200], Loss: 0.0452, Val Loss: 0.0197\n",
            "Epoch [26/200], Loss: 0.0450, Val Loss: 0.0184\n",
            "Epoch [27/200], Loss: 0.0445, Val Loss: 0.0176\n",
            "Epoch [28/200], Loss: 0.0442, Val Loss: 0.0180\n",
            "Epoch [29/200], Loss: 0.0435, Val Loss: 0.0175\n",
            "Epoch [30/200], Loss: 0.0428, Val Loss: 0.0179\n",
            "Epoch [31/200], Loss: 0.0423, Val Loss: 0.0173\n",
            "Epoch [32/200], Loss: 0.0408, Val Loss: 0.0159\n",
            "Epoch [33/200], Loss: 0.0406, Val Loss: 0.0168\n",
            "Epoch [34/200], Loss: 0.0402, Val Loss: 0.0149\n",
            "Epoch [35/200], Loss: 0.0398, Val Loss: 0.0183\n",
            "Epoch [36/200], Loss: 0.0393, Val Loss: 0.0155\n",
            "Epoch [37/200], Loss: 0.0394, Val Loss: 0.0144\n",
            "Epoch [38/200], Loss: 0.0390, Val Loss: 0.0151\n",
            "Epoch [39/200], Loss: 0.0393, Val Loss: 0.0136\n",
            "Epoch [40/200], Loss: 0.0389, Val Loss: 0.0157\n",
            "Epoch [41/200], Loss: 0.0391, Val Loss: 0.0142\n",
            "Epoch [42/200], Loss: 0.0384, Val Loss: 0.0149\n",
            "Epoch [43/200], Loss: 0.0387, Val Loss: 0.0143\n",
            "Epoch [44/200], Loss: 0.0385, Val Loss: 0.0145\n",
            "Epoch [45/200], Loss: 0.0383, Val Loss: 0.0156\n",
            "Epoch [46/200], Loss: 0.0383, Val Loss: 0.0133\n",
            "Epoch [47/200], Loss: 0.0378, Val Loss: 0.0144\n",
            "Epoch [48/200], Loss: 0.0380, Val Loss: 0.0129\n",
            "Epoch [49/200], Loss: 0.0376, Val Loss: 0.0143\n",
            "Epoch [50/200], Loss: 0.0375, Val Loss: 0.0135\n",
            "Epoch [51/200], Loss: 0.0377, Val Loss: 0.0154\n",
            "Epoch [52/200], Loss: 0.0378, Val Loss: 0.0126\n",
            "Epoch [53/200], Loss: 0.0374, Val Loss: 0.0147\n",
            "Epoch [54/200], Loss: 0.0382, Val Loss: 0.0156\n",
            "Epoch [55/200], Loss: 0.0372, Val Loss: 0.0129\n",
            "Epoch [56/200], Loss: 0.0375, Val Loss: 0.0126\n",
            "Epoch [57/200], Loss: 0.0374, Val Loss: 0.0130\n",
            "Epoch [58/200], Loss: 0.0374, Val Loss: 0.0125\n",
            "Epoch [59/200], Loss: 0.0368, Val Loss: 0.0160\n",
            "Epoch [60/200], Loss: 0.0370, Val Loss: 0.0134\n",
            "Epoch [61/200], Loss: 0.0371, Val Loss: 0.0135\n",
            "Epoch [62/200], Loss: 0.0367, Val Loss: 0.0134\n",
            "Epoch [63/200], Loss: 0.0368, Val Loss: 0.0138\n",
            "Epoch [64/200], Loss: 0.0366, Val Loss: 0.0140\n",
            "Epoch [65/200], Loss: 0.0368, Val Loss: 0.0131\n",
            "Epoch [66/200], Loss: 0.0371, Val Loss: 0.0141\n",
            "Epoch [67/200], Loss: 0.0375, Val Loss: 0.0131\n",
            "Epoch [68/200], Loss: 0.0370, Val Loss: 0.0120\n",
            "Epoch [69/200], Loss: 0.0370, Val Loss: 0.0141\n",
            "Epoch [70/200], Loss: 0.0367, Val Loss: 0.0132\n",
            "Epoch [71/200], Loss: 0.0367, Val Loss: 0.0149\n",
            "Epoch [72/200], Loss: 0.0369, Val Loss: 0.0140\n",
            "Epoch [73/200], Loss: 0.0366, Val Loss: 0.0150\n",
            "Epoch [74/200], Loss: 0.0370, Val Loss: 0.0134\n",
            "Epoch [75/200], Loss: 0.0372, Val Loss: 0.0149\n",
            "Epoch [76/200], Loss: 0.0368, Val Loss: 0.0149\n",
            "Epoch [77/200], Loss: 0.0367, Val Loss: 0.0137\n",
            "Epoch [78/200], Loss: 0.0369, Val Loss: 0.0143\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1230, Val Loss: 0.0492\n",
            "Epoch [2/200], Loss: 0.0792, Val Loss: 0.0330\n",
            "Epoch [3/200], Loss: 0.0708, Val Loss: 0.0306\n",
            "Epoch [4/200], Loss: 0.0672, Val Loss: 0.0303\n",
            "Epoch [5/200], Loss: 0.0636, Val Loss: 0.0295\n",
            "Epoch [6/200], Loss: 0.0607, Val Loss: 0.0252\n",
            "Epoch [7/200], Loss: 0.0576, Val Loss: 0.0223\n",
            "Epoch [8/200], Loss: 0.0548, Val Loss: 0.0202\n",
            "Epoch [9/200], Loss: 0.0524, Val Loss: 0.0206\n",
            "Epoch [10/200], Loss: 0.0504, Val Loss: 0.0202\n",
            "Epoch [11/200], Loss: 0.0490, Val Loss: 0.0201\n",
            "Epoch [12/200], Loss: 0.0483, Val Loss: 0.0197\n",
            "Epoch [13/200], Loss: 0.0466, Val Loss: 0.0185\n",
            "Epoch [14/200], Loss: 0.0463, Val Loss: 0.0194\n",
            "Epoch [15/200], Loss: 0.0446, Val Loss: 0.0171\n",
            "Epoch [16/200], Loss: 0.0435, Val Loss: 0.0153\n",
            "Epoch [17/200], Loss: 0.0421, Val Loss: 0.0149\n",
            "Epoch [18/200], Loss: 0.0416, Val Loss: 0.0135\n",
            "Epoch [19/200], Loss: 0.0397, Val Loss: 0.0125\n",
            "Epoch [20/200], Loss: 0.0397, Val Loss: 0.0123\n",
            "Epoch [21/200], Loss: 0.0384, Val Loss: 0.0161\n",
            "Epoch [22/200], Loss: 0.0390, Val Loss: 0.0150\n",
            "Epoch [23/200], Loss: 0.0382, Val Loss: 0.0144\n",
            "Epoch [24/200], Loss: 0.0379, Val Loss: 0.0130\n",
            "Epoch [25/200], Loss: 0.0378, Val Loss: 0.0158\n",
            "Epoch [26/200], Loss: 0.0374, Val Loss: 0.0122\n",
            "Epoch [27/200], Loss: 0.0369, Val Loss: 0.0145\n",
            "Epoch [28/200], Loss: 0.0371, Val Loss: 0.0136\n",
            "Epoch [29/200], Loss: 0.0367, Val Loss: 0.0137\n",
            "Epoch [30/200], Loss: 0.0361, Val Loss: 0.0130\n",
            "Epoch [31/200], Loss: 0.0371, Val Loss: 0.0145\n",
            "Epoch [32/200], Loss: 0.0365, Val Loss: 0.0139\n",
            "Epoch [33/200], Loss: 0.0367, Val Loss: 0.0126\n",
            "Epoch [34/200], Loss: 0.0361, Val Loss: 0.0143\n",
            "Epoch [35/200], Loss: 0.0367, Val Loss: 0.0137\n",
            "Epoch [36/200], Loss: 0.0363, Val Loss: 0.0142\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1263, Val Loss: 0.0405\n",
            "Epoch [2/200], Loss: 0.0762, Val Loss: 0.0301\n",
            "Epoch [3/200], Loss: 0.0689, Val Loss: 0.0288\n",
            "Epoch [4/200], Loss: 0.0660, Val Loss: 0.0250\n",
            "Epoch [5/200], Loss: 0.0631, Val Loss: 0.0246\n",
            "Epoch [6/200], Loss: 0.0614, Val Loss: 0.0230\n",
            "Epoch [7/200], Loss: 0.0599, Val Loss: 0.0241\n",
            "Epoch [8/200], Loss: 0.0581, Val Loss: 0.0229\n",
            "Epoch [9/200], Loss: 0.0570, Val Loss: 0.0250\n",
            "Epoch [10/200], Loss: 0.0553, Val Loss: 0.0234\n",
            "Epoch [11/200], Loss: 0.0544, Val Loss: 0.0233\n",
            "Epoch [12/200], Loss: 0.0533, Val Loss: 0.0245\n",
            "Epoch [13/200], Loss: 0.0525, Val Loss: 0.0242\n",
            "Epoch [14/200], Loss: 0.0507, Val Loss: 0.0208\n",
            "Epoch [15/200], Loss: 0.0500, Val Loss: 0.0204\n",
            "Epoch [16/200], Loss: 0.0487, Val Loss: 0.0177\n",
            "Epoch [17/200], Loss: 0.0473, Val Loss: 0.0192\n",
            "Epoch [18/200], Loss: 0.0450, Val Loss: 0.0149\n",
            "Epoch [19/200], Loss: 0.0448, Val Loss: 0.0152\n",
            "Epoch [20/200], Loss: 0.0436, Val Loss: 0.0152\n",
            "Epoch [21/200], Loss: 0.0427, Val Loss: 0.0140\n",
            "Epoch [22/200], Loss: 0.0422, Val Loss: 0.0132\n",
            "Epoch [23/200], Loss: 0.0420, Val Loss: 0.0124\n",
            "Epoch [24/200], Loss: 0.0418, Val Loss: 0.0133\n",
            "Epoch [25/200], Loss: 0.0409, Val Loss: 0.0143\n",
            "Epoch [26/200], Loss: 0.0409, Val Loss: 0.0129\n",
            "Epoch [27/200], Loss: 0.0402, Val Loss: 0.0127\n",
            "Epoch [28/200], Loss: 0.0399, Val Loss: 0.0143\n",
            "Epoch [29/200], Loss: 0.0401, Val Loss: 0.0128\n",
            "Epoch [30/200], Loss: 0.0398, Val Loss: 0.0123\n",
            "Epoch [31/200], Loss: 0.0398, Val Loss: 0.0130\n",
            "Epoch [32/200], Loss: 0.0388, Val Loss: 0.0134\n",
            "Epoch [33/200], Loss: 0.0390, Val Loss: 0.0136\n",
            "Epoch [34/200], Loss: 0.0388, Val Loss: 0.0134\n",
            "Epoch [35/200], Loss: 0.0390, Val Loss: 0.0127\n",
            "Epoch [36/200], Loss: 0.0386, Val Loss: 0.0122\n",
            "Epoch [37/200], Loss: 0.0388, Val Loss: 0.0139\n",
            "Epoch [38/200], Loss: 0.0387, Val Loss: 0.0130\n",
            "Epoch [39/200], Loss: 0.0382, Val Loss: 0.0124\n",
            "Epoch [40/200], Loss: 0.0385, Val Loss: 0.0136\n",
            "Epoch [41/200], Loss: 0.0387, Val Loss: 0.0130\n",
            "Epoch [42/200], Loss: 0.0387, Val Loss: 0.0150\n",
            "Epoch [43/200], Loss: 0.0374, Val Loss: 0.0122\n",
            "Epoch [44/200], Loss: 0.0381, Val Loss: 0.0134\n",
            "Epoch [45/200], Loss: 0.0378, Val Loss: 0.0135\n",
            "Epoch [46/200], Loss: 0.0378, Val Loss: 0.0130\n",
            "Epoch [47/200], Loss: 0.0381, Val Loss: 0.0134\n",
            "Epoch [48/200], Loss: 0.0376, Val Loss: 0.0129\n",
            "Epoch [49/200], Loss: 0.0376, Val Loss: 0.0142\n",
            "Epoch [50/200], Loss: 0.0375, Val Loss: 0.0159\n",
            "Epoch [51/200], Loss: 0.0374, Val Loss: 0.0120\n",
            "Epoch [52/200], Loss: 0.0374, Val Loss: 0.0132\n",
            "Epoch [53/200], Loss: 0.0378, Val Loss: 0.0123\n",
            "Epoch [54/200], Loss: 0.0371, Val Loss: 0.0123\n",
            "Epoch [55/200], Loss: 0.0370, Val Loss: 0.0126\n",
            "Epoch [56/200], Loss: 0.0370, Val Loss: 0.0142\n",
            "Epoch [57/200], Loss: 0.0372, Val Loss: 0.0135\n",
            "Epoch [58/200], Loss: 0.0372, Val Loss: 0.0136\n",
            "Epoch [59/200], Loss: 0.0368, Val Loss: 0.0120\n",
            "Epoch [60/200], Loss: 0.0374, Val Loss: 0.0133\n",
            "Epoch [61/200], Loss: 0.0376, Val Loss: 0.0130\n",
            "Epoch [62/200], Loss: 0.0369, Val Loss: 0.0137\n",
            "Epoch [63/200], Loss: 0.0372, Val Loss: 0.0149\n",
            "Epoch [64/200], Loss: 0.0371, Val Loss: 0.0137\n",
            "Epoch [65/200], Loss: 0.0371, Val Loss: 0.0144\n",
            "Epoch [66/200], Loss: 0.0372, Val Loss: 0.0141\n",
            "Epoch [67/200], Loss: 0.0371, Val Loss: 0.0138\n",
            "Epoch [68/200], Loss: 0.0368, Val Loss: 0.0127\n",
            "Epoch [69/200], Loss: 0.0368, Val Loss: 0.0128\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=64, BS=32, Dropout=0.1, EncDim=8 -> MAE=0.0660, Error%=143237739.3991\n",
            "Running: LR=0.001, HS=64, BS=32, Dropout=0.2, EncDim=8\n",
            "77 / 81 completed\n",
            "Epoch [1/200], Loss: 0.1865, Val Loss: 0.0823\n",
            "Epoch [2/200], Loss: 0.1329, Val Loss: 0.0775\n",
            "Epoch [3/200], Loss: 0.1258, Val Loss: 0.0744\n",
            "Epoch [4/200], Loss: 0.1210, Val Loss: 0.0738\n",
            "Epoch [5/200], Loss: 0.1168, Val Loss: 0.0695\n",
            "Epoch [6/200], Loss: 0.1126, Val Loss: 0.0681\n",
            "Epoch [7/200], Loss: 0.1100, Val Loss: 0.0673\n",
            "Epoch [8/200], Loss: 0.1078, Val Loss: 0.0668\n",
            "Epoch [9/200], Loss: 0.1062, Val Loss: 0.0656\n",
            "Epoch [10/200], Loss: 0.1047, Val Loss: 0.0603\n",
            "Epoch [11/200], Loss: 0.1015, Val Loss: 0.0547\n",
            "Epoch [12/200], Loss: 0.0994, Val Loss: 0.0539\n",
            "Epoch [13/200], Loss: 0.0990, Val Loss: 0.0550\n",
            "Epoch [14/200], Loss: 0.0982, Val Loss: 0.0540\n",
            "Epoch [15/200], Loss: 0.0979, Val Loss: 0.0528\n",
            "Epoch [16/200], Loss: 0.0975, Val Loss: 0.0518\n",
            "Epoch [17/200], Loss: 0.0968, Val Loss: 0.0514\n",
            "Epoch [18/200], Loss: 0.0965, Val Loss: 0.0525\n",
            "Epoch [19/200], Loss: 0.0969, Val Loss: 0.0508\n",
            "Epoch [20/200], Loss: 0.0968, Val Loss: 0.0518\n",
            "Epoch [21/200], Loss: 0.0954, Val Loss: 0.0491\n",
            "Epoch [22/200], Loss: 0.0954, Val Loss: 0.0492\n",
            "Epoch [23/200], Loss: 0.0936, Val Loss: 0.0486\n",
            "Epoch [24/200], Loss: 0.0940, Val Loss: 0.0500\n",
            "Epoch [25/200], Loss: 0.0938, Val Loss: 0.0537\n",
            "Epoch [26/200], Loss: 0.0932, Val Loss: 0.0483\n",
            "Epoch [27/200], Loss: 0.0922, Val Loss: 0.0473\n",
            "Epoch [28/200], Loss: 0.0926, Val Loss: 0.0484\n",
            "Epoch [29/200], Loss: 0.0920, Val Loss: 0.0502\n",
            "Epoch [30/200], Loss: 0.0909, Val Loss: 0.0474\n",
            "Epoch [31/200], Loss: 0.0910, Val Loss: 0.0488\n",
            "Epoch [32/200], Loss: 0.0908, Val Loss: 0.0468\n",
            "Epoch [33/200], Loss: 0.0903, Val Loss: 0.0477\n",
            "Epoch [34/200], Loss: 0.0902, Val Loss: 0.0479\n",
            "Epoch [35/200], Loss: 0.0894, Val Loss: 0.0480\n",
            "Epoch [36/200], Loss: 0.0894, Val Loss: 0.0502\n",
            "Epoch [37/200], Loss: 0.0894, Val Loss: 0.0458\n",
            "Epoch [38/200], Loss: 0.0893, Val Loss: 0.0431\n",
            "Epoch [39/200], Loss: 0.0881, Val Loss: 0.0403\n",
            "Epoch [40/200], Loss: 0.0881, Val Loss: 0.0445\n",
            "Epoch [41/200], Loss: 0.0869, Val Loss: 0.0419\n",
            "Epoch [42/200], Loss: 0.0866, Val Loss: 0.0415\n",
            "Epoch [43/200], Loss: 0.0868, Val Loss: 0.0403\n",
            "Epoch [44/200], Loss: 0.0859, Val Loss: 0.0383\n",
            "Epoch [45/200], Loss: 0.0866, Val Loss: 0.0419\n",
            "Epoch [46/200], Loss: 0.0859, Val Loss: 0.0382\n",
            "Epoch [47/200], Loss: 0.0856, Val Loss: 0.0386\n",
            "Epoch [48/200], Loss: 0.0852, Val Loss: 0.0372\n",
            "Epoch [49/200], Loss: 0.0849, Val Loss: 0.0367\n",
            "Epoch [50/200], Loss: 0.0845, Val Loss: 0.0375\n",
            "Epoch [51/200], Loss: 0.0853, Val Loss: 0.0396\n",
            "Epoch [52/200], Loss: 0.0851, Val Loss: 0.0390\n",
            "Epoch [53/200], Loss: 0.0846, Val Loss: 0.0374\n",
            "Epoch [54/200], Loss: 0.0851, Val Loss: 0.0385\n",
            "Epoch [55/200], Loss: 0.0834, Val Loss: 0.0371\n",
            "Epoch [56/200], Loss: 0.0834, Val Loss: 0.0377\n",
            "Epoch [57/200], Loss: 0.0828, Val Loss: 0.0401\n",
            "Epoch [58/200], Loss: 0.0833, Val Loss: 0.0387\n",
            "Epoch [59/200], Loss: 0.0820, Val Loss: 0.0383\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1829, Val Loss: 0.0794\n",
            "Epoch [2/200], Loss: 0.1347, Val Loss: 0.0793\n",
            "Epoch [3/200], Loss: 0.1276, Val Loss: 0.0738\n",
            "Epoch [4/200], Loss: 0.1247, Val Loss: 0.0714\n",
            "Epoch [5/200], Loss: 0.1231, Val Loss: 0.0718\n",
            "Epoch [6/200], Loss: 0.1203, Val Loss: 0.0668\n",
            "Epoch [7/200], Loss: 0.1155, Val Loss: 0.0610\n",
            "Epoch [8/200], Loss: 0.1130, Val Loss: 0.0605\n",
            "Epoch [9/200], Loss: 0.1113, Val Loss: 0.0613\n",
            "Epoch [10/200], Loss: 0.1093, Val Loss: 0.0565\n",
            "Epoch [11/200], Loss: 0.1071, Val Loss: 0.0570\n",
            "Epoch [12/200], Loss: 0.1056, Val Loss: 0.0531\n",
            "Epoch [13/200], Loss: 0.1036, Val Loss: 0.0525\n",
            "Epoch [14/200], Loss: 0.1022, Val Loss: 0.0506\n",
            "Epoch [15/200], Loss: 0.1010, Val Loss: 0.0496\n",
            "Epoch [16/200], Loss: 0.0991, Val Loss: 0.0490\n",
            "Epoch [17/200], Loss: 0.0989, Val Loss: 0.0479\n",
            "Epoch [18/200], Loss: 0.0980, Val Loss: 0.0475\n",
            "Epoch [19/200], Loss: 0.0971, Val Loss: 0.0482\n",
            "Epoch [20/200], Loss: 0.0962, Val Loss: 0.0469\n",
            "Epoch [21/200], Loss: 0.0950, Val Loss: 0.0465\n",
            "Epoch [22/200], Loss: 0.0946, Val Loss: 0.0450\n",
            "Epoch [23/200], Loss: 0.0938, Val Loss: 0.0461\n",
            "Epoch [24/200], Loss: 0.0932, Val Loss: 0.0438\n",
            "Epoch [25/200], Loss: 0.0923, Val Loss: 0.0441\n",
            "Epoch [26/200], Loss: 0.0920, Val Loss: 0.0452\n",
            "Epoch [27/200], Loss: 0.0913, Val Loss: 0.0433\n",
            "Epoch [28/200], Loss: 0.0904, Val Loss: 0.0423\n",
            "Epoch [29/200], Loss: 0.0902, Val Loss: 0.0423\n",
            "Epoch [30/200], Loss: 0.0894, Val Loss: 0.0405\n",
            "Epoch [31/200], Loss: 0.0893, Val Loss: 0.0394\n",
            "Epoch [32/200], Loss: 0.0885, Val Loss: 0.0381\n",
            "Epoch [33/200], Loss: 0.0877, Val Loss: 0.0397\n",
            "Epoch [34/200], Loss: 0.0872, Val Loss: 0.0373\n",
            "Epoch [35/200], Loss: 0.0862, Val Loss: 0.0396\n",
            "Epoch [36/200], Loss: 0.0858, Val Loss: 0.0366\n",
            "Epoch [37/200], Loss: 0.0856, Val Loss: 0.0365\n",
            "Epoch [38/200], Loss: 0.0846, Val Loss: 0.0387\n",
            "Epoch [39/200], Loss: 0.0856, Val Loss: 0.0364\n",
            "Epoch [40/200], Loss: 0.0848, Val Loss: 0.0375\n",
            "Epoch [41/200], Loss: 0.0849, Val Loss: 0.0364\n",
            "Epoch [42/200], Loss: 0.0846, Val Loss: 0.0371\n",
            "Epoch [43/200], Loss: 0.0837, Val Loss: 0.0367\n",
            "Epoch [44/200], Loss: 0.0850, Val Loss: 0.0388\n",
            "Epoch [45/200], Loss: 0.0836, Val Loss: 0.0363\n",
            "Epoch [46/200], Loss: 0.0827, Val Loss: 0.0365\n",
            "Epoch [47/200], Loss: 0.0834, Val Loss: 0.0384\n",
            "Epoch [48/200], Loss: 0.0828, Val Loss: 0.0356\n",
            "Epoch [49/200], Loss: 0.0833, Val Loss: 0.0351\n",
            "Epoch [50/200], Loss: 0.0838, Val Loss: 0.0376\n",
            "Epoch [51/200], Loss: 0.0837, Val Loss: 0.0378\n",
            "Epoch [52/200], Loss: 0.0832, Val Loss: 0.0386\n",
            "Epoch [53/200], Loss: 0.0833, Val Loss: 0.0358\n",
            "Epoch [54/200], Loss: 0.0821, Val Loss: 0.0357\n",
            "Epoch [55/200], Loss: 0.0830, Val Loss: 0.0384\n",
            "Epoch [56/200], Loss: 0.0822, Val Loss: 0.0366\n",
            "Epoch [57/200], Loss: 0.0825, Val Loss: 0.0361\n",
            "Epoch [58/200], Loss: 0.0824, Val Loss: 0.0358\n",
            "Epoch [59/200], Loss: 0.0828, Val Loss: 0.0366\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1775, Val Loss: 0.0846\n",
            "Epoch [2/200], Loss: 0.1346, Val Loss: 0.0767\n",
            "Epoch [3/200], Loss: 0.1276, Val Loss: 0.0683\n",
            "Epoch [4/200], Loss: 0.1213, Val Loss: 0.0649\n",
            "Epoch [5/200], Loss: 0.1174, Val Loss: 0.0616\n",
            "Epoch [6/200], Loss: 0.1148, Val Loss: 0.0628\n",
            "Epoch [7/200], Loss: 0.1125, Val Loss: 0.0553\n",
            "Epoch [8/200], Loss: 0.1095, Val Loss: 0.0541\n",
            "Epoch [9/200], Loss: 0.1077, Val Loss: 0.0547\n",
            "Epoch [10/200], Loss: 0.1065, Val Loss: 0.0536\n",
            "Epoch [11/200], Loss: 0.1052, Val Loss: 0.0530\n",
            "Epoch [12/200], Loss: 0.1034, Val Loss: 0.0493\n",
            "Epoch [13/200], Loss: 0.1014, Val Loss: 0.0508\n",
            "Epoch [14/200], Loss: 0.1006, Val Loss: 0.0502\n",
            "Epoch [15/200], Loss: 0.0986, Val Loss: 0.0474\n",
            "Epoch [16/200], Loss: 0.0975, Val Loss: 0.0496\n",
            "Epoch [17/200], Loss: 0.0972, Val Loss: 0.0445\n",
            "Epoch [18/200], Loss: 0.0964, Val Loss: 0.0452\n",
            "Epoch [19/200], Loss: 0.0952, Val Loss: 0.0459\n",
            "Epoch [20/200], Loss: 0.0948, Val Loss: 0.0425\n",
            "Epoch [21/200], Loss: 0.0933, Val Loss: 0.0447\n",
            "Epoch [22/200], Loss: 0.0932, Val Loss: 0.0422\n",
            "Epoch [23/200], Loss: 0.0922, Val Loss: 0.0439\n",
            "Epoch [24/200], Loss: 0.0912, Val Loss: 0.0415\n",
            "Epoch [25/200], Loss: 0.0899, Val Loss: 0.0422\n",
            "Epoch [26/200], Loss: 0.0907, Val Loss: 0.0418\n",
            "Epoch [27/200], Loss: 0.0898, Val Loss: 0.0427\n",
            "Epoch [28/200], Loss: 0.0898, Val Loss: 0.0427\n",
            "Epoch [29/200], Loss: 0.0894, Val Loss: 0.0425\n",
            "Epoch [30/200], Loss: 0.0886, Val Loss: 0.0420\n",
            "Epoch [31/200], Loss: 0.0891, Val Loss: 0.0400\n",
            "Epoch [32/200], Loss: 0.0877, Val Loss: 0.0410\n",
            "Epoch [33/200], Loss: 0.0876, Val Loss: 0.0403\n",
            "Epoch [34/200], Loss: 0.0876, Val Loss: 0.0437\n",
            "Epoch [35/200], Loss: 0.0875, Val Loss: 0.0394\n",
            "Epoch [36/200], Loss: 0.0870, Val Loss: 0.0398\n",
            "Epoch [37/200], Loss: 0.0867, Val Loss: 0.0412\n",
            "Epoch [38/200], Loss: 0.0866, Val Loss: 0.0405\n",
            "Epoch [39/200], Loss: 0.0864, Val Loss: 0.0388\n",
            "Epoch [40/200], Loss: 0.0862, Val Loss: 0.0402\n",
            "Epoch [41/200], Loss: 0.0868, Val Loss: 0.0371\n",
            "Epoch [42/200], Loss: 0.0860, Val Loss: 0.0397\n",
            "Epoch [43/200], Loss: 0.0852, Val Loss: 0.0396\n",
            "Epoch [44/200], Loss: 0.0849, Val Loss: 0.0398\n",
            "Epoch [45/200], Loss: 0.0850, Val Loss: 0.0396\n",
            "Epoch [46/200], Loss: 0.0842, Val Loss: 0.0392\n",
            "Epoch [47/200], Loss: 0.0849, Val Loss: 0.0405\n",
            "Epoch [48/200], Loss: 0.0843, Val Loss: 0.0392\n",
            "Epoch [49/200], Loss: 0.0841, Val Loss: 0.0400\n",
            "Epoch [50/200], Loss: 0.0839, Val Loss: 0.0393\n",
            "Epoch [51/200], Loss: 0.0845, Val Loss: 0.0382\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1769, Val Loss: 0.0809\n",
            "Epoch [2/200], Loss: 0.1318, Val Loss: 0.0751\n",
            "Epoch [3/200], Loss: 0.1261, Val Loss: 0.0740\n",
            "Epoch [4/200], Loss: 0.1228, Val Loss: 0.0739\n",
            "Epoch [5/200], Loss: 0.1213, Val Loss: 0.0704\n",
            "Epoch [6/200], Loss: 0.1194, Val Loss: 0.0681\n",
            "Epoch [7/200], Loss: 0.1160, Val Loss: 0.0603\n",
            "Epoch [8/200], Loss: 0.1134, Val Loss: 0.0644\n",
            "Epoch [9/200], Loss: 0.1123, Val Loss: 0.0546\n",
            "Epoch [10/200], Loss: 0.1117, Val Loss: 0.0562\n",
            "Epoch [11/200], Loss: 0.1094, Val Loss: 0.0552\n",
            "Epoch [12/200], Loss: 0.1076, Val Loss: 0.0523\n",
            "Epoch [13/200], Loss: 0.1053, Val Loss: 0.0512\n",
            "Epoch [14/200], Loss: 0.1036, Val Loss: 0.0485\n",
            "Epoch [15/200], Loss: 0.1018, Val Loss: 0.0493\n",
            "Epoch [16/200], Loss: 0.1007, Val Loss: 0.0489\n",
            "Epoch [17/200], Loss: 0.0988, Val Loss: 0.0446\n",
            "Epoch [18/200], Loss: 0.0965, Val Loss: 0.0470\n",
            "Epoch [19/200], Loss: 0.0962, Val Loss: 0.0469\n",
            "Epoch [20/200], Loss: 0.0947, Val Loss: 0.0441\n",
            "Epoch [21/200], Loss: 0.0934, Val Loss: 0.0438\n",
            "Epoch [22/200], Loss: 0.0928, Val Loss: 0.0414\n",
            "Epoch [23/200], Loss: 0.0917, Val Loss: 0.0431\n",
            "Epoch [24/200], Loss: 0.0916, Val Loss: 0.0392\n",
            "Epoch [25/200], Loss: 0.0906, Val Loss: 0.0411\n",
            "Epoch [26/200], Loss: 0.0909, Val Loss: 0.0424\n",
            "Epoch [27/200], Loss: 0.0907, Val Loss: 0.0413\n",
            "Epoch [28/200], Loss: 0.0900, Val Loss: 0.0408\n",
            "Epoch [29/200], Loss: 0.0900, Val Loss: 0.0397\n",
            "Epoch [30/200], Loss: 0.0892, Val Loss: 0.0430\n",
            "Epoch [31/200], Loss: 0.0886, Val Loss: 0.0404\n",
            "Epoch [32/200], Loss: 0.0894, Val Loss: 0.0428\n",
            "Epoch [33/200], Loss: 0.0887, Val Loss: 0.0396\n",
            "Epoch [34/200], Loss: 0.0878, Val Loss: 0.0401\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1773, Val Loss: 0.0799\n",
            "Epoch [2/200], Loss: 0.1321, Val Loss: 0.0781\n",
            "Epoch [3/200], Loss: 0.1256, Val Loss: 0.0780\n",
            "Epoch [4/200], Loss: 0.1221, Val Loss: 0.0793\n",
            "Epoch [5/200], Loss: 0.1187, Val Loss: 0.0752\n",
            "Epoch [6/200], Loss: 0.1164, Val Loss: 0.0711\n",
            "Epoch [7/200], Loss: 0.1131, Val Loss: 0.0739\n",
            "Epoch [8/200], Loss: 0.1109, Val Loss: 0.0691\n",
            "Epoch [9/200], Loss: 0.1094, Val Loss: 0.0716\n",
            "Epoch [10/200], Loss: 0.1082, Val Loss: 0.0710\n",
            "Epoch [11/200], Loss: 0.1078, Val Loss: 0.0683\n",
            "Epoch [12/200], Loss: 0.1054, Val Loss: 0.0636\n",
            "Epoch [13/200], Loss: 0.1022, Val Loss: 0.0598\n",
            "Epoch [14/200], Loss: 0.1008, Val Loss: 0.0573\n",
            "Epoch [15/200], Loss: 0.1007, Val Loss: 0.0601\n",
            "Epoch [16/200], Loss: 0.0997, Val Loss: 0.0560\n",
            "Epoch [17/200], Loss: 0.0990, Val Loss: 0.0565\n",
            "Epoch [18/200], Loss: 0.0974, Val Loss: 0.0523\n",
            "Epoch [19/200], Loss: 0.0952, Val Loss: 0.0517\n",
            "Epoch [20/200], Loss: 0.0944, Val Loss: 0.0517\n",
            "Epoch [21/200], Loss: 0.0932, Val Loss: 0.0465\n",
            "Epoch [22/200], Loss: 0.0912, Val Loss: 0.0484\n",
            "Epoch [23/200], Loss: 0.0914, Val Loss: 0.0471\n",
            "Epoch [24/200], Loss: 0.0899, Val Loss: 0.0453\n",
            "Epoch [25/200], Loss: 0.0885, Val Loss: 0.0429\n",
            "Epoch [26/200], Loss: 0.0876, Val Loss: 0.0426\n",
            "Epoch [27/200], Loss: 0.0882, Val Loss: 0.0422\n",
            "Epoch [28/200], Loss: 0.0866, Val Loss: 0.0419\n",
            "Epoch [29/200], Loss: 0.0865, Val Loss: 0.0424\n",
            "Epoch [30/200], Loss: 0.0858, Val Loss: 0.0414\n",
            "Epoch [31/200], Loss: 0.0860, Val Loss: 0.0414\n",
            "Epoch [32/200], Loss: 0.0854, Val Loss: 0.0390\n",
            "Epoch [33/200], Loss: 0.0857, Val Loss: 0.0417\n",
            "Epoch [34/200], Loss: 0.0850, Val Loss: 0.0408\n",
            "Epoch [35/200], Loss: 0.0844, Val Loss: 0.0407\n",
            "Epoch [36/200], Loss: 0.0853, Val Loss: 0.0402\n",
            "Epoch [37/200], Loss: 0.0844, Val Loss: 0.0414\n",
            "Epoch [38/200], Loss: 0.0844, Val Loss: 0.0391\n",
            "Epoch [39/200], Loss: 0.0832, Val Loss: 0.0402\n",
            "Epoch [40/200], Loss: 0.0839, Val Loss: 0.0422\n",
            "Epoch [41/200], Loss: 0.0830, Val Loss: 0.0399\n",
            "Epoch [42/200], Loss: 0.0835, Val Loss: 0.0389\n",
            "Epoch [43/200], Loss: 0.0832, Val Loss: 0.0420\n",
            "Epoch [44/200], Loss: 0.0827, Val Loss: 0.0400\n",
            "Epoch [45/200], Loss: 0.0837, Val Loss: 0.0408\n",
            "Epoch [46/200], Loss: 0.0831, Val Loss: 0.0398\n",
            "Epoch [47/200], Loss: 0.0828, Val Loss: 0.0409\n",
            "Epoch [48/200], Loss: 0.0826, Val Loss: 0.0399\n",
            "Epoch [49/200], Loss: 0.0824, Val Loss: 0.0414\n",
            "Epoch [50/200], Loss: 0.0832, Val Loss: 0.0386\n",
            "Epoch [51/200], Loss: 0.0830, Val Loss: 0.0394\n",
            "Epoch [52/200], Loss: 0.0827, Val Loss: 0.0392\n",
            "Epoch [53/200], Loss: 0.0834, Val Loss: 0.0400\n",
            "Epoch [54/200], Loss: 0.0825, Val Loss: 0.0411\n",
            "Epoch [55/200], Loss: 0.0827, Val Loss: 0.0372\n",
            "Epoch [56/200], Loss: 0.0820, Val Loss: 0.0391\n",
            "Epoch [57/200], Loss: 0.0820, Val Loss: 0.0406\n",
            "Epoch [58/200], Loss: 0.0827, Val Loss: 0.0403\n",
            "Epoch [59/200], Loss: 0.0829, Val Loss: 0.0373\n",
            "Epoch [60/200], Loss: 0.0822, Val Loss: 0.0397\n",
            "Epoch [61/200], Loss: 0.0821, Val Loss: 0.0411\n",
            "Epoch [62/200], Loss: 0.0821, Val Loss: 0.0418\n",
            "Epoch [63/200], Loss: 0.0813, Val Loss: 0.0406\n",
            "Epoch [64/200], Loss: 0.0820, Val Loss: 0.0395\n",
            "Epoch [65/200], Loss: 0.0818, Val Loss: 0.0386\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=64, BS=32, Dropout=0.2, EncDim=8 -> MAE=0.1110, Error%=320494927.5059\n",
            "Running: LR=0.001, HS=64, BS=64, Dropout=0.0, EncDim=8\n",
            "78 / 81 completed\n",
            "Epoch [1/200], Loss: 0.0634, Val Loss: 0.0165\n",
            "Epoch [2/200], Loss: 0.0096, Val Loss: 0.0060\n",
            "Epoch [3/200], Loss: 0.0035, Val Loss: 0.0025\n",
            "Epoch [4/200], Loss: 0.0022, Val Loss: 0.0019\n",
            "Epoch [5/200], Loss: 0.0019, Val Loss: 0.0020\n",
            "Epoch [6/200], Loss: 0.0017, Val Loss: 0.0018\n",
            "Epoch [7/200], Loss: 0.0016, Val Loss: 0.0015\n",
            "Epoch [8/200], Loss: 0.0015, Val Loss: 0.0020\n",
            "Epoch [9/200], Loss: 0.0015, Val Loss: 0.0015\n",
            "Epoch [10/200], Loss: 0.0014, Val Loss: 0.0017\n",
            "Epoch [11/200], Loss: 0.0014, Val Loss: 0.0014\n",
            "Epoch [12/200], Loss: 0.0013, Val Loss: 0.0012\n",
            "Epoch [13/200], Loss: 0.0012, Val Loss: 0.0011\n",
            "Epoch [14/200], Loss: 0.0011, Val Loss: 0.0010\n",
            "Epoch [15/200], Loss: 0.0010, Val Loss: 0.0012\n",
            "Epoch [16/200], Loss: 0.0009, Val Loss: 0.0009\n",
            "Epoch [17/200], Loss: 0.0009, Val Loss: 0.0010\n",
            "Epoch [18/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [19/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [20/200], Loss: 0.0007, Val Loss: 0.0008\n",
            "Epoch [21/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [22/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [23/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [24/200], Loss: 0.0005, Val Loss: 0.0007\n",
            "Epoch [25/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [26/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [27/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [28/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [29/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [30/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [31/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [32/200], Loss: 0.0004, Val Loss: 0.0013\n",
            "Epoch [33/200], Loss: 0.0004, Val Loss: 0.0006\n",
            "Epoch [34/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [35/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [36/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [37/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [38/200], Loss: 0.0004, Val Loss: 0.0006\n",
            "Epoch [39/200], Loss: 0.0004, Val Loss: 0.0006\n",
            "Epoch [40/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [41/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [42/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [43/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [44/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [45/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [46/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [47/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [48/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [49/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [50/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [51/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [52/200], Loss: 0.0003, Val Loss: 0.0009\n",
            "Epoch [53/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [54/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [55/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [56/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [57/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [58/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [59/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [60/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [61/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [62/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [63/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [64/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [65/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [66/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [67/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [68/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [69/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [70/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [71/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [72/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [73/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [74/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [75/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [76/200], Loss: 0.0001, Val Loss: 0.0007\n",
            "Epoch [77/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [78/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [79/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [80/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [81/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [82/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [83/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [84/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [85/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [86/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [87/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [88/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [89/200], Loss: 0.0002, Val Loss: 0.0000\n",
            "Epoch [90/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [91/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [92/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [93/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [94/200], Loss: 0.0001, Val Loss: 0.0004\n",
            "Epoch [95/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [96/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [97/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [98/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0682, Val Loss: 0.0126\n",
            "Epoch [2/200], Loss: 0.0079, Val Loss: 0.0059\n",
            "Epoch [3/200], Loss: 0.0047, Val Loss: 0.0032\n",
            "Epoch [4/200], Loss: 0.0023, Val Loss: 0.0019\n",
            "Epoch [5/200], Loss: 0.0018, Val Loss: 0.0015\n",
            "Epoch [6/200], Loss: 0.0015, Val Loss: 0.0014\n",
            "Epoch [7/200], Loss: 0.0014, Val Loss: 0.0013\n",
            "Epoch [8/200], Loss: 0.0013, Val Loss: 0.0012\n",
            "Epoch [9/200], Loss: 0.0012, Val Loss: 0.0012\n",
            "Epoch [10/200], Loss: 0.0011, Val Loss: 0.0010\n",
            "Epoch [11/200], Loss: 0.0011, Val Loss: 0.0009\n",
            "Epoch [12/200], Loss: 0.0010, Val Loss: 0.0010\n",
            "Epoch [13/200], Loss: 0.0010, Val Loss: 0.0009\n",
            "Epoch [14/200], Loss: 0.0010, Val Loss: 0.0011\n",
            "Epoch [15/200], Loss: 0.0009, Val Loss: 0.0010\n",
            "Epoch [16/200], Loss: 0.0009, Val Loss: 0.0009\n",
            "Epoch [17/200], Loss: 0.0008, Val Loss: 0.0009\n",
            "Epoch [18/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [19/200], Loss: 0.0007, Val Loss: 0.0006\n",
            "Epoch [20/200], Loss: 0.0006, Val Loss: 0.0007\n",
            "Epoch [21/200], Loss: 0.0006, Val Loss: 0.0007\n",
            "Epoch [22/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [23/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [24/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [25/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [26/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [27/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [28/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [29/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [30/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [31/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [32/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [33/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [34/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [35/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [36/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [37/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [38/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [39/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [40/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [41/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [42/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [43/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [44/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [45/200], Loss: 0.0002, Val Loss: 0.0004\n",
            "Epoch [46/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [47/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [48/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [49/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [50/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [51/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [52/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [53/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [54/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [55/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [56/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [57/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [58/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [59/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [60/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [61/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [62/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [63/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [64/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [65/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [66/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [67/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [68/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [69/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [70/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [71/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [72/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [73/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [74/200], Loss: 0.0001, Val Loss: 0.0000\n",
            "Epoch [75/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [76/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0728, Val Loss: 0.0152\n",
            "Epoch [2/200], Loss: 0.0102, Val Loss: 0.0076\n",
            "Epoch [3/200], Loss: 0.0060, Val Loss: 0.0053\n",
            "Epoch [4/200], Loss: 0.0049, Val Loss: 0.0050\n",
            "Epoch [5/200], Loss: 0.0045, Val Loss: 0.0047\n",
            "Epoch [6/200], Loss: 0.0039, Val Loss: 0.0032\n",
            "Epoch [7/200], Loss: 0.0024, Val Loss: 0.0021\n",
            "Epoch [8/200], Loss: 0.0020, Val Loss: 0.0018\n",
            "Epoch [9/200], Loss: 0.0019, Val Loss: 0.0020\n",
            "Epoch [10/200], Loss: 0.0018, Val Loss: 0.0020\n",
            "Epoch [11/200], Loss: 0.0016, Val Loss: 0.0016\n",
            "Epoch [12/200], Loss: 0.0015, Val Loss: 0.0015\n",
            "Epoch [13/200], Loss: 0.0013, Val Loss: 0.0016\n",
            "Epoch [14/200], Loss: 0.0012, Val Loss: 0.0011\n",
            "Epoch [15/200], Loss: 0.0011, Val Loss: 0.0010\n",
            "Epoch [16/200], Loss: 0.0010, Val Loss: 0.0009\n",
            "Epoch [17/200], Loss: 0.0010, Val Loss: 0.0009\n",
            "Epoch [18/200], Loss: 0.0009, Val Loss: 0.0010\n",
            "Epoch [19/200], Loss: 0.0009, Val Loss: 0.0010\n",
            "Epoch [20/200], Loss: 0.0009, Val Loss: 0.0010\n",
            "Epoch [21/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [22/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [23/200], Loss: 0.0007, Val Loss: 0.0005\n",
            "Epoch [24/200], Loss: 0.0006, Val Loss: 0.0007\n",
            "Epoch [25/200], Loss: 0.0006, Val Loss: 0.0005\n",
            "Epoch [26/200], Loss: 0.0005, Val Loss: 0.0006\n",
            "Epoch [27/200], Loss: 0.0005, Val Loss: 0.0007\n",
            "Epoch [28/200], Loss: 0.0005, Val Loss: 0.0003\n",
            "Epoch [29/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [30/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [31/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [32/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [33/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [34/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [35/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [36/200], Loss: 0.0004, Val Loss: 0.0011\n",
            "Epoch [37/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [38/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [39/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [40/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [41/200], Loss: 0.0003, Val Loss: 0.0005\n",
            "Epoch [42/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [43/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [44/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [45/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [46/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [47/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [48/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [49/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [50/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [51/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [52/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0704, Val Loss: 0.0177\n",
            "Epoch [2/200], Loss: 0.0120, Val Loss: 0.0069\n",
            "Epoch [3/200], Loss: 0.0056, Val Loss: 0.0049\n",
            "Epoch [4/200], Loss: 0.0046, Val Loss: 0.0042\n",
            "Epoch [5/200], Loss: 0.0032, Val Loss: 0.0027\n",
            "Epoch [6/200], Loss: 0.0020, Val Loss: 0.0019\n",
            "Epoch [7/200], Loss: 0.0017, Val Loss: 0.0017\n",
            "Epoch [8/200], Loss: 0.0015, Val Loss: 0.0014\n",
            "Epoch [9/200], Loss: 0.0014, Val Loss: 0.0013\n",
            "Epoch [10/200], Loss: 0.0014, Val Loss: 0.0012\n",
            "Epoch [11/200], Loss: 0.0013, Val Loss: 0.0016\n",
            "Epoch [12/200], Loss: 0.0012, Val Loss: 0.0012\n",
            "Epoch [13/200], Loss: 0.0012, Val Loss: 0.0022\n",
            "Epoch [14/200], Loss: 0.0011, Val Loss: 0.0014\n",
            "Epoch [15/200], Loss: 0.0011, Val Loss: 0.0011\n",
            "Epoch [16/200], Loss: 0.0011, Val Loss: 0.0010\n",
            "Epoch [17/200], Loss: 0.0010, Val Loss: 0.0010\n",
            "Epoch [18/200], Loss: 0.0009, Val Loss: 0.0011\n",
            "Epoch [19/200], Loss: 0.0009, Val Loss: 0.0009\n",
            "Epoch [20/200], Loss: 0.0009, Val Loss: 0.0009\n",
            "Epoch [21/200], Loss: 0.0008, Val Loss: 0.0010\n",
            "Epoch [22/200], Loss: 0.0008, Val Loss: 0.0009\n",
            "Epoch [23/200], Loss: 0.0008, Val Loss: 0.0009\n",
            "Epoch [24/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [25/200], Loss: 0.0008, Val Loss: 0.0008\n",
            "Epoch [26/200], Loss: 0.0007, Val Loss: 0.0007\n",
            "Epoch [27/200], Loss: 0.0006, Val Loss: 0.0008\n",
            "Epoch [28/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [29/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [30/200], Loss: 0.0005, Val Loss: 0.0004\n",
            "Epoch [31/200], Loss: 0.0004, Val Loss: 0.0005\n",
            "Epoch [32/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [33/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [34/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [35/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [36/200], Loss: 0.0003, Val Loss: 0.0005\n",
            "Epoch [37/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [38/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [39/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [40/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [41/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [42/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [43/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [44/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [45/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [46/200], Loss: 0.0002, Val Loss: 0.0004\n",
            "Epoch [47/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [48/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [49/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [50/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [51/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [52/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [53/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [54/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [55/200], Loss: 0.0001, Val Loss: 0.0003\n",
            "Epoch [56/200], Loss: 0.0001, Val Loss: 0.0002\n",
            "Epoch [57/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [58/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Epoch [59/200], Loss: 0.0001, Val Loss: 0.0001\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.0737, Val Loss: 0.0214\n",
            "Epoch [2/200], Loss: 0.0152, Val Loss: 0.0097\n",
            "Epoch [3/200], Loss: 0.0081, Val Loss: 0.0063\n",
            "Epoch [4/200], Loss: 0.0041, Val Loss: 0.0028\n",
            "Epoch [5/200], Loss: 0.0021, Val Loss: 0.0019\n",
            "Epoch [6/200], Loss: 0.0018, Val Loss: 0.0016\n",
            "Epoch [7/200], Loss: 0.0015, Val Loss: 0.0019\n",
            "Epoch [8/200], Loss: 0.0014, Val Loss: 0.0014\n",
            "Epoch [9/200], Loss: 0.0013, Val Loss: 0.0013\n",
            "Epoch [10/200], Loss: 0.0011, Val Loss: 0.0016\n",
            "Epoch [11/200], Loss: 0.0010, Val Loss: 0.0008\n",
            "Epoch [12/200], Loss: 0.0008, Val Loss: 0.0007\n",
            "Epoch [13/200], Loss: 0.0006, Val Loss: 0.0006\n",
            "Epoch [14/200], Loss: 0.0005, Val Loss: 0.0005\n",
            "Epoch [15/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [16/200], Loss: 0.0004, Val Loss: 0.0006\n",
            "Epoch [17/200], Loss: 0.0004, Val Loss: 0.0003\n",
            "Epoch [18/200], Loss: 0.0004, Val Loss: 0.0004\n",
            "Epoch [19/200], Loss: 0.0003, Val Loss: 0.0003\n",
            "Epoch [20/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [21/200], Loss: 0.0003, Val Loss: 0.0004\n",
            "Epoch [22/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [23/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [24/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [25/200], Loss: 0.0003, Val Loss: 0.0007\n",
            "Epoch [26/200], Loss: 0.0002, Val Loss: 0.0001\n",
            "Epoch [27/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [28/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [29/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [30/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [31/200], Loss: 0.0003, Val Loss: 0.0002\n",
            "Epoch [32/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [33/200], Loss: 0.0002, Val Loss: 0.0003\n",
            "Epoch [34/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [35/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Epoch [36/200], Loss: 0.0002, Val Loss: 0.0002\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=64, BS=64, Dropout=0.0, EncDim=8 -> MAE=0.0069, Error%=27502914.2854\n",
            "Running: LR=0.001, HS=64, BS=64, Dropout=0.1, EncDim=8\n",
            "79 / 81 completed\n",
            "Epoch [1/200], Loss: 0.1479, Val Loss: 0.0511\n",
            "Epoch [2/200], Loss: 0.0837, Val Loss: 0.0338\n",
            "Epoch [3/200], Loss: 0.0741, Val Loss: 0.0321\n",
            "Epoch [4/200], Loss: 0.0695, Val Loss: 0.0303\n",
            "Epoch [5/200], Loss: 0.0663, Val Loss: 0.0296\n",
            "Epoch [6/200], Loss: 0.0641, Val Loss: 0.0290\n",
            "Epoch [7/200], Loss: 0.0627, Val Loss: 0.0281\n",
            "Epoch [8/200], Loss: 0.0611, Val Loss: 0.0276\n",
            "Epoch [9/200], Loss: 0.0597, Val Loss: 0.0250\n",
            "Epoch [10/200], Loss: 0.0567, Val Loss: 0.0255\n",
            "Epoch [11/200], Loss: 0.0555, Val Loss: 0.0214\n",
            "Epoch [12/200], Loss: 0.0542, Val Loss: 0.0212\n",
            "Epoch [13/200], Loss: 0.0525, Val Loss: 0.0212\n",
            "Epoch [14/200], Loss: 0.0515, Val Loss: 0.0223\n",
            "Epoch [15/200], Loss: 0.0504, Val Loss: 0.0197\n",
            "Epoch [16/200], Loss: 0.0495, Val Loss: 0.0208\n",
            "Epoch [17/200], Loss: 0.0488, Val Loss: 0.0205\n",
            "Epoch [18/200], Loss: 0.0484, Val Loss: 0.0192\n",
            "Epoch [19/200], Loss: 0.0478, Val Loss: 0.0191\n",
            "Epoch [20/200], Loss: 0.0476, Val Loss: 0.0179\n",
            "Epoch [21/200], Loss: 0.0472, Val Loss: 0.0183\n",
            "Epoch [22/200], Loss: 0.0466, Val Loss: 0.0171\n",
            "Epoch [23/200], Loss: 0.0462, Val Loss: 0.0180\n",
            "Epoch [24/200], Loss: 0.0456, Val Loss: 0.0184\n",
            "Epoch [25/200], Loss: 0.0453, Val Loss: 0.0190\n",
            "Epoch [26/200], Loss: 0.0448, Val Loss: 0.0176\n",
            "Epoch [27/200], Loss: 0.0445, Val Loss: 0.0187\n",
            "Epoch [28/200], Loss: 0.0441, Val Loss: 0.0186\n",
            "Epoch [29/200], Loss: 0.0439, Val Loss: 0.0183\n",
            "Epoch [30/200], Loss: 0.0434, Val Loss: 0.0175\n",
            "Epoch [31/200], Loss: 0.0438, Val Loss: 0.0195\n",
            "Epoch [32/200], Loss: 0.0437, Val Loss: 0.0182\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1468, Val Loss: 0.0542\n",
            "Epoch [2/200], Loss: 0.0899, Val Loss: 0.0500\n",
            "Epoch [3/200], Loss: 0.0834, Val Loss: 0.0478\n",
            "Epoch [4/200], Loss: 0.0795, Val Loss: 0.0415\n",
            "Epoch [5/200], Loss: 0.0702, Val Loss: 0.0341\n",
            "Epoch [6/200], Loss: 0.0669, Val Loss: 0.0292\n",
            "Epoch [7/200], Loss: 0.0647, Val Loss: 0.0293\n",
            "Epoch [8/200], Loss: 0.0625, Val Loss: 0.0277\n",
            "Epoch [9/200], Loss: 0.0615, Val Loss: 0.0264\n",
            "Epoch [10/200], Loss: 0.0593, Val Loss: 0.0241\n",
            "Epoch [11/200], Loss: 0.0579, Val Loss: 0.0240\n",
            "Epoch [12/200], Loss: 0.0563, Val Loss: 0.0233\n",
            "Epoch [13/200], Loss: 0.0554, Val Loss: 0.0233\n",
            "Epoch [14/200], Loss: 0.0542, Val Loss: 0.0218\n",
            "Epoch [15/200], Loss: 0.0531, Val Loss: 0.0214\n",
            "Epoch [16/200], Loss: 0.0519, Val Loss: 0.0210\n",
            "Epoch [17/200], Loss: 0.0511, Val Loss: 0.0213\n",
            "Epoch [18/200], Loss: 0.0504, Val Loss: 0.0206\n",
            "Epoch [19/200], Loss: 0.0491, Val Loss: 0.0192\n",
            "Epoch [20/200], Loss: 0.0482, Val Loss: 0.0187\n",
            "Epoch [21/200], Loss: 0.0473, Val Loss: 0.0189\n",
            "Epoch [22/200], Loss: 0.0469, Val Loss: 0.0181\n",
            "Epoch [23/200], Loss: 0.0464, Val Loss: 0.0179\n",
            "Epoch [24/200], Loss: 0.0456, Val Loss: 0.0174\n",
            "Epoch [25/200], Loss: 0.0455, Val Loss: 0.0175\n",
            "Epoch [26/200], Loss: 0.0449, Val Loss: 0.0186\n",
            "Epoch [27/200], Loss: 0.0443, Val Loss: 0.0164\n",
            "Epoch [28/200], Loss: 0.0439, Val Loss: 0.0181\n",
            "Epoch [29/200], Loss: 0.0435, Val Loss: 0.0178\n",
            "Epoch [30/200], Loss: 0.0428, Val Loss: 0.0159\n",
            "Epoch [31/200], Loss: 0.0424, Val Loss: 0.0166\n",
            "Epoch [32/200], Loss: 0.0420, Val Loss: 0.0152\n",
            "Epoch [33/200], Loss: 0.0414, Val Loss: 0.0170\n",
            "Epoch [34/200], Loss: 0.0413, Val Loss: 0.0152\n",
            "Epoch [35/200], Loss: 0.0405, Val Loss: 0.0152\n",
            "Epoch [36/200], Loss: 0.0397, Val Loss: 0.0156\n",
            "Epoch [37/200], Loss: 0.0398, Val Loss: 0.0137\n",
            "Epoch [38/200], Loss: 0.0388, Val Loss: 0.0141\n",
            "Epoch [39/200], Loss: 0.0383, Val Loss: 0.0110\n",
            "Epoch [40/200], Loss: 0.0379, Val Loss: 0.0140\n",
            "Epoch [41/200], Loss: 0.0373, Val Loss: 0.0108\n",
            "Epoch [42/200], Loss: 0.0366, Val Loss: 0.0120\n",
            "Epoch [43/200], Loss: 0.0367, Val Loss: 0.0119\n",
            "Epoch [44/200], Loss: 0.0364, Val Loss: 0.0115\n",
            "Epoch [45/200], Loss: 0.0360, Val Loss: 0.0118\n",
            "Epoch [46/200], Loss: 0.0361, Val Loss: 0.0116\n",
            "Epoch [47/200], Loss: 0.0354, Val Loss: 0.0117\n",
            "Epoch [48/200], Loss: 0.0353, Val Loss: 0.0105\n",
            "Epoch [49/200], Loss: 0.0353, Val Loss: 0.0100\n",
            "Epoch [50/200], Loss: 0.0348, Val Loss: 0.0113\n",
            "Epoch [51/200], Loss: 0.0357, Val Loss: 0.0110\n",
            "Epoch [52/200], Loss: 0.0350, Val Loss: 0.0103\n",
            "Epoch [53/200], Loss: 0.0348, Val Loss: 0.0109\n",
            "Epoch [54/200], Loss: 0.0350, Val Loss: 0.0113\n",
            "Epoch [55/200], Loss: 0.0349, Val Loss: 0.0123\n",
            "Epoch [56/200], Loss: 0.0339, Val Loss: 0.0101\n",
            "Epoch [57/200], Loss: 0.0344, Val Loss: 0.0105\n",
            "Epoch [58/200], Loss: 0.0343, Val Loss: 0.0107\n",
            "Epoch [59/200], Loss: 0.0339, Val Loss: 0.0097\n",
            "Epoch [60/200], Loss: 0.0342, Val Loss: 0.0101\n",
            "Epoch [61/200], Loss: 0.0339, Val Loss: 0.0114\n",
            "Epoch [62/200], Loss: 0.0340, Val Loss: 0.0107\n",
            "Epoch [63/200], Loss: 0.0337, Val Loss: 0.0105\n",
            "Epoch [64/200], Loss: 0.0336, Val Loss: 0.0113\n",
            "Epoch [65/200], Loss: 0.0337, Val Loss: 0.0099\n",
            "Epoch [66/200], Loss: 0.0335, Val Loss: 0.0102\n",
            "Epoch [67/200], Loss: 0.0331, Val Loss: 0.0093\n",
            "Epoch [68/200], Loss: 0.0338, Val Loss: 0.0113\n",
            "Epoch [69/200], Loss: 0.0336, Val Loss: 0.0117\n",
            "Epoch [70/200], Loss: 0.0332, Val Loss: 0.0102\n",
            "Epoch [71/200], Loss: 0.0328, Val Loss: 0.0105\n",
            "Epoch [72/200], Loss: 0.0329, Val Loss: 0.0108\n",
            "Epoch [73/200], Loss: 0.0331, Val Loss: 0.0101\n",
            "Epoch [74/200], Loss: 0.0331, Val Loss: 0.0102\n",
            "Epoch [75/200], Loss: 0.0332, Val Loss: 0.0109\n",
            "Epoch [76/200], Loss: 0.0326, Val Loss: 0.0107\n",
            "Epoch [77/200], Loss: 0.0323, Val Loss: 0.0097\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1464, Val Loss: 0.0644\n",
            "Epoch [2/200], Loss: 0.0928, Val Loss: 0.0505\n",
            "Epoch [3/200], Loss: 0.0843, Val Loss: 0.0464\n",
            "Epoch [4/200], Loss: 0.0754, Val Loss: 0.0336\n",
            "Epoch [5/200], Loss: 0.0692, Val Loss: 0.0318\n",
            "Epoch [6/200], Loss: 0.0668, Val Loss: 0.0292\n",
            "Epoch [7/200], Loss: 0.0645, Val Loss: 0.0263\n",
            "Epoch [8/200], Loss: 0.0628, Val Loss: 0.0267\n",
            "Epoch [9/200], Loss: 0.0613, Val Loss: 0.0261\n",
            "Epoch [10/200], Loss: 0.0599, Val Loss: 0.0264\n",
            "Epoch [11/200], Loss: 0.0592, Val Loss: 0.0254\n",
            "Epoch [12/200], Loss: 0.0581, Val Loss: 0.0233\n",
            "Epoch [13/200], Loss: 0.0572, Val Loss: 0.0252\n",
            "Epoch [14/200], Loss: 0.0566, Val Loss: 0.0256\n",
            "Epoch [15/200], Loss: 0.0559, Val Loss: 0.0247\n",
            "Epoch [16/200], Loss: 0.0549, Val Loss: 0.0243\n",
            "Epoch [17/200], Loss: 0.0542, Val Loss: 0.0254\n",
            "Epoch [18/200], Loss: 0.0536, Val Loss: 0.0224\n",
            "Epoch [19/200], Loss: 0.0526, Val Loss: 0.0229\n",
            "Epoch [20/200], Loss: 0.0521, Val Loss: 0.0229\n",
            "Epoch [21/200], Loss: 0.0514, Val Loss: 0.0225\n",
            "Epoch [22/200], Loss: 0.0511, Val Loss: 0.0216\n",
            "Epoch [23/200], Loss: 0.0508, Val Loss: 0.0220\n",
            "Epoch [24/200], Loss: 0.0498, Val Loss: 0.0211\n",
            "Epoch [25/200], Loss: 0.0496, Val Loss: 0.0203\n",
            "Epoch [26/200], Loss: 0.0488, Val Loss: 0.0206\n",
            "Epoch [27/200], Loss: 0.0483, Val Loss: 0.0200\n",
            "Epoch [28/200], Loss: 0.0479, Val Loss: 0.0194\n",
            "Epoch [29/200], Loss: 0.0480, Val Loss: 0.0196\n",
            "Epoch [30/200], Loss: 0.0471, Val Loss: 0.0193\n",
            "Epoch [31/200], Loss: 0.0473, Val Loss: 0.0188\n",
            "Epoch [32/200], Loss: 0.0467, Val Loss: 0.0206\n",
            "Epoch [33/200], Loss: 0.0465, Val Loss: 0.0184\n",
            "Epoch [34/200], Loss: 0.0457, Val Loss: 0.0192\n",
            "Epoch [35/200], Loss: 0.0452, Val Loss: 0.0188\n",
            "Epoch [36/200], Loss: 0.0452, Val Loss: 0.0184\n",
            "Epoch [37/200], Loss: 0.0448, Val Loss: 0.0177\n",
            "Epoch [38/200], Loss: 0.0444, Val Loss: 0.0182\n",
            "Epoch [39/200], Loss: 0.0440, Val Loss: 0.0171\n",
            "Epoch [40/200], Loss: 0.0440, Val Loss: 0.0169\n",
            "Epoch [41/200], Loss: 0.0434, Val Loss: 0.0181\n",
            "Epoch [42/200], Loss: 0.0437, Val Loss: 0.0177\n",
            "Epoch [43/200], Loss: 0.0431, Val Loss: 0.0170\n",
            "Epoch [44/200], Loss: 0.0431, Val Loss: 0.0177\n",
            "Epoch [45/200], Loss: 0.0426, Val Loss: 0.0168\n",
            "Epoch [46/200], Loss: 0.0422, Val Loss: 0.0163\n",
            "Epoch [47/200], Loss: 0.0423, Val Loss: 0.0164\n",
            "Epoch [48/200], Loss: 0.0415, Val Loss: 0.0160\n",
            "Epoch [49/200], Loss: 0.0415, Val Loss: 0.0155\n",
            "Epoch [50/200], Loss: 0.0402, Val Loss: 0.0153\n",
            "Epoch [51/200], Loss: 0.0400, Val Loss: 0.0147\n",
            "Epoch [52/200], Loss: 0.0395, Val Loss: 0.0148\n",
            "Epoch [53/200], Loss: 0.0395, Val Loss: 0.0145\n",
            "Epoch [54/200], Loss: 0.0394, Val Loss: 0.0136\n",
            "Epoch [55/200], Loss: 0.0390, Val Loss: 0.0142\n",
            "Epoch [56/200], Loss: 0.0392, Val Loss: 0.0143\n",
            "Epoch [57/200], Loss: 0.0386, Val Loss: 0.0140\n",
            "Epoch [58/200], Loss: 0.0386, Val Loss: 0.0140\n",
            "Epoch [59/200], Loss: 0.0388, Val Loss: 0.0148\n",
            "Epoch [60/200], Loss: 0.0388, Val Loss: 0.0144\n",
            "Epoch [61/200], Loss: 0.0386, Val Loss: 0.0138\n",
            "Epoch [62/200], Loss: 0.0383, Val Loss: 0.0155\n",
            "Epoch [63/200], Loss: 0.0382, Val Loss: 0.0152\n",
            "Epoch [64/200], Loss: 0.0384, Val Loss: 0.0140\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1508, Val Loss: 0.0518\n",
            "Epoch [2/200], Loss: 0.0875, Val Loss: 0.0348\n",
            "Epoch [3/200], Loss: 0.0748, Val Loss: 0.0331\n",
            "Epoch [4/200], Loss: 0.0711, Val Loss: 0.0306\n",
            "Epoch [5/200], Loss: 0.0677, Val Loss: 0.0274\n",
            "Epoch [6/200], Loss: 0.0645, Val Loss: 0.0254\n",
            "Epoch [7/200], Loss: 0.0627, Val Loss: 0.0247\n",
            "Epoch [8/200], Loss: 0.0615, Val Loss: 0.0239\n",
            "Epoch [9/200], Loss: 0.0606, Val Loss: 0.0253\n",
            "Epoch [10/200], Loss: 0.0597, Val Loss: 0.0244\n",
            "Epoch [11/200], Loss: 0.0588, Val Loss: 0.0230\n",
            "Epoch [12/200], Loss: 0.0575, Val Loss: 0.0240\n",
            "Epoch [13/200], Loss: 0.0570, Val Loss: 0.0239\n",
            "Epoch [14/200], Loss: 0.0563, Val Loss: 0.0228\n",
            "Epoch [15/200], Loss: 0.0554, Val Loss: 0.0225\n",
            "Epoch [16/200], Loss: 0.0550, Val Loss: 0.0242\n",
            "Epoch [17/200], Loss: 0.0543, Val Loss: 0.0220\n",
            "Epoch [18/200], Loss: 0.0536, Val Loss: 0.0218\n",
            "Epoch [19/200], Loss: 0.0532, Val Loss: 0.0219\n",
            "Epoch [20/200], Loss: 0.0524, Val Loss: 0.0214\n",
            "Epoch [21/200], Loss: 0.0517, Val Loss: 0.0211\n",
            "Epoch [22/200], Loss: 0.0509, Val Loss: 0.0225\n",
            "Epoch [23/200], Loss: 0.0504, Val Loss: 0.0208\n",
            "Epoch [24/200], Loss: 0.0498, Val Loss: 0.0214\n",
            "Epoch [25/200], Loss: 0.0494, Val Loss: 0.0217\n",
            "Epoch [26/200], Loss: 0.0490, Val Loss: 0.0225\n",
            "Epoch [27/200], Loss: 0.0484, Val Loss: 0.0219\n",
            "Epoch [28/200], Loss: 0.0480, Val Loss: 0.0218\n",
            "Epoch [29/200], Loss: 0.0478, Val Loss: 0.0215\n",
            "Epoch [30/200], Loss: 0.0468, Val Loss: 0.0208\n",
            "Epoch [31/200], Loss: 0.0468, Val Loss: 0.0219\n",
            "Epoch [32/200], Loss: 0.0463, Val Loss: 0.0205\n",
            "Epoch [33/200], Loss: 0.0462, Val Loss: 0.0215\n",
            "Epoch [34/200], Loss: 0.0454, Val Loss: 0.0209\n",
            "Epoch [35/200], Loss: 0.0455, Val Loss: 0.0206\n",
            "Epoch [36/200], Loss: 0.0453, Val Loss: 0.0218\n",
            "Epoch [37/200], Loss: 0.0445, Val Loss: 0.0206\n",
            "Epoch [38/200], Loss: 0.0441, Val Loss: 0.0206\n",
            "Epoch [39/200], Loss: 0.0440, Val Loss: 0.0203\n",
            "Epoch [40/200], Loss: 0.0439, Val Loss: 0.0208\n",
            "Epoch [41/200], Loss: 0.0435, Val Loss: 0.0200\n",
            "Epoch [42/200], Loss: 0.0432, Val Loss: 0.0188\n",
            "Epoch [43/200], Loss: 0.0427, Val Loss: 0.0193\n",
            "Epoch [44/200], Loss: 0.0424, Val Loss: 0.0183\n",
            "Epoch [45/200], Loss: 0.0421, Val Loss: 0.0174\n",
            "Epoch [46/200], Loss: 0.0419, Val Loss: 0.0179\n",
            "Epoch [47/200], Loss: 0.0415, Val Loss: 0.0180\n",
            "Epoch [48/200], Loss: 0.0421, Val Loss: 0.0171\n",
            "Epoch [49/200], Loss: 0.0412, Val Loss: 0.0175\n",
            "Epoch [50/200], Loss: 0.0416, Val Loss: 0.0175\n",
            "Epoch [51/200], Loss: 0.0407, Val Loss: 0.0180\n",
            "Epoch [52/200], Loss: 0.0408, Val Loss: 0.0174\n",
            "Epoch [53/200], Loss: 0.0408, Val Loss: 0.0167\n",
            "Epoch [54/200], Loss: 0.0406, Val Loss: 0.0177\n",
            "Epoch [55/200], Loss: 0.0392, Val Loss: 0.0173\n",
            "Epoch [56/200], Loss: 0.0400, Val Loss: 0.0162\n",
            "Epoch [57/200], Loss: 0.0393, Val Loss: 0.0170\n",
            "Epoch [58/200], Loss: 0.0389, Val Loss: 0.0147\n",
            "Epoch [59/200], Loss: 0.0386, Val Loss: 0.0134\n",
            "Epoch [60/200], Loss: 0.0381, Val Loss: 0.0144\n",
            "Epoch [61/200], Loss: 0.0385, Val Loss: 0.0154\n",
            "Epoch [62/200], Loss: 0.0377, Val Loss: 0.0128\n",
            "Epoch [63/200], Loss: 0.0375, Val Loss: 0.0145\n",
            "Epoch [64/200], Loss: 0.0372, Val Loss: 0.0140\n",
            "Epoch [65/200], Loss: 0.0370, Val Loss: 0.0144\n",
            "Epoch [66/200], Loss: 0.0369, Val Loss: 0.0140\n",
            "Epoch [67/200], Loss: 0.0371, Val Loss: 0.0132\n",
            "Epoch [68/200], Loss: 0.0374, Val Loss: 0.0138\n",
            "Epoch [69/200], Loss: 0.0370, Val Loss: 0.0128\n",
            "Epoch [70/200], Loss: 0.0372, Val Loss: 0.0133\n",
            "Epoch [71/200], Loss: 0.0365, Val Loss: 0.0127\n",
            "Epoch [72/200], Loss: 0.0366, Val Loss: 0.0133\n",
            "Epoch [73/200], Loss: 0.0364, Val Loss: 0.0133\n",
            "Epoch [74/200], Loss: 0.0369, Val Loss: 0.0142\n",
            "Epoch [75/200], Loss: 0.0364, Val Loss: 0.0156\n",
            "Epoch [76/200], Loss: 0.0364, Val Loss: 0.0133\n",
            "Epoch [77/200], Loss: 0.0369, Val Loss: 0.0144\n",
            "Epoch [78/200], Loss: 0.0367, Val Loss: 0.0143\n",
            "Epoch [79/200], Loss: 0.0364, Val Loss: 0.0127\n",
            "Epoch [80/200], Loss: 0.0361, Val Loss: 0.0135\n",
            "Epoch [81/200], Loss: 0.0365, Val Loss: 0.0124\n",
            "Epoch [82/200], Loss: 0.0360, Val Loss: 0.0141\n",
            "Epoch [83/200], Loss: 0.0365, Val Loss: 0.0146\n",
            "Epoch [84/200], Loss: 0.0357, Val Loss: 0.0140\n",
            "Epoch [85/200], Loss: 0.0360, Val Loss: 0.0136\n",
            "Epoch [86/200], Loss: 0.0365, Val Loss: 0.0136\n",
            "Epoch [87/200], Loss: 0.0354, Val Loss: 0.0129\n",
            "Epoch [88/200], Loss: 0.0361, Val Loss: 0.0134\n",
            "Epoch [89/200], Loss: 0.0364, Val Loss: 0.0135\n",
            "Epoch [90/200], Loss: 0.0358, Val Loss: 0.0131\n",
            "Epoch [91/200], Loss: 0.0355, Val Loss: 0.0129\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1481, Val Loss: 0.0527\n",
            "Epoch [2/200], Loss: 0.0897, Val Loss: 0.0456\n",
            "Epoch [3/200], Loss: 0.0766, Val Loss: 0.0320\n",
            "Epoch [4/200], Loss: 0.0706, Val Loss: 0.0302\n",
            "Epoch [5/200], Loss: 0.0673, Val Loss: 0.0306\n",
            "Epoch [6/200], Loss: 0.0646, Val Loss: 0.0302\n",
            "Epoch [7/200], Loss: 0.0625, Val Loss: 0.0271\n",
            "Epoch [8/200], Loss: 0.0601, Val Loss: 0.0248\n",
            "Epoch [9/200], Loss: 0.0582, Val Loss: 0.0256\n",
            "Epoch [10/200], Loss: 0.0566, Val Loss: 0.0239\n",
            "Epoch [11/200], Loss: 0.0551, Val Loss: 0.0220\n",
            "Epoch [12/200], Loss: 0.0538, Val Loss: 0.0228\n",
            "Epoch [13/200], Loss: 0.0530, Val Loss: 0.0208\n",
            "Epoch [14/200], Loss: 0.0522, Val Loss: 0.0203\n",
            "Epoch [15/200], Loss: 0.0514, Val Loss: 0.0197\n",
            "Epoch [16/200], Loss: 0.0510, Val Loss: 0.0197\n",
            "Epoch [17/200], Loss: 0.0499, Val Loss: 0.0213\n",
            "Epoch [18/200], Loss: 0.0496, Val Loss: 0.0194\n",
            "Epoch [19/200], Loss: 0.0488, Val Loss: 0.0189\n",
            "Epoch [20/200], Loss: 0.0480, Val Loss: 0.0193\n",
            "Epoch [21/200], Loss: 0.0472, Val Loss: 0.0186\n",
            "Epoch [22/200], Loss: 0.0468, Val Loss: 0.0196\n",
            "Epoch [23/200], Loss: 0.0459, Val Loss: 0.0181\n",
            "Epoch [24/200], Loss: 0.0451, Val Loss: 0.0182\n",
            "Epoch [25/200], Loss: 0.0444, Val Loss: 0.0152\n",
            "Epoch [26/200], Loss: 0.0432, Val Loss: 0.0152\n",
            "Epoch [27/200], Loss: 0.0421, Val Loss: 0.0150\n",
            "Epoch [28/200], Loss: 0.0418, Val Loss: 0.0154\n",
            "Epoch [29/200], Loss: 0.0416, Val Loss: 0.0166\n",
            "Epoch [30/200], Loss: 0.0409, Val Loss: 0.0155\n",
            "Epoch [31/200], Loss: 0.0400, Val Loss: 0.0141\n",
            "Epoch [32/200], Loss: 0.0397, Val Loss: 0.0150\n",
            "Epoch [33/200], Loss: 0.0400, Val Loss: 0.0146\n",
            "Epoch [34/200], Loss: 0.0391, Val Loss: 0.0156\n",
            "Epoch [35/200], Loss: 0.0392, Val Loss: 0.0142\n",
            "Epoch [36/200], Loss: 0.0390, Val Loss: 0.0147\n",
            "Epoch [37/200], Loss: 0.0388, Val Loss: 0.0134\n",
            "Epoch [38/200], Loss: 0.0384, Val Loss: 0.0135\n",
            "Epoch [39/200], Loss: 0.0382, Val Loss: 0.0148\n",
            "Epoch [40/200], Loss: 0.0381, Val Loss: 0.0144\n",
            "Epoch [41/200], Loss: 0.0382, Val Loss: 0.0137\n",
            "Epoch [42/200], Loss: 0.0376, Val Loss: 0.0148\n",
            "Epoch [43/200], Loss: 0.0376, Val Loss: 0.0142\n",
            "Epoch [44/200], Loss: 0.0372, Val Loss: 0.0136\n",
            "Epoch [45/200], Loss: 0.0375, Val Loss: 0.0146\n",
            "Epoch [46/200], Loss: 0.0372, Val Loss: 0.0134\n",
            "Epoch [47/200], Loss: 0.0377, Val Loss: 0.0153\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=64, BS=64, Dropout=0.1, EncDim=8 -> MAE=0.0603, Error%=140092338.6458\n",
            "Running: LR=0.001, HS=64, BS=64, Dropout=0.2, EncDim=8\n",
            "80 / 81 completed\n",
            "Epoch [1/200], Loss: 0.1999, Val Loss: 0.0824\n",
            "Epoch [2/200], Loss: 0.1391, Val Loss: 0.0762\n",
            "Epoch [3/200], Loss: 0.1312, Val Loss: 0.0732\n",
            "Epoch [4/200], Loss: 0.1270, Val Loss: 0.0710\n",
            "Epoch [5/200], Loss: 0.1238, Val Loss: 0.0700\n",
            "Epoch [6/200], Loss: 0.1176, Val Loss: 0.0610\n",
            "Epoch [7/200], Loss: 0.1136, Val Loss: 0.0571\n",
            "Epoch [8/200], Loss: 0.1107, Val Loss: 0.0570\n",
            "Epoch [9/200], Loss: 0.1088, Val Loss: 0.0571\n",
            "Epoch [10/200], Loss: 0.1067, Val Loss: 0.0543\n",
            "Epoch [11/200], Loss: 0.1053, Val Loss: 0.0546\n",
            "Epoch [12/200], Loss: 0.1035, Val Loss: 0.0516\n",
            "Epoch [13/200], Loss: 0.1022, Val Loss: 0.0512\n",
            "Epoch [14/200], Loss: 0.1010, Val Loss: 0.0507\n",
            "Epoch [15/200], Loss: 0.0995, Val Loss: 0.0513\n",
            "Epoch [16/200], Loss: 0.0987, Val Loss: 0.0498\n",
            "Epoch [17/200], Loss: 0.0983, Val Loss: 0.0463\n",
            "Epoch [18/200], Loss: 0.0963, Val Loss: 0.0479\n",
            "Epoch [19/200], Loss: 0.0948, Val Loss: 0.0466\n",
            "Epoch [20/200], Loss: 0.0941, Val Loss: 0.0462\n",
            "Epoch [21/200], Loss: 0.0928, Val Loss: 0.0468\n",
            "Epoch [22/200], Loss: 0.0911, Val Loss: 0.0441\n",
            "Epoch [23/200], Loss: 0.0898, Val Loss: 0.0420\n",
            "Epoch [24/200], Loss: 0.0899, Val Loss: 0.0417\n",
            "Epoch [25/200], Loss: 0.0874, Val Loss: 0.0400\n",
            "Epoch [26/200], Loss: 0.0870, Val Loss: 0.0408\n",
            "Epoch [27/200], Loss: 0.0866, Val Loss: 0.0381\n",
            "Epoch [28/200], Loss: 0.0853, Val Loss: 0.0389\n",
            "Epoch [29/200], Loss: 0.0847, Val Loss: 0.0409\n",
            "Epoch [30/200], Loss: 0.0845, Val Loss: 0.0381\n",
            "Epoch [31/200], Loss: 0.0845, Val Loss: 0.0380\n",
            "Epoch [32/200], Loss: 0.0833, Val Loss: 0.0368\n",
            "Epoch [33/200], Loss: 0.0828, Val Loss: 0.0373\n",
            "Epoch [34/200], Loss: 0.0834, Val Loss: 0.0384\n",
            "Epoch [35/200], Loss: 0.0822, Val Loss: 0.0373\n",
            "Epoch [36/200], Loss: 0.0818, Val Loss: 0.0373\n",
            "Epoch [37/200], Loss: 0.0811, Val Loss: 0.0381\n",
            "Epoch [38/200], Loss: 0.0818, Val Loss: 0.0383\n",
            "Epoch [39/200], Loss: 0.0815, Val Loss: 0.0356\n",
            "Epoch [40/200], Loss: 0.0811, Val Loss: 0.0377\n",
            "Epoch [41/200], Loss: 0.0813, Val Loss: 0.0354\n",
            "Epoch [42/200], Loss: 0.0805, Val Loss: 0.0362\n",
            "Epoch [43/200], Loss: 0.0802, Val Loss: 0.0370\n",
            "Epoch [44/200], Loss: 0.0804, Val Loss: 0.0376\n",
            "Epoch [45/200], Loss: 0.0805, Val Loss: 0.0355\n",
            "Epoch [46/200], Loss: 0.0804, Val Loss: 0.0361\n",
            "Epoch [47/200], Loss: 0.0799, Val Loss: 0.0361\n",
            "Epoch [48/200], Loss: 0.0795, Val Loss: 0.0353\n",
            "Epoch [49/200], Loss: 0.0801, Val Loss: 0.0365\n",
            "Epoch [50/200], Loss: 0.0802, Val Loss: 0.0350\n",
            "Epoch [51/200], Loss: 0.0801, Val Loss: 0.0365\n",
            "Epoch [52/200], Loss: 0.0794, Val Loss: 0.0355\n",
            "Epoch [53/200], Loss: 0.0795, Val Loss: 0.0331\n",
            "Epoch [54/200], Loss: 0.0792, Val Loss: 0.0347\n",
            "Epoch [55/200], Loss: 0.0798, Val Loss: 0.0360\n",
            "Epoch [56/200], Loss: 0.0795, Val Loss: 0.0349\n",
            "Epoch [57/200], Loss: 0.0791, Val Loss: 0.0348\n",
            "Epoch [58/200], Loss: 0.0784, Val Loss: 0.0341\n",
            "Epoch [59/200], Loss: 0.0782, Val Loss: 0.0383\n",
            "Epoch [60/200], Loss: 0.0785, Val Loss: 0.0341\n",
            "Epoch [61/200], Loss: 0.0783, Val Loss: 0.0346\n",
            "Epoch [62/200], Loss: 0.0787, Val Loss: 0.0352\n",
            "Epoch [63/200], Loss: 0.0787, Val Loss: 0.0353\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1982, Val Loss: 0.0797\n",
            "Epoch [2/200], Loss: 0.1378, Val Loss: 0.0759\n",
            "Epoch [3/200], Loss: 0.1303, Val Loss: 0.0717\n",
            "Epoch [4/200], Loss: 0.1263, Val Loss: 0.0687\n",
            "Epoch [5/200], Loss: 0.1198, Val Loss: 0.0583\n",
            "Epoch [6/200], Loss: 0.1173, Val Loss: 0.0561\n",
            "Epoch [7/200], Loss: 0.1156, Val Loss: 0.0571\n",
            "Epoch [8/200], Loss: 0.1141, Val Loss: 0.0557\n",
            "Epoch [9/200], Loss: 0.1131, Val Loss: 0.0550\n",
            "Epoch [10/200], Loss: 0.1120, Val Loss: 0.0553\n",
            "Epoch [11/200], Loss: 0.1111, Val Loss: 0.0560\n",
            "Epoch [12/200], Loss: 0.1106, Val Loss: 0.0575\n",
            "Epoch [13/200], Loss: 0.1098, Val Loss: 0.0553\n",
            "Epoch [14/200], Loss: 0.1095, Val Loss: 0.0558\n",
            "Epoch [15/200], Loss: 0.1083, Val Loss: 0.0483\n",
            "Epoch [16/200], Loss: 0.1063, Val Loss: 0.0506\n",
            "Epoch [17/200], Loss: 0.1048, Val Loss: 0.0469\n",
            "Epoch [18/200], Loss: 0.1033, Val Loss: 0.0441\n",
            "Epoch [19/200], Loss: 0.1022, Val Loss: 0.0425\n",
            "Epoch [20/200], Loss: 0.1009, Val Loss: 0.0422\n",
            "Epoch [21/200], Loss: 0.0987, Val Loss: 0.0410\n",
            "Epoch [22/200], Loss: 0.0976, Val Loss: 0.0414\n",
            "Epoch [23/200], Loss: 0.0966, Val Loss: 0.0399\n",
            "Epoch [24/200], Loss: 0.0953, Val Loss: 0.0395\n",
            "Epoch [25/200], Loss: 0.0949, Val Loss: 0.0387\n",
            "Epoch [26/200], Loss: 0.0944, Val Loss: 0.0397\n",
            "Epoch [27/200], Loss: 0.0935, Val Loss: 0.0419\n",
            "Epoch [28/200], Loss: 0.0925, Val Loss: 0.0401\n",
            "Epoch [29/200], Loss: 0.0919, Val Loss: 0.0366\n",
            "Epoch [30/200], Loss: 0.0913, Val Loss: 0.0379\n",
            "Epoch [31/200], Loss: 0.0907, Val Loss: 0.0360\n",
            "Epoch [32/200], Loss: 0.0908, Val Loss: 0.0382\n",
            "Epoch [33/200], Loss: 0.0907, Val Loss: 0.0387\n",
            "Epoch [34/200], Loss: 0.0898, Val Loss: 0.0353\n",
            "Epoch [35/200], Loss: 0.0900, Val Loss: 0.0353\n",
            "Epoch [36/200], Loss: 0.0896, Val Loss: 0.0361\n",
            "Epoch [37/200], Loss: 0.0893, Val Loss: 0.0349\n",
            "Epoch [38/200], Loss: 0.0889, Val Loss: 0.0368\n",
            "Epoch [39/200], Loss: 0.0893, Val Loss: 0.0372\n",
            "Epoch [40/200], Loss: 0.0886, Val Loss: 0.0356\n",
            "Epoch [41/200], Loss: 0.0878, Val Loss: 0.0356\n",
            "Epoch [42/200], Loss: 0.0879, Val Loss: 0.0350\n",
            "Epoch [43/200], Loss: 0.0876, Val Loss: 0.0357\n",
            "Epoch [44/200], Loss: 0.0881, Val Loss: 0.0352\n",
            "Epoch [45/200], Loss: 0.0870, Val Loss: 0.0362\n",
            "Epoch [46/200], Loss: 0.0874, Val Loss: 0.0365\n",
            "Epoch [47/200], Loss: 0.0868, Val Loss: 0.0355\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1950, Val Loss: 0.0768\n",
            "Epoch [2/200], Loss: 0.1352, Val Loss: 0.0748\n",
            "Epoch [3/200], Loss: 0.1288, Val Loss: 0.0721\n",
            "Epoch [4/200], Loss: 0.1244, Val Loss: 0.0718\n",
            "Epoch [5/200], Loss: 0.1216, Val Loss: 0.0690\n",
            "Epoch [6/200], Loss: 0.1190, Val Loss: 0.0690\n",
            "Epoch [7/200], Loss: 0.1151, Val Loss: 0.0642\n",
            "Epoch [8/200], Loss: 0.1115, Val Loss: 0.0574\n",
            "Epoch [9/200], Loss: 0.1092, Val Loss: 0.0585\n",
            "Epoch [10/200], Loss: 0.1074, Val Loss: 0.0561\n",
            "Epoch [11/200], Loss: 0.1057, Val Loss: 0.0566\n",
            "Epoch [12/200], Loss: 0.1049, Val Loss: 0.0571\n",
            "Epoch [13/200], Loss: 0.1032, Val Loss: 0.0547\n",
            "Epoch [14/200], Loss: 0.1024, Val Loss: 0.0522\n",
            "Epoch [15/200], Loss: 0.1012, Val Loss: 0.0526\n",
            "Epoch [16/200], Loss: 0.0989, Val Loss: 0.0511\n",
            "Epoch [17/200], Loss: 0.0986, Val Loss: 0.0525\n",
            "Epoch [18/200], Loss: 0.0974, Val Loss: 0.0496\n",
            "Epoch [19/200], Loss: 0.0964, Val Loss: 0.0490\n",
            "Epoch [20/200], Loss: 0.0954, Val Loss: 0.0498\n",
            "Epoch [21/200], Loss: 0.0946, Val Loss: 0.0492\n",
            "Epoch [22/200], Loss: 0.0933, Val Loss: 0.0487\n",
            "Epoch [23/200], Loss: 0.0934, Val Loss: 0.0471\n",
            "Epoch [24/200], Loss: 0.0934, Val Loss: 0.0468\n",
            "Epoch [25/200], Loss: 0.0915, Val Loss: 0.0473\n",
            "Epoch [26/200], Loss: 0.0914, Val Loss: 0.0465\n",
            "Epoch [27/200], Loss: 0.0907, Val Loss: 0.0445\n",
            "Epoch [28/200], Loss: 0.0905, Val Loss: 0.0480\n",
            "Epoch [29/200], Loss: 0.0900, Val Loss: 0.0477\n",
            "Epoch [30/200], Loss: 0.0895, Val Loss: 0.0436\n",
            "Epoch [31/200], Loss: 0.0888, Val Loss: 0.0451\n",
            "Epoch [32/200], Loss: 0.0888, Val Loss: 0.0433\n",
            "Epoch [33/200], Loss: 0.0886, Val Loss: 0.0458\n",
            "Epoch [34/200], Loss: 0.0885, Val Loss: 0.0449\n",
            "Epoch [35/200], Loss: 0.0875, Val Loss: 0.0437\n",
            "Epoch [36/200], Loss: 0.0873, Val Loss: 0.0457\n",
            "Epoch [37/200], Loss: 0.0878, Val Loss: 0.0456\n",
            "Epoch [38/200], Loss: 0.0871, Val Loss: 0.0429\n",
            "Epoch [39/200], Loss: 0.0871, Val Loss: 0.0447\n",
            "Epoch [40/200], Loss: 0.0864, Val Loss: 0.0430\n",
            "Epoch [41/200], Loss: 0.0864, Val Loss: 0.0435\n",
            "Epoch [42/200], Loss: 0.0861, Val Loss: 0.0450\n",
            "Epoch [43/200], Loss: 0.0852, Val Loss: 0.0430\n",
            "Epoch [44/200], Loss: 0.0855, Val Loss: 0.0432\n",
            "Epoch [45/200], Loss: 0.0860, Val Loss: 0.0431\n",
            "Epoch [46/200], Loss: 0.0856, Val Loss: 0.0417\n",
            "Epoch [47/200], Loss: 0.0848, Val Loss: 0.0415\n",
            "Epoch [48/200], Loss: 0.0853, Val Loss: 0.0414\n",
            "Epoch [49/200], Loss: 0.0850, Val Loss: 0.0440\n",
            "Epoch [50/200], Loss: 0.0848, Val Loss: 0.0430\n",
            "Epoch [51/200], Loss: 0.0844, Val Loss: 0.0426\n",
            "Epoch [52/200], Loss: 0.0845, Val Loss: 0.0417\n",
            "Epoch [53/200], Loss: 0.0845, Val Loss: 0.0424\n",
            "Epoch [54/200], Loss: 0.0842, Val Loss: 0.0423\n",
            "Epoch [55/200], Loss: 0.0839, Val Loss: 0.0426\n",
            "Epoch [56/200], Loss: 0.0832, Val Loss: 0.0417\n",
            "Epoch [57/200], Loss: 0.0836, Val Loss: 0.0404\n",
            "Epoch [58/200], Loss: 0.0840, Val Loss: 0.0416\n",
            "Epoch [59/200], Loss: 0.0840, Val Loss: 0.0422\n",
            "Epoch [60/200], Loss: 0.0836, Val Loss: 0.0412\n",
            "Epoch [61/200], Loss: 0.0842, Val Loss: 0.0406\n",
            "Epoch [62/200], Loss: 0.0830, Val Loss: 0.0420\n",
            "Epoch [63/200], Loss: 0.0838, Val Loss: 0.0405\n",
            "Epoch [64/200], Loss: 0.0830, Val Loss: 0.0420\n",
            "Epoch [65/200], Loss: 0.0833, Val Loss: 0.0427\n",
            "Epoch [66/200], Loss: 0.0837, Val Loss: 0.0416\n",
            "Epoch [67/200], Loss: 0.0837, Val Loss: 0.0422\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.2012, Val Loss: 0.0818\n",
            "Epoch [2/200], Loss: 0.1369, Val Loss: 0.0780\n",
            "Epoch [3/200], Loss: 0.1279, Val Loss: 0.0737\n",
            "Epoch [4/200], Loss: 0.1232, Val Loss: 0.0728\n",
            "Epoch [5/200], Loss: 0.1205, Val Loss: 0.0735\n",
            "Epoch [6/200], Loss: 0.1189, Val Loss: 0.0694\n",
            "Epoch [7/200], Loss: 0.1148, Val Loss: 0.0606\n",
            "Epoch [8/200], Loss: 0.1108, Val Loss: 0.0587\n",
            "Epoch [9/200], Loss: 0.1086, Val Loss: 0.0569\n",
            "Epoch [10/200], Loss: 0.1067, Val Loss: 0.0572\n",
            "Epoch [11/200], Loss: 0.1053, Val Loss: 0.0580\n",
            "Epoch [12/200], Loss: 0.1043, Val Loss: 0.0584\n",
            "Epoch [13/200], Loss: 0.1032, Val Loss: 0.0565\n",
            "Epoch [14/200], Loss: 0.1020, Val Loss: 0.0599\n",
            "Epoch [15/200], Loss: 0.1010, Val Loss: 0.0554\n",
            "Epoch [16/200], Loss: 0.0999, Val Loss: 0.0573\n",
            "Epoch [17/200], Loss: 0.0990, Val Loss: 0.0554\n",
            "Epoch [18/200], Loss: 0.0985, Val Loss: 0.0546\n",
            "Epoch [19/200], Loss: 0.0980, Val Loss: 0.0547\n",
            "Epoch [20/200], Loss: 0.0969, Val Loss: 0.0545\n",
            "Epoch [21/200], Loss: 0.0966, Val Loss: 0.0549\n",
            "Epoch [22/200], Loss: 0.0961, Val Loss: 0.0567\n",
            "Epoch [23/200], Loss: 0.0962, Val Loss: 0.0541\n",
            "Epoch [24/200], Loss: 0.0964, Val Loss: 0.0541\n",
            "Epoch [25/200], Loss: 0.0960, Val Loss: 0.0529\n",
            "Epoch [26/200], Loss: 0.0953, Val Loss: 0.0536\n",
            "Epoch [27/200], Loss: 0.0949, Val Loss: 0.0568\n",
            "Epoch [28/200], Loss: 0.0947, Val Loss: 0.0567\n",
            "Epoch [29/200], Loss: 0.0943, Val Loss: 0.0547\n",
            "Epoch [30/200], Loss: 0.0942, Val Loss: 0.0575\n",
            "Epoch [31/200], Loss: 0.0942, Val Loss: 0.0539\n",
            "Epoch [32/200], Loss: 0.0939, Val Loss: 0.0547\n",
            "Epoch [33/200], Loss: 0.0934, Val Loss: 0.0543\n",
            "Epoch [34/200], Loss: 0.0936, Val Loss: 0.0539\n",
            "Epoch [35/200], Loss: 0.0932, Val Loss: 0.0529\n",
            "Epoch [36/200], Loss: 0.0928, Val Loss: 0.0550\n",
            "Epoch [37/200], Loss: 0.0929, Val Loss: 0.0546\n",
            "Epoch [38/200], Loss: 0.0925, Val Loss: 0.0535\n",
            "Epoch [39/200], Loss: 0.0924, Val Loss: 0.0547\n",
            "Epoch [40/200], Loss: 0.0926, Val Loss: 0.0518\n",
            "Epoch [41/200], Loss: 0.0925, Val Loss: 0.0538\n",
            "Epoch [42/200], Loss: 0.0919, Val Loss: 0.0528\n",
            "Epoch [43/200], Loss: 0.0916, Val Loss: 0.0545\n",
            "Epoch [44/200], Loss: 0.0919, Val Loss: 0.0525\n",
            "Epoch [45/200], Loss: 0.0926, Val Loss: 0.0559\n",
            "Epoch [46/200], Loss: 0.0918, Val Loss: 0.0550\n",
            "Epoch [47/200], Loss: 0.0912, Val Loss: 0.0540\n",
            "Epoch [48/200], Loss: 0.0910, Val Loss: 0.0541\n",
            "Epoch [49/200], Loss: 0.0911, Val Loss: 0.0557\n",
            "Epoch [50/200], Loss: 0.0915, Val Loss: 0.0543\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Epoch [1/200], Loss: 0.1983, Val Loss: 0.0790\n",
            "Epoch [2/200], Loss: 0.1361, Val Loss: 0.0757\n",
            "Epoch [3/200], Loss: 0.1285, Val Loss: 0.0760\n",
            "Epoch [4/200], Loss: 0.1240, Val Loss: 0.0739\n",
            "Epoch [5/200], Loss: 0.1220, Val Loss: 0.0733\n",
            "Epoch [6/200], Loss: 0.1201, Val Loss: 0.0731\n",
            "Epoch [7/200], Loss: 0.1184, Val Loss: 0.0726\n",
            "Epoch [8/200], Loss: 0.1171, Val Loss: 0.0724\n",
            "Epoch [9/200], Loss: 0.1151, Val Loss: 0.0715\n",
            "Epoch [10/200], Loss: 0.1141, Val Loss: 0.0734\n",
            "Epoch [11/200], Loss: 0.1127, Val Loss: 0.0708\n",
            "Epoch [12/200], Loss: 0.1122, Val Loss: 0.0707\n",
            "Epoch [13/200], Loss: 0.1108, Val Loss: 0.0707\n",
            "Epoch [14/200], Loss: 0.1091, Val Loss: 0.0710\n",
            "Epoch [15/200], Loss: 0.1087, Val Loss: 0.0698\n",
            "Epoch [16/200], Loss: 0.1077, Val Loss: 0.0689\n",
            "Epoch [17/200], Loss: 0.1074, Val Loss: 0.0694\n",
            "Epoch [18/200], Loss: 0.1058, Val Loss: 0.0698\n",
            "Epoch [19/200], Loss: 0.1045, Val Loss: 0.0635\n",
            "Epoch [20/200], Loss: 0.1022, Val Loss: 0.0586\n",
            "Epoch [21/200], Loss: 0.1004, Val Loss: 0.0554\n",
            "Epoch [22/200], Loss: 0.0990, Val Loss: 0.0562\n",
            "Epoch [23/200], Loss: 0.0980, Val Loss: 0.0561\n",
            "Epoch [24/200], Loss: 0.0967, Val Loss: 0.0551\n",
            "Epoch [25/200], Loss: 0.0956, Val Loss: 0.0530\n",
            "Epoch [26/200], Loss: 0.0947, Val Loss: 0.0528\n",
            "Epoch [27/200], Loss: 0.0946, Val Loss: 0.0522\n",
            "Epoch [28/200], Loss: 0.0933, Val Loss: 0.0524\n",
            "Epoch [29/200], Loss: 0.0919, Val Loss: 0.0507\n",
            "Epoch [30/200], Loss: 0.0914, Val Loss: 0.0483\n",
            "Epoch [31/200], Loss: 0.0905, Val Loss: 0.0476\n",
            "Epoch [32/200], Loss: 0.0903, Val Loss: 0.0481\n",
            "Epoch [33/200], Loss: 0.0907, Val Loss: 0.0464\n",
            "Epoch [34/200], Loss: 0.0894, Val Loss: 0.0484\n",
            "Epoch [35/200], Loss: 0.0893, Val Loss: 0.0466\n",
            "Epoch [36/200], Loss: 0.0882, Val Loss: 0.0457\n",
            "Epoch [37/200], Loss: 0.0876, Val Loss: 0.0460\n",
            "Epoch [38/200], Loss: 0.0880, Val Loss: 0.0452\n",
            "Epoch [39/200], Loss: 0.0869, Val Loss: 0.0452\n",
            "Epoch [40/200], Loss: 0.0877, Val Loss: 0.0466\n",
            "Epoch [41/200], Loss: 0.0872, Val Loss: 0.0465\n",
            "Epoch [42/200], Loss: 0.0861, Val Loss: 0.0485\n",
            "Epoch [43/200], Loss: 0.0866, Val Loss: 0.0448\n",
            "Epoch [44/200], Loss: 0.0866, Val Loss: 0.0463\n",
            "Epoch [45/200], Loss: 0.0864, Val Loss: 0.0463\n",
            "Epoch [46/200], Loss: 0.0862, Val Loss: 0.0462\n",
            "Epoch [47/200], Loss: 0.0855, Val Loss: 0.0454\n",
            "Epoch [48/200], Loss: 0.0860, Val Loss: 0.0449\n",
            "Epoch [49/200], Loss: 0.0849, Val Loss: 0.0438\n",
            "Epoch [50/200], Loss: 0.0852, Val Loss: 0.0472\n",
            "Epoch [51/200], Loss: 0.0859, Val Loss: 0.0448\n",
            "Epoch [52/200], Loss: 0.0853, Val Loss: 0.0452\n",
            "Epoch [53/200], Loss: 0.0853, Val Loss: 0.0450\n",
            "Epoch [54/200], Loss: 0.0845, Val Loss: 0.0455\n",
            "Epoch [55/200], Loss: 0.0843, Val Loss: 0.0454\n",
            "Epoch [56/200], Loss: 0.0847, Val Loss: 0.0450\n",
            "Epoch [57/200], Loss: 0.0841, Val Loss: 0.0415\n",
            "Epoch [58/200], Loss: 0.0833, Val Loss: 0.0401\n",
            "Epoch [59/200], Loss: 0.0825, Val Loss: 0.0406\n",
            "Epoch [60/200], Loss: 0.0835, Val Loss: 0.0427\n",
            "Epoch [61/200], Loss: 0.0828, Val Loss: 0.0423\n",
            "Epoch [62/200], Loss: 0.0834, Val Loss: 0.0410\n",
            "Epoch [63/200], Loss: 0.0825, Val Loss: 0.0408\n",
            "Epoch [64/200], Loss: 0.0819, Val Loss: 0.0406\n",
            "Epoch [65/200], Loss: 0.0823, Val Loss: 0.0405\n",
            "Epoch [66/200], Loss: 0.0822, Val Loss: 0.0422\n",
            "Epoch [67/200], Loss: 0.0819, Val Loss: 0.0400\n",
            "Epoch [68/200], Loss: 0.0818, Val Loss: 0.0387\n",
            "Epoch [69/200], Loss: 0.0818, Val Loss: 0.0388\n",
            "Epoch [70/200], Loss: 0.0814, Val Loss: 0.0404\n",
            "Epoch [71/200], Loss: 0.0812, Val Loss: 0.0399\n",
            "Epoch [72/200], Loss: 0.0826, Val Loss: 0.0406\n",
            "Epoch [73/200], Loss: 0.0815, Val Loss: 0.0401\n",
            "Epoch [74/200], Loss: 0.0816, Val Loss: 0.0385\n",
            "Epoch [75/200], Loss: 0.0807, Val Loss: 0.0409\n",
            "Epoch [76/200], Loss: 0.0815, Val Loss: 0.0409\n",
            "Epoch [77/200], Loss: 0.0809, Val Loss: 0.0391\n",
            "Epoch [78/200], Loss: 0.0809, Val Loss: 0.0389\n",
            "Epoch [79/200], Loss: 0.0810, Val Loss: 0.0397\n",
            "Epoch [80/200], Loss: 0.0809, Val Loss: 0.0403\n",
            "Epoch [81/200], Loss: 0.0811, Val Loss: 0.0400\n",
            "Epoch [82/200], Loss: 0.0799, Val Loss: 0.0405\n",
            "Epoch [83/200], Loss: 0.0809, Val Loss: 0.0406\n",
            "Epoch [84/200], Loss: 0.0806, Val Loss: 0.0378\n",
            "Epoch [85/200], Loss: 0.0810, Val Loss: 0.0427\n",
            "Epoch [86/200], Loss: 0.0800, Val Loss: 0.0389\n",
            "Epoch [87/200], Loss: 0.0813, Val Loss: 0.0397\n",
            "Epoch [88/200], Loss: 0.0816, Val Loss: 0.0397\n",
            "Epoch [89/200], Loss: 0.0807, Val Loss: 0.0410\n",
            "Epoch [90/200], Loss: 0.0806, Val Loss: 0.0402\n",
            "Epoch [91/200], Loss: 0.0799, Val Loss: 0.0398\n",
            "Epoch [92/200], Loss: 0.0803, Val Loss: 0.0401\n",
            "Epoch [93/200], Loss: 0.0798, Val Loss: 0.0387\n",
            "Epoch [94/200], Loss: 0.0812, Val Loss: 0.0406\n",
            "Early stopping triggered.\n",
            "Training complete. Best model saved.\n",
            "Completed: LR=0.001, HS=64, BS=64, Dropout=0.2, EncDim=8 -> MAE=0.1148, Error%=339133696.8333\n",
            "Hyperparameter tuning completed. Results saved to hyperparameter_tuning_results.csv\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Define hyperparameter search space\n",
        "learning_rates = [0.01, 0.005, 0.001]\n",
        "hidden_sizes = [16, 32, 64]\n",
        "batch_sizes = [16, 32, 64]\n",
        "dropouts = [0.0, 0.1, 0.2]\n",
        "encoding_dims = [8]\n",
        "\n",
        "\n",
        "def run_experiment(x_train, x_val, x_test, learning_rate, hidden_size, batch_size, dropout, encoding_dim, epochs=200, patience=10, runs=5):\n",
        "    maes, error_percentages = [], []\n",
        "\n",
        "    for _ in range(runs):\n",
        "        model_path = 'temp.pth'\n",
        "        autoencoder_model = train_autoencoder(x_train, x_val, learning_rate=learning_rate, hidden_size=hidden_size,\n",
        "                                              batch_size=batch_size, dropout=dropout, encoding_dim=encoding_dim,\n",
        "                                              epochs=epochs, patience=patience, model_path=model_path)\n",
        "\n",
        "        # Convert dataset to numpy if it's a DataFrame\n",
        "        x_test_scaled = x_test.values if isinstance(x_test, pd.DataFrame) else x_test\n",
        "\n",
        "        # Calculate reconstruction error\n",
        "        with torch.no_grad():\n",
        "            reconstructed_test = autoencoder_model(torch.tensor(x_test_scaled, dtype=torch.float32).to(device)).cpu().numpy()\n",
        "\n",
        "        reconstruction_error_percentage = (\n",
        "            np.mean(np.abs(x_test_scaled - reconstructed_test) / (np.abs(x_test_scaled) + 1e-8), axis=1) * 100\n",
        "        )\n",
        "        mae_per_column = np.abs(x_test_scaled - reconstructed_test)\n",
        "        mae_per_row = np.mean(mae_per_column, axis=1)\n",
        "\n",
        "        maes.append(np.mean(mae_per_row))\n",
        "        error_percentages.append(np.mean(reconstruction_error_percentage))\n",
        "\n",
        "    return np.mean(maes), np.mean(error_percentages)\n",
        "\n",
        "# Run experiments for all combinations\n",
        "hyperparameter_combinations = list(itertools.product(learning_rates, hidden_sizes, batch_sizes, dropouts, encoding_dims))\n",
        "\n",
        "total_len = len(learning_rates) * len(hidden_sizes) * len(batch_sizes) * len(dropouts) * len(encoding_dims)\n",
        "results = []\n",
        "count = 0\n",
        "\n",
        "for lr, hs, bs, dr, enc_dim in hyperparameter_combinations:\n",
        "    print(f\"Running: LR={lr}, HS={hs}, BS={bs}, Dropout={dr}, EncDim={enc_dim}\")\n",
        "    print(f\"{count} / {total_len} completed\")\n",
        "    count += 1\n",
        "    avg_mae, avg_error_percentage = run_experiment(x_train, x_val, x_test, lr, hs, bs, dr, enc_dim)\n",
        "    results.append([lr, hs, bs, dr, enc_dim, avg_mae, avg_error_percentage])\n",
        "    print(f\"Completed: LR={lr}, HS={hs}, BS={bs}, Dropout={dr}, EncDim={enc_dim} -> MAE={avg_mae:.4f}, Error%={avg_error_percentage:.4f}\")\n",
        "\n",
        "# Save results to CSV\n",
        "df_results = pd.DataFrame(results, columns=['Learning Rate', 'Hidden Size', 'Batch Size', 'Dropout', 'Encoding Dim', 'Avg MAE', 'Avg Error %'])\n",
        "df_results.to_csv('hyperparameter_tuning_results.csv', index=False)\n",
        "print(\"Hyperparameter tuning completed. Results saved to hyperparameter_tuning_results.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Top 5 results by lowest MAE\")\n",
        "df_results.sort_values(by=\"Avg MAE\").head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "mFGOHxAuot-G",
        "outputId": "65b62a9b-e75d-4767-8aa1-8353af2bcb34"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 results by lowest MAE\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Learning Rate  Hidden Size  Batch Size  Dropout  Encoding Dim   Avg MAE  \\\n",
              "66          0.001           32          32      0.0             8  0.006393   \n",
              "78          0.001           64          64      0.0             8  0.006886   \n",
              "75          0.001           64          32      0.0             8  0.007525   \n",
              "72          0.001           64          16      0.0             8  0.007675   \n",
              "63          0.001           32          16      0.0             8  0.008793   \n",
              "\n",
              "     Avg Error %  \n",
              "66  2.364888e+07  \n",
              "78  2.750291e+07  \n",
              "75  2.184123e+07  \n",
              "72  1.863790e+07  \n",
              "63  2.995454e+07  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc41c50b-c426-4482-9cc2-ba25e32bab35\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Learning Rate</th>\n",
              "      <th>Hidden Size</th>\n",
              "      <th>Batch Size</th>\n",
              "      <th>Dropout</th>\n",
              "      <th>Encoding Dim</th>\n",
              "      <th>Avg MAE</th>\n",
              "      <th>Avg Error %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>0.001</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.006393</td>\n",
              "      <td>2.364888e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>0.001</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.006886</td>\n",
              "      <td>2.750291e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>0.001</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.007525</td>\n",
              "      <td>2.184123e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>0.001</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.007675</td>\n",
              "      <td>1.863790e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>0.001</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.008793</td>\n",
              "      <td>2.995454e+07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc41c50b-c426-4482-9cc2-ba25e32bab35')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fc41c50b-c426-4482-9cc2-ba25e32bab35 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fc41c50b-c426-4482-9cc2-ba25e32bab35');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d719a1f5-8e8d-4e93-9c20-013df8811074\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d719a1f5-8e8d-4e93-9c20-013df8811074')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d719a1f5-8e8d-4e93-9c20-013df8811074 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Learning Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.001,\n        \"max\": 0.001,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hidden Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 32,\n        \"max\": 64,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Batch Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 16,\n        \"max\": 64,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dropout\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Encoding Dim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.000907738368693121,\n        \"min\": 0.006393289942214797,\n        \"max\": 0.008793427386219568,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.006885718334412899\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg Error %\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4493326.596156029,\n        \"min\": 18637895.479929507,\n        \"max\": 29954538.18865589,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          27502914.285402685\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nV3vNBe2vbgU"
      },
      "execution_count": 16,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}